"""
Causal Narrative Engine - ì¸ê³¼ì  ì„œì‚¬ ì—”ì§„
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

í”„ë¡œì íŠ¸ ëª©ì ì„±ì— ë§ëŠ” ì–¸ì–´ëŠ¥ë ¥ í•™ìŠµ ì‹œìŠ¤í…œ:
- ë³´ì—¬ì£¼ê¸°ì‹(ê²‰ìœ¼ë¡œë§Œ ê·¸ëŸ´ì‹¸í•œ) ì‹œë®¬ë ˆì´ì…˜ ì§€ì–‘
- ì¸ê³¼ì  í˜•íƒœì˜ ì„­ë¦¬êµ¬ì¡° ì§€í–¥
- ì‚¬ê³ ìš°ì£¼ì™€ ê°œë…ë…¸ë“œë“¤ì´ ì„œë¡œ ì´ì–´ì ¸ì„œ êµì •í•˜ê³  ë³´ì™„í•˜ëŠ” í˜•íƒœ

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì°¨ì› í™•ì¥ êµ¬ì¡° (Dimensional Expansion Structure)                            â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚
â”‚                                                                             â”‚
â”‚  ì (Point) â†’ ì„ (Line) â†’ ë©´(Plane) â†’ ê³µê°„(Space) â†’ ë²•ì¹™/ì›ë¦¬(Law)            â”‚
â”‚                                                                             â”‚
â”‚  1. ì  (Point) - ê°œë… ë…¸ë“œ                                                  â”‚
â”‚     ë‹¨ì¼ ê°œë…: "ë¶ˆ", "ëœ¨ê±°ì›€", "ì•„í””"                                        â”‚
â”‚                                                                             â”‚
â”‚  2. ì„  (Line) - ì¸ê³¼ ê´€ê³„                                                   â”‚
â”‚     ë‘ ì ì˜ ì—°ê²°: "ë¶ˆ â†’ ëœ¨ê±°ì›€"                                              â”‚
â”‚     ê´€ê³„ì  ì˜ë¯¸ì˜ ì°½ë°œ                                                       â”‚
â”‚                                                                             â”‚
â”‚  3. ë©´ (Plane) - ë¬¸ë§¥/ë§¥ë½                                                  â”‚
â”‚     ì—¬ëŸ¬ ì„ ì˜ êµì°¨: "ë¶ˆ + ì† + ë‹¿ë‹¤ â†’ ëœ¨ê±°ì›€ + ì•„í””"                         â”‚
â”‚     ìƒí™©ì  ì´í•´ì˜ ì°½ë°œ                                                       â”‚
â”‚                                                                             â”‚
â”‚  4. ê³µê°„ (Space) - ì„¸ê³„ê´€/ìŠ¤í‚¤ë§ˆ                                            â”‚
â”‚     ì—¬ëŸ¬ ë©´ì˜ êµì°¨: "ìœ„í—˜ íšŒí”¼", "ìƒì¡´ ë³¸ëŠ¥"                                  â”‚
â”‚     íŒ¨í„´ ì¸ì‹ê³¼ ì¼ë°˜í™”                                                       â”‚
â”‚                                                                             â”‚
â”‚  5. ë²•ì¹™ (Law/Principle) - ë³´í¸ì  ì›ë¦¬                                      â”‚
â”‚     ê³µê°„ì„ ê´€í†µí•˜ëŠ” ë¶ˆë³€ ê·œì¹™: "ì¸ê³¼ìœ¨", "ì—ë„ˆì§€ ë³´ì¡´"                        â”‚
â”‚     ì„­ë¦¬ì  ì´í•´                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[ì‚¬ê³ ìš°ì£¼ì™€ ê°œë…ë…¸ë“œì˜ ìƒí˜¸ êµì • (Thought Universe & Concept Node Mutual Correction)]

ê°œë…ë…¸ë“œë“¤ì€ ê³ ë¦½ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.
ì‚¬ê³ ìš°ì£¼(Thought Universe) ì•ˆì—ì„œ ì„œë¡œ ì—°ê²°ë˜ê³ , êµì •í•˜ê³ , ë³´ì™„í•©ë‹ˆë‹¤.

1. ìƒí–¥ êµì • (Bottom-Up Correction)
   - ìƒˆë¡œìš´ ê²½í—˜ì´ ê¸°ì¡´ ê°œë…ì„ ìˆ˜ì •
   - "ë¶ˆì€ í•­ìƒ ëœ¨ê²ë‹¤" â†’ "êº¼ì§„ ë¶ˆì€ ì•ˆ ëœ¨ê²ë‹¤" (ë°˜ë¡€ í•™ìŠµ)

2. í•˜í–¥ êµì • (Top-Down Correction)
   - ìƒìœ„ ë²•ì¹™ì´ í•˜ìœ„ ê°œë…ì„ ì¡°ì •
   - "ì—ë„ˆì§€ ë³´ì¡´" ë²•ì¹™ì´ "ë¶ˆì˜ ì—´" ê°œë…ì„ ì •êµí™”

3. ìˆ˜í‰ êµì • (Lateral Correction)
   - ë™ì¼ ë ˆë²¨ì˜ ê°œë…ë“¤ì´ ì„œë¡œ ì¡°ì •
   - "ëœ¨ê±°ì›€"ê³¼ "ì°¨ê°€ì›€"ì´ ì„œë¡œì˜ ê²½ê³„ë¥¼ ì •ì˜

[ì¸ê³¼ì  ì„­ë¦¬ êµ¬ì¡° (Providential Causal Structure)]

1. ì›ì¸ â†’ ê²°ê³¼ (Cause â†’ Effect)
   - ë‹¨ìˆœí•œ ìƒê´€ê´€ê³„ê°€ ì•„ë‹Œ ì¸ê³¼ê´€ê³„
   - "ë¶ˆ â†’ ëœ¨ê±°ì›€"ì´ ì•„ë‹ˆë¼ "ë¶ˆì— ë‹¿ìŒ â†’ ëœ¨ê±°ì›€ì„ ëŠë‚Œ"

2. ì¡°ê±´ â†’ ê°€ëŠ¥ì„± (Condition â†’ Possibility)
   - "ë¹„ê°€ ì˜¤ë©´ â†’ ë¬¼ì›…ë©ì´ê°€ ìƒê¸´ë‹¤"
   - ì¡°ê±´ì  ì¸ê³¼ ì´í•´

3. ëª©ì  â†’ ìˆ˜ë‹¨ (Purpose â†’ Means)
   - "ë°°ê³ í””ì„ í•´ê²°í•˜ê¸° ìœ„í•´ â†’ ìŒì‹ì„ ë¨¹ëŠ”ë‹¤"
   - ëª©ì ë¡ ì  ì´í•´

4. ë°˜ì‚¬ì‹¤ (Counterfactual)
   - "ë§Œì•½ ë¶ˆì— ì†ì„ ëŒ€ì§€ ì•Šì•˜ë‹¤ë©´ â†’ ì•„í”„ì§€ ì•Šì•˜ì„ ê²ƒ"
   - ê°€ì •ë²•ì  ì¶”ë¡ 
"""

from __future__ import annotations

import math
import numpy as np
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple, Any, Set, Callable
from collections import defaultdict
from enum import Enum
import logging
import time

logger = logging.getLogger("CausalNarrativeEngine")


# ============================================================================
# ì°¨ì› ê³„ì¸µ (Dimensional Hierarchy)
# ì  â†’ ì„  â†’ ë©´ â†’ ê³µê°„ â†’ ë²•ì¹™
# ============================================================================

class DimensionLevel(Enum):
    """
    ì§€ì‹ì˜ ì°¨ì› ë ˆë²¨
    
    ì ì—ì„œ ì„ ìœ¼ë¡œ, ì„ ì—ì„œ ë©´ìœ¼ë¡œ, ê³µê°„ìœ¼ë¡œ, ë²•ì¹™ìœ¼ë¡œ í™•ì¥ë˜ëŠ” í˜•íƒœ
    """
    POINT = 0      # ì : ë‹¨ì¼ ê°œë… ë…¸ë“œ
    LINE = 1       # ì„ : ë‘ ê°œë… ê°„ì˜ ê´€ê³„ (ì¸ê³¼)
    PLANE = 2      # ë©´: ì—¬ëŸ¬ ê´€ê³„ê°€ êµì°¨í•˜ëŠ” ë¬¸ë§¥
    SPACE = 3      # ê³µê°„: ì—¬ëŸ¬ ë¬¸ë§¥ì´ êµì°¨í•˜ëŠ” ì„¸ê³„ê´€/ìŠ¤í‚¤ë§ˆ
    LAW = 4        # ë²•ì¹™: ê³µê°„ì„ ê´€í†µí•˜ëŠ” ë³´í¸ì  ì›ë¦¬


@dataclass
class DimensionalEntity:
    """
    ì°¨ì›ì  ì¡´ì¬ - ëª¨ë“  ì§€ì‹ ìš”ì†Œì˜ ê¸°ë°˜ í´ë˜ìŠ¤
    
    ê° ìš”ì†ŒëŠ” ìì‹ ì˜ ì°¨ì› ë ˆë²¨ì„ ì•Œê³  ìˆìœ¼ë©°,
    ìƒìœ„/í•˜ìœ„ ì°¨ì›ì˜ ìš”ì†Œë“¤ê³¼ ì—°ê²°ë©ë‹ˆë‹¤.
    """
    id: str
    level: DimensionLevel
    description: str = ""
    
    # ìƒìœ„ ì°¨ì› ì—°ê²° (ì´ ìš”ì†Œê°€ ì†í•œ ìƒìœ„ êµ¬ì¡°)
    parent_ids: List[str] = field(default_factory=list)
    
    # í•˜ìœ„ ì°¨ì› ì—°ê²° (ì´ ìš”ì†Œë¥¼ êµ¬ì„±í•˜ëŠ” í•˜ìœ„ ìš”ì†Œë“¤)
    child_ids: List[str] = field(default_factory=list)
    
    # ì‹ ë¢°ë„ ë° í•™ìŠµ ìƒíƒœ
    confidence: float = 1.0
    experience_count: int = 0
    last_updated: float = 0.0
    
    # êµì • ì´ë ¥ (ë‹¤ë¥¸ ìš”ì†Œì— ì˜í•´ ìˆ˜ì •ëœ ê¸°ë¡)
    corrections: List[Dict[str, Any]] = field(default_factory=list)
    
    def get_level_name(self) -> str:
        """ì°¨ì› ë ˆë²¨ ì´ë¦„"""
        names = {
            DimensionLevel.POINT: "ì (Point)",
            DimensionLevel.LINE: "ì„ (Line)",
            DimensionLevel.PLANE: "ë©´(Plane)",
            DimensionLevel.SPACE: "ê³µê°„(Space)",
            DimensionLevel.LAW: "ë²•ì¹™(Law)",
        }
        return names.get(self.level, "ì•Œ ìˆ˜ ì—†ìŒ")


# ============================================================================
# ì  (Point) - ê°œë… ë…¸ë“œ
# ============================================================================

@dataclass
class ConceptPoint(DimensionalEntity):
    """
    ì  (Point) - ê°€ì¥ ê¸°ë³¸ì ì¸ ê°œë… ë‹¨ìœ„
    
    ì˜ˆ: "ë¶ˆ", "ëœ¨ê±°ì›€", "ì•„í””", "ì†"
    
    ë‹¨ìˆœí•œ ë ˆì´ë¸”ì´ ì•„ë‹Œ, ê°ê°/ê°ì • ì„œëª…ì„ ê°€ì§„ ì‹¤ì²´
    """
    
    # ê°ê° ì„œëª… (8ì°¨ì›)
    sensory_signature: Dict[str, float] = field(default_factory=dict)
    
    # ê°ì • ê°€ì¹˜ (-1 ~ +1)
    emotional_valence: float = 0.0
    
    # í™œì„±í™” ì •ë„ (í˜„ì¬ ì–¼ë§ˆë‚˜ "ë– ì˜¤ë¥´ëŠ”ê°€")
    activation: float = 0.0
    
    # ê°œë…ì˜ ìœ í˜•
    concept_type: str = "general"  # "object", "action", "state", "relation", "abstract"
    
    def __post_init__(self):
        self.level = DimensionLevel.POINT


# ============================================================================
# ì„  (Line) - ì¸ê³¼ ê´€ê³„
# ============================================================================

@dataclass
class CausalLine(DimensionalEntity):
    """
    ì„  (Line) - ë‘ ì ì„ ì‡ëŠ” ì¸ê³¼ ê´€ê³„
    
    ì˜ˆ: "ë¶ˆ â†’ ëœ¨ê±°ì›€", "ë‹¿ë‹¤ â†’ ì•„í”„ë‹¤"
    
    ë‹¨ìˆœ ì—°ê²°ì´ ì•„ë‹Œ, ê´€ê³„ì˜ ìœ í˜•ê³¼ ë°©í–¥ì„±ì„ ê°€ì§„ ì‹¤ì²´
    """
    
    # ì—°ê²°í•˜ëŠ” ë‘ ì 
    source_point_id: str = ""
    target_point_id: str = ""
    
    # ê´€ê³„ ìœ í˜•
    relation_type: str = "causes"  # "causes", "enables", "prevents", "follows", etc.
    
    # ì¸ê³¼ ê°•ë„ (0 ~ 1)
    strength: float = 1.0
    
    # ì¡°ê±´ë“¤ (ì´ ê´€ê³„ê°€ ì„±ë¦½í•˜ê¸° ìœ„í•œ ì¡°ê±´)
    conditions: List[str] = field(default_factory=list)
    
    # ì˜ˆì™¸ ìƒí™©ë“¤ (ì´ ê´€ê³„ê°€ ì„±ë¦½í•˜ì§€ ì•ŠëŠ” ê²½ìš°)
    exceptions: List[str] = field(default_factory=list)
    
    def __post_init__(self):
        self.level = DimensionLevel.LINE


# ============================================================================
# ë©´ (Plane) - ë¬¸ë§¥/ë§¥ë½
# ============================================================================

@dataclass
class ContextPlane(DimensionalEntity):
    """
    ë©´ (Plane) - ì—¬ëŸ¬ ì„ ì´ êµì°¨í•˜ëŠ” ë¬¸ë§¥
    
    ì˜ˆ: "ë¶ˆì— ì†ì„ ëŒ€ë©´ ì•„í”„ë‹¤" (ë¶ˆ, ì†, ë‹¿ë‹¤, ëœ¨ê²ë‹¤, ì•„í”„ë‹¤ì˜ êµì°¨)
    
    ìƒí™©ì  ì´í•´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” êµ¬ì¡°
    """
    
    # ì´ ë©´ì„ êµ¬ì„±í•˜ëŠ” ì„ ë“¤
    line_ids: List[str] = field(default_factory=list)
    
    # ì´ ë©´ì— í¬í•¨ëœ ì ë“¤ (ì„ ë“¤ì˜ ëì )
    point_ids: List[str] = field(default_factory=list)
    
    # ë¬¸ë§¥ì˜ ìœ í˜•
    context_type: str = "situation"  # "situation", "scenario", "episode"
    
    # ê°ì •ì  ë¶„ìœ„ê¸° (ì´ ë¬¸ë§¥ì˜ ì „ì²´ì ì¸ ê°ì •)
    emotional_tone: float = 0.0
    
    # ì‹œê°„ì  ë²”ìœ„
    temporal_span: str = "instant"  # "instant", "short", "long", "repeated"
    
    # ë¬¸ë§¥ì˜ ê²°ë¡ /êµí›ˆ
    lesson: str = ""
    
    def __post_init__(self):
        self.level = DimensionLevel.PLANE


# ============================================================================
# ê³µê°„ (Space) - ì„¸ê³„ê´€/ìŠ¤í‚¤ë§ˆ
# ============================================================================

@dataclass
class SchemaSpace(DimensionalEntity):
    """
    ê³µê°„ (Space) - ì—¬ëŸ¬ ë©´ì´ êµì°¨í•˜ëŠ” ì„¸ê³„ê´€/ìŠ¤í‚¤ë§ˆ
    
    ì˜ˆ: "ìœ„í—˜ íšŒí”¼ ìŠ¤í‚¤ë§ˆ", "ìƒì¡´ ë³¸ëŠ¥ ìŠ¤í‚¤ë§ˆ", "ì‚¬íšŒì  ìƒí˜¸ì‘ìš© ìŠ¤í‚¤ë§ˆ"
    
    íŒ¨í„´ ì¸ì‹ê³¼ ì¼ë°˜í™”ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” êµ¬ì¡°
    """
    
    # ì´ ê³µê°„ì„ êµ¬ì„±í•˜ëŠ” ë©´ë“¤
    plane_ids: List[str] = field(default_factory=list)
    
    # ìŠ¤í‚¤ë§ˆì˜ ìœ í˜•
    schema_type: str = "behavior"  # "behavior", "belief", "emotion", "social"
    
    # ìŠ¤í‚¤ë§ˆì˜ í•µì‹¬ ì›ë¦¬ (ì´ ê³µê°„ì„ ê´€í†µí•˜ëŠ” ì£¼ìš” íŒ¨í„´)
    core_patterns: List[str] = field(default_factory=list)
    
    # ì ìš© ë²”ìœ„ (ì–´ë–¤ ìƒí™©ì— ì ìš©ë˜ëŠ”ê°€)
    applicability: List[str] = field(default_factory=list)
    
    # ì˜ˆì¸¡ë ¥ (ì´ ìŠ¤í‚¤ë§ˆë¡œ ì–¼ë§ˆë‚˜ ì •í™•íˆ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ”ê°€)
    predictive_power: float = 0.0
    
    def __post_init__(self):
        self.level = DimensionLevel.SPACE


# ============================================================================
# ë²•ì¹™ (Law) - ë³´í¸ì  ì›ë¦¬
# ============================================================================

@dataclass
class UniversalLaw(DimensionalEntity):
    """
    ë²•ì¹™ (Law) - ì—¬ëŸ¬ ê³µê°„ì„ ê´€í†µí•˜ëŠ” ë³´í¸ì  ì›ë¦¬
    
    ì˜ˆ: "ì¸ê³¼ìœ¨", "ì—ë„ˆì§€ ë³´ì¡´", "í–‰ë™-ê²°ê³¼ ì—°ê²°"
    
    ì„­ë¦¬ì  ì´í•´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ìµœìƒìœ„ êµ¬ì¡°
    """
    
    # ì´ ë²•ì¹™ì´ ì ìš©ë˜ëŠ” ê³µê°„ë“¤
    space_ids: List[str] = field(default_factory=list)
    
    # ë²•ì¹™ì˜ ìœ í˜•
    law_type: str = "causal"  # "causal", "conservation", "symmetry", "teleological"
    
    # ë²•ì¹™ì˜ ê³µì‹í™” (ê°€ëŠ¥í•˜ë©´)
    formulation: str = ""
    
    # ì˜ˆì™¸ ì—†ìŒ ì—¬ë¶€ (ì§„ì •í•œ ë²•ì¹™ì¸ê°€, ì•„ë‹ˆë©´ ê²½í–¥ì„±ì¸ê°€)
    is_absolute: bool = False
    
    # ì¦ê±° (ì´ ë²•ì¹™ì„ ì§€ì§€í•˜ëŠ” ê²½í—˜ë“¤)
    supporting_evidence: List[str] = field(default_factory=list)
    
    # ë°˜ë¡€ (ì´ ë²•ì¹™ì— ìœ„ë°°ë˜ëŠ” ê²½í—˜ë“¤)
    counter_examples: List[str] = field(default_factory=list)
    
    def __post_init__(self):
        self.level = DimensionLevel.LAW


# ============================================================================
# ì¸ê³¼ ê´€ê³„ ìœ í˜• (Types of Causal Relations)
# ============================================================================

class CausalRelationType(Enum):
    """ì¸ê³¼ ê´€ê³„ ìœ í˜•"""
    # ì§ì ‘ì  ì¸ê³¼
    CAUSES = "causes"           # Aê°€ Bë¥¼ ì¼ìœ¼í‚´ (A â†’ B)
    PREVENTS = "prevents"       # Aê°€ Bë¥¼ ë§‰ìŒ (A âŠ£ B)
    ENABLES = "enables"         # Aê°€ Bì˜ ê°€ëŠ¥ì„±ì„ ì—´ì–´ì¤Œ
    
    # ì¡°ê±´ì  ì¸ê³¼
    CONDITIONAL = "conditional"  # Aì´ë©´ B (if A then B)
    NECESSARY = "necessary"      # A ì—†ì´ B ë¶ˆê°€ (B requires A)
    SUFFICIENT = "sufficient"    # Aë§Œ ìˆìœ¼ë©´ B ê°€ëŠ¥ (A is enough for B)
    
    # ëª©ì ë¡ ì  ì¸ê³¼
    MEANS_TO = "means_to"        # AëŠ” Bë¥¼ ìœ„í•œ ìˆ˜ë‹¨ (A is means to B)
    PURPOSE_OF = "purpose_of"    # Aì˜ ëª©ì ì€ B (purpose of A is B)
    
    # ì‹œê°„ì  ê´€ê³„
    PRECEDES = "precedes"        # Aê°€ Bë³´ë‹¤ ë¨¼ì € (A before B)
    FOLLOWS = "follows"          # Aê°€ B ë‹¤ìŒ (A after B)
    SIMULTANEOUS = "simultaneous"  # Aì™€ Bê°€ ë™ì‹œ


# ============================================================================
# ì¸ê³¼ ë…¸ë“œ (Causal Node) - ë‹¨ìˆœ ê°œë…ì´ ì•„ë‹Œ ìƒíƒœ/ì‚¬ê±´
# ============================================================================

@dataclass
class CausalNode:
    """
    ì¸ê³¼ ë…¸ë“œ - ë‹¨ìˆœ ê°œë…ì´ ì•„ë‹Œ 'ìƒíƒœ' ë˜ëŠ” 'ì‚¬ê±´'
    
    "ë¶ˆ"ì´ ì•„ë‹ˆë¼ "ë¶ˆì— ì†ì„ ëŒ”ë‹¤"
    "ëœ¨ê±°ì›€"ì´ ì•„ë‹ˆë¼ "ëœ¨ê±°ì›€ì„ ëŠê¼ˆë‹¤"
    
    ìƒíƒœ(State)ì™€ ì‚¬ê±´(Event)ì˜ ì°¨ì´:
    - ìƒíƒœ: ì§€ì†ì ì¸ ì¡°ê±´ (ì˜ˆ: ë°°ê³ í”„ë‹¤, ì•ˆì „í•˜ë‹¤)
    - ì‚¬ê±´: ìˆœê°„ì ì¸ ë°œìƒ (ì˜ˆ: ë¶ˆì— ë‹¿ë‹¤, ë¨¹ë‹¤)
    """
    
    id: str
    description: str              # ìì—°ì–´ ì„¤ëª…
    
    # ë…¸ë“œ ìœ í˜•
    is_state: bool = True         # True: ìƒíƒœ, False: ì‚¬ê±´
    
    # ê´€ë ¨ëœ ê°œë…ë“¤ (ë‹¨ìˆœ ê°œë… ë…¸ë“œì™€ì˜ ì—°ê²°)
    concepts: List[str] = field(default_factory=list)
    
    # ê°ê°/ê°ì • ì„œëª…
    sensory_signature: Dict[str, float] = field(default_factory=dict)
    emotional_valence: float = 0.0  # -1 (ë¶ˆì¾Œ) ~ +1 (ì¾Œ)
    
    # í–‰ìœ„ì (ëˆ„ê°€ ê²½í—˜í–ˆëŠ”ê°€)
    agent: Optional[str] = None
    
    # ì‹œê°„ ì •ë³´
    timestamp: float = 0.0
    duration: float = 0.0  # ì‚¬ê±´ì˜ ê²½ìš° ìˆœê°„, ìƒíƒœì˜ ê²½ìš° ì§€ì† ì‹œê°„
    
    # í™œì„±í™”/ì¤‘ìš”ë„
    activation: float = 1.0
    importance: float = 1.0
    
    # í•™ìŠµ í†µê³„
    experience_count: int = 0
    
    def get_valence_description(self) -> str:
        """ê°ì •ê°€ ì„¤ëª…"""
        if self.emotional_valence > 0.5:
            return "ë§¤ìš° ê¸ì •ì "
        elif self.emotional_valence > 0:
            return "ê¸ì •ì "
        elif self.emotional_valence < -0.5:
            return "ë§¤ìš° ë¶€ì •ì "
        elif self.emotional_valence < 0:
            return "ë¶€ì •ì "
        else:
            return "ì¤‘ë¦½ì "


# ============================================================================
# ì¸ê³¼ ì—°ê²° (Causal Link) - ë…¸ë“œ ê°„ì˜ ì¸ê³¼ ê´€ê³„
# ============================================================================

@dataclass
class CausalLink:
    """
    ì¸ê³¼ ì—°ê²° - ë‘ ë…¸ë“œ ì‚¬ì´ì˜ ì¸ê³¼ ê´€ê³„
    
    ë‹¨ìˆœí•œ ì—°ê²°ì´ ì•„ë‹Œ, "ì™œ"ì™€ "ì–´ë–»ê²Œ"ë¥¼ í¬í•¨
    """
    
    source_id: str                # ì›ì¸/ì¡°ê±´/ìˆ˜ë‹¨
    target_id: str                # ê²°ê³¼/ê°€ëŠ¥ì„±/ëª©ì 
    relation: CausalRelationType  # ê´€ê³„ ìœ í˜•
    
    # ì¸ê³¼ ê°•ë„ (0-1)
    strength: float = 1.0
    
    # ì‹ ë¢°ë„ (ì–¼ë§ˆë‚˜ í™•ì‹¤í•œ ì¸ê³¼ê´€ê³„ì¸ê°€)
    confidence: float = 1.0
    
    # ì¡°ê±´ (ì´ ì¸ê³¼ê°€ ì„±ë¦½í•˜ê¸° ìœ„í•œ ì¡°ê±´ë“¤)
    conditions: List[str] = field(default_factory=list)
    
    # ê²½í—˜ íšŸìˆ˜ (ëª‡ ë²ˆ ê²½í—˜í–ˆëŠ”ê°€)
    experience_count: int = 1
    
    # ë°˜ì‚¬ì‹¤ì  í…ŒìŠ¤íŠ¸ ê²°ê³¼
    counterfactual_tested: bool = False
    counterfactual_confirmed: bool = False
    
    # ìì—°ì–´ ì„¤ëª…
    description: str = ""
    
    def strengthen(self, amount: float = 0.1):
        """ì¸ê³¼ ê°•ë„ ê°•í™” (ë°˜ë³µ ê²½í—˜)"""
        self.strength = min(1.0, self.strength + amount * (1 - self.strength))
        self.experience_count += 1
    
    def weaken(self, amount: float = 0.1):
        """ì¸ê³¼ ê°•ë„ ì•½í™” (ë°˜ì¦)"""
        self.strength = max(0.0, self.strength - amount)
    
    def get_description(self) -> str:
        """ì¸ê³¼ ê´€ê³„ ì„¤ëª… ìƒì„±"""
        relation_descriptions = {
            CausalRelationType.CAUSES: "ë•Œë¬¸ì—",
            CausalRelationType.PREVENTS: "ë§‰ì•„ì„œ",
            CausalRelationType.ENABLES: "ë•ë¶„ì— ê°€ëŠ¥í•´ì ¸ì„œ",
            CausalRelationType.CONDITIONAL: "ì´ë©´",
            CausalRelationType.NECESSARY: "ì—†ì´ëŠ” ë¶ˆê°€ëŠ¥í•´ì„œ",
            CausalRelationType.SUFFICIENT: "ë§Œìœ¼ë¡œ ì¶©ë¶„í•´ì„œ",
            CausalRelationType.MEANS_TO: "í•˜ê¸° ìœ„í•´",
            CausalRelationType.PURPOSE_OF: "ì˜ ëª©ì ì€",
            CausalRelationType.PRECEDES: "ë³´ë‹¤ ë¨¼ì €",
            CausalRelationType.FOLLOWS: "ë‹¤ìŒì—",
            CausalRelationType.SIMULTANEOUS: "ì™€ ë™ì‹œì—",
        }
        return self.description or relation_descriptions.get(self.relation, "ê´€ë ¨ë˜ì–´")


# ============================================================================
# ì¸ê³¼ ì—°ì‡„ (Causal Chain) - ì—°ê²°ëœ ì¸ê³¼ ì‹œí€€ìŠ¤
# ============================================================================

@dataclass
class CausalChain:
    """
    ì¸ê³¼ ì—°ì‡„ - ì—¬ëŸ¬ ì¸ê³¼ ê´€ê³„ê°€ ì—°ê²°ëœ ì‹œí€€ìŠ¤
    
    ì˜ˆ: ë°°ê³ í”” â†’ ìŒì‹ ì°¾ê¸° â†’ ë¨¹ê¸° â†’ ë°°ë¶€ë¦„ â†’ ë§Œì¡±
    
    ì´ê²ƒì´ ì§„ì •í•œ "ì´ì•¼ê¸°"ì˜ ì›í˜•ì…ë‹ˆë‹¤.
    """
    
    id: str
    name: str = ""
    
    # ì—°ì‡„ë¥¼ êµ¬ì„±í•˜ëŠ” ë…¸ë“œë“¤ (ìˆœì„œ ì¤‘ìš”!)
    node_sequence: List[str] = field(default_factory=list)
    
    # ì—°ì‡„ì˜ ì¸ê³¼ ì—°ê²°ë“¤
    links: List[CausalLink] = field(default_factory=list)
    
    # ì—°ì‡„ì˜ ì‹œì‘ê³¼ ë
    initial_state: Optional[str] = None  # ì‹œì‘ ìƒíƒœ (ë™ê¸°)
    final_state: Optional[str] = None    # ë ìƒíƒœ (ê²°ê³¼)
    
    # ì—°ì‡„ì˜ íŠ¹ì„±
    is_goal_directed: bool = False  # ëª©í‘œ ì§€í–¥ì ì¸ê°€
    goal: Optional[str] = None      # ëª©í‘œ
    
    # ì—°ì‡„ì˜ ê°ì •ì  ê¶¤ì 
    emotional_arc: List[float] = field(default_factory=list)
    
    # ê²½í—˜ íšŸìˆ˜
    experience_count: int = 1
    
    # ì—°ì‡„ì˜ íš¨ê³¼ì„± (ëª©í‘œ ë‹¬ì„± ì—¬ë¶€)
    success_rate: float = 0.0
    
    def get_length(self) -> int:
        return len(self.node_sequence)
    
    def get_emotional_trajectory(self) -> str:
        """ê°ì • ê¶¤ì  ë¶„ì„"""
        if not self.emotional_arc:
            return "ì¤‘ë¦½"
        
        start = self.emotional_arc[0] if self.emotional_arc else 0
        end = self.emotional_arc[-1] if self.emotional_arc else 0
        
        if end > start + 0.3:
            return "ìƒìŠ¹ (ë¶€ì •â†’ê¸ì •)"
        elif end < start - 0.3:
            return "í•˜ê°• (ê¸ì •â†’ë¶€ì •)"
        else:
            return "í‰íƒ„"


# ============================================================================
# ì¸ê³¼ì  ì§€ì‹ ë² ì´ìŠ¤ (Causal Knowledge Base)
# ============================================================================

class CausalKnowledgeBase:
    """
    ì¸ê³¼ì  ì§€ì‹ ë² ì´ìŠ¤
    
    ê²½í—˜ì„ í†µí•´ í•™ìŠµëœ ì¸ê³¼ ê´€ê³„ë“¤ì˜ ì €ì¥ì†Œ.
    ë‹¨ìˆœí•œ ê·¸ë˜í”„ê°€ ì•„ë‹Œ, ì¸ê³¼ ì¶”ë¡ ì„ ì§€ì›í•˜ëŠ” êµ¬ì¡°.
    """
    
    def __init__(self):
        # ë…¸ë“œë“¤
        self.nodes: Dict[str, CausalNode] = {}
        
        # ì¸ê³¼ ì—°ê²°ë“¤
        self.links: Dict[str, CausalLink] = {}  # link_id â†’ link
        
        # ì¸ë±ìŠ¤: ë¹ ë¥¸ ê²€ìƒ‰ì„ ìœ„í•œ ì—­ë°©í–¥ ë§¤í•‘
        self.outgoing: Dict[str, List[str]] = defaultdict(list)  # node_id â†’ [link_ids]
        self.incoming: Dict[str, List[str]] = defaultdict(list)  # node_id â†’ [link_ids]
        
        # ì¸ê³¼ ì—°ì‡„ë“¤
        self.chains: Dict[str, CausalChain] = {}
        
        # í†µê³„
        self.total_experiences = 0
    
    def add_node(self, node: CausalNode) -> CausalNode:
        """ë…¸ë“œ ì¶”ê°€ ë˜ëŠ” ì—…ë°ì´íŠ¸"""
        if node.id in self.nodes:
            # ê¸°ì¡´ ë…¸ë“œ ì—…ë°ì´íŠ¸ (ê²½í—˜ ê°•í™”)
            existing = self.nodes[node.id]
            existing.experience_count += 1
            existing.activation = min(1.0, existing.activation + 0.1)
        else:
            self.nodes[node.id] = node
        
        return self.nodes[node.id]
    
    def add_link(
        self,
        source_id: str,
        target_id: str,
        relation: CausalRelationType,
        strength: float = 1.0,
        conditions: List[str] = None,
        description: str = ""
    ) -> CausalLink:
        """ì¸ê³¼ ì—°ê²° ì¶”ê°€ ë˜ëŠ” ê°•í™”"""
        link_id = f"{source_id}_{relation.value}_{target_id}"
        
        if link_id in self.links:
            # ê¸°ì¡´ ì—°ê²° ê°•í™”
            self.links[link_id].strengthen()
        else:
            # ìƒˆ ì—°ê²° ìƒì„±
            link = CausalLink(
                source_id=source_id,
                target_id=target_id,
                relation=relation,
                strength=strength,
                conditions=conditions or [],
                description=description
            )
            self.links[link_id] = link
            self.outgoing[source_id].append(link_id)
            self.incoming[target_id].append(link_id)
        
        return self.links[link_id]
    
    def get_causes_of(self, node_id: str) -> List[Tuple[CausalNode, CausalLink]]:
        """ë…¸ë“œì˜ ì›ì¸ë“¤ ì°¾ê¸° (ì—­ë°©í–¥ ì¸ê³¼ ì¶”ë¡ )"""
        results = []
        for link_id in self.incoming.get(node_id, []):
            link = self.links[link_id]
            if link.relation in [CausalRelationType.CAUSES, CausalRelationType.ENABLES]:
                source_node = self.nodes.get(link.source_id)
                if source_node:
                    results.append((source_node, link))
        return results
    
    def get_effects_of(self, node_id: str) -> List[Tuple[CausalNode, CausalLink]]:
        """ë…¸ë“œì˜ ê²°ê³¼ë“¤ ì°¾ê¸° (ìˆœë°©í–¥ ì¸ê³¼ ì¶”ë¡ )"""
        results = []
        for link_id in self.outgoing.get(node_id, []):
            link = self.links[link_id]
            if link.relation in [CausalRelationType.CAUSES, CausalRelationType.ENABLES]:
                target_node = self.nodes.get(link.target_id)
                if target_node:
                    results.append((target_node, link))
        return results
    
    def trace_causal_chain(
        self,
        start_id: str,
        max_depth: int = 5
    ) -> List[CausalChain]:
        """ì‹œì‘ ë…¸ë“œë¶€í„° ê°€ëŠ¥í•œ ì¸ê³¼ ì—°ì‡„ ì¶”ì """
        chains = []
        
        def dfs(current_id: str, path: List[str], links: List[CausalLink], depth: int):
            if depth >= max_depth:
                if len(path) >= 2:
                    chain = CausalChain(
                        id=f"chain_{len(chains)}",
                        node_sequence=path.copy(),
                        links=links.copy()
                    )
                    chains.append(chain)
                return
            
            for link_id in self.outgoing.get(current_id, []):
                link = self.links[link_id]
                if link.target_id not in path:  # ìˆœí™˜ ë°©ì§€
                    path.append(link.target_id)
                    links.append(link)
                    dfs(link.target_id, path, links, depth + 1)
                    path.pop()
                    links.pop()
            
            # í˜„ì¬ ê²½ë¡œë„ ì²´ì¸ìœ¼ë¡œ ì €ì¥ (ë§ë‹¨ ë…¸ë“œ)
            if len(path) >= 2 and not self.outgoing.get(current_id):
                chain = CausalChain(
                    id=f"chain_{len(chains)}",
                    node_sequence=path.copy(),
                    links=links.copy()
                )
                chains.append(chain)
        
        dfs(start_id, [start_id], [], 0)
        return chains
    
    def find_path(self, source_id: str, target_id: str) -> Optional[CausalChain]:
        """ë‘ ë…¸ë“œ ì‚¬ì´ì˜ ì¸ê³¼ ê²½ë¡œ ì°¾ê¸° (BFS)"""
        if source_id not in self.nodes or target_id not in self.nodes:
            return None
        
        visited = {source_id}
        queue = [(source_id, [source_id], [])]
        
        while queue:
            current_id, path, links = queue.pop(0)
            
            if current_id == target_id:
                return CausalChain(
                    id=f"path_{source_id}_to_{target_id}",
                    node_sequence=path,
                    links=links
                )
            
            for link_id in self.outgoing.get(current_id, []):
                link = self.links[link_id]
                if link.target_id not in visited:
                    visited.add(link.target_id)
                    queue.append((
                        link.target_id,
                        path + [link.target_id],
                        links + [link]
                    ))
        
        return None
    
    def counterfactual_query(
        self,
        premise_node_id: str,
        premise_negated: bool,
        conclusion_node_id: str
    ) -> Tuple[bool, str]:
        """
        ë°˜ì‚¬ì‹¤ì  ì§ˆë¬¸
        
        "ë§Œì•½ Aê°€ (ì•„ë‹ˆì—ˆë‹¤ë©´/ìˆì—ˆë‹¤ë©´) BëŠ” ì–´ë–»ê²Œ ë˜ì—ˆì„ê¹Œ?"
        
        Args:
            premise_node_id: ì „ì œ ë…¸ë“œ
            premise_negated: Trueì´ë©´ "ì—†ì—ˆë‹¤ë©´", Falseì´ë©´ "ìˆì—ˆë‹¤ë©´"
            conclusion_node_id: ê²°ë¡  ë…¸ë“œ
        
        Returns:
            (ê²°ê³¼, ì„¤ëª…)
        """
        # A â†’ B ê²½ë¡œê°€ ìˆëŠ”ì§€ í™•ì¸
        path = self.find_path(premise_node_id, conclusion_node_id)
        
        if path is None:
            return (False, f"{premise_node_id}ì™€ {conclusion_node_id} ì‚¬ì´ì— ì¸ê³¼ ê´€ê³„ ì—†ìŒ")
        
        # ì¸ê³¼ ì—°ê²° ê°•ë„ ê³„ì‚°
        total_strength = 1.0
        for link in path.links:
            total_strength *= link.strength
        
        if premise_negated:
            # "ì—†ì—ˆë‹¤ë©´" â†’ ê²°ê³¼ë„ ì—†ì—ˆì„ ê²ƒ
            if total_strength > 0.7:
                return (True, f"ë§Œì•½ {premise_node_id}ê°€ ì—†ì—ˆë‹¤ë©´, {conclusion_node_id}ë„ ì—†ì—ˆì„ ê²ƒ (í™•ì‹ ë„: {total_strength:.0%})")
            else:
                return (False, f"{premise_node_id}ê°€ ì—†ì–´ë„ {conclusion_node_id}ëŠ” ë‹¤ë¥¸ ê²½ë¡œë¡œ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŒ")
        else:
            # "ìˆì—ˆë‹¤ë©´" â†’ ê²°ê³¼ê°€ ìˆì—ˆì„ ê²ƒ
            if total_strength > 0.5:
                return (True, f"ë§Œì•½ {premise_node_id}ê°€ ìˆì—ˆë‹¤ë©´, {conclusion_node_id}ë„ ìˆì—ˆì„ ê²ƒ (í™•ì‹ ë„: {total_strength:.0%})")
            else:
                return (False, f"{premise_node_id}ë§Œìœ¼ë¡œëŠ” {conclusion_node_id}ë¥¼ ë³´ì¥í•  ìˆ˜ ì—†ìŒ")


# ============================================================================
# ì¸ê³¼ì  ê²½í—˜ (Causal Experience)
# ============================================================================

@dataclass
class CausalExperience:
    """
    ì¸ê³¼ì  ê²½í—˜ - ì‹¤ì œë¡œ ê²½í—˜í•œ ì¸ê³¼ ì—°ì‡„
    
    ì´ê²ƒì´ í•™ìŠµì˜ ê¸°ë³¸ ë‹¨ìœ„ì…ë‹ˆë‹¤.
    """
    
    id: str
    timestamp: float
    
    # ê²½í—˜í•œ ì¸ê³¼ ì—°ì‡„
    cause_node: CausalNode         # ì›ì¸/ì‹œì‘ ìƒíƒœ
    effect_node: CausalNode        # ê²°ê³¼/ë ìƒíƒœ
    intermediate_nodes: List[CausalNode] = field(default_factory=list)  # ì¤‘ê°„ ìƒíƒœë“¤
    
    # í–‰ìœ„ì
    agent_id: str = ""
    
    # ê²°ê³¼
    success: bool = True           # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
    emotional_outcome: float = 0.0  # ê°ì •ì  ê²°ê³¼ (-1 ~ +1)
    
    # ë°˜ì‚¬ì‹¤ì  ì‚¬ê³ 
    counterfactual_considered: bool = False
    alternative_action: Optional[str] = None
    
    def get_full_sequence(self) -> List[CausalNode]:
        """ì „ì²´ ë…¸ë“œ ì‹œí€€ìŠ¤"""
        return [self.cause_node] + self.intermediate_nodes + [self.effect_node]


# ============================================================================
# ì¸ê³¼ì  ì„œì‚¬ ì—”ì§„ (Causal Narrative Engine)
# ============================================================================

class CausalNarrativeEngine:
    """
    ì¸ê³¼ì  ì„œì‚¬ ì—”ì§„
    
    ì‚¬ê±´ì„ í†µí•œ ê´€ê³„ì  ì˜ë¯¸ì˜ ê°œë… ì°½ë°œê³¼ í•™ìŠµì„ êµ¬ì¡°ì ìœ¼ë¡œ ì§€ì›.
    ë‹¨ìˆœ ë…¸ë“œ ì—°ê²°ì´ ì•„ë‹Œ, "ì™œ"ì™€ "ì–´ë–»ê²Œ"ì˜ ì¸ê³¼ êµ¬ì¡°ë¥¼ í•™ìŠµ.
    
    í•µì‹¬ ì›ë¦¬:
    1. ê²½í—˜ ê¸°ë°˜ í•™ìŠµ (Experience-Based Learning)
       - ì¸ê³¼ ì—°ì‡„ë¥¼ ê²½í—˜í•˜ë©´ í•´ë‹¹ ê´€ê³„ê°€ ê°•í™”ë¨
    
    2. ë°˜ì‚¬ì‹¤ì  ì¶”ë¡  (Counterfactual Reasoning)
       - "ë§Œì•½ ~í–ˆë‹¤ë©´"ì„ í†µí•´ ì¸ê³¼ ê´€ê³„ ê²€ì¦
    
    3. ëª©í‘œ ì§€í–¥ì  ê³„íš (Goal-Directed Planning)
       - ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ìœ„í•œ ì›ì¸ íƒìƒ‰
    
    4. ê°ì •ì  í•™ìŠµ (Emotional Learning)
       - ê¸ì •/ë¶€ì • ê²°ê³¼ê°€ ì¸ê³¼ ê°•ë„ì— ì˜í–¥
    """
    
    def __init__(self, persistence_path: str = "causal_memory.json"):
        self.persistence_path = persistence_path
        self.knowledge_base = CausalKnowledgeBase()
        
        # ê²½í—˜ ê¸°ë¡
        self.experiences: List[CausalExperience] = []
        
        # í•™ìŠµ í†µê³„
        self.total_experiences = 0
        self.successful_predictions = 0
        self.failed_predictions = 0
        
        # ê¸°ë³¸ ì¸ê³¼ ìŠ¤í‚¤ë§ˆ ì´ˆê¸°í™”
        self._initialize_fundamental_causality()
        
        # Load Memory
        self.load_memory()
        
        logger.info("ğŸ”® CausalNarrativeEngine initialized")

    def record_experience(self, cause_id: str, effect_id: str, outcome: str):
        """
        Records a real experience to learn causality.
        """
        # 1. Create Nodes if not exist
        cause_node = CausalNode(id=cause_id, description=cause_id)
        effect_node = CausalNode(id=effect_id, description=effect_id)
        
        self.knowledge_base.add_node(cause_node)
        self.knowledge_base.add_node(effect_node)
        
        # 2. Create/Strengthen Link
        # If outcome was positive/expected, strengthen "Causes"
        # If outcome was negative/unexpected, maybe "Prevents" or weak link
        relation = CausalRelationType.CAUSES
        strength = 1.0
        
        self.knowledge_base.add_link(
            source_id=cause_id,
            target_id=effect_id,
            relation=relation,
            strength=strength
        )
        
        # 3. Save
        self.save_memory()
        logger.info(f"ğŸ“ Experience Recorded: {cause_id} -> {effect_id}")

    def save_memory(self):
        """Saves knowledge base to JSON (Simple persistence)."""
        import json
        import copy
        
        # Create a clean dictionary for serialization
        data = {
            "nodes": [n.__dict__.copy() for n in self.knowledge_base.nodes.values()],
            "links": []
        }
        
        for l in self.knowledge_base.links.values():
            l_dict = l.__dict__.copy()
            # Convert Enum to str for JSON
            if hasattr(l_dict["relation"], "value"):
                l_dict["relation"] = l_dict["relation"].value
            data["links"].append(l_dict)
            
        try:
            with open(self.persistence_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, default=str)
        except Exception as e:
            logger.error(f"Failed to save causal memory: {e}")

    def load_memory(self):
        """Loads knowledge base from JSON."""
        import json
        import os
        if not os.path.exists(self.persistence_path):
            return
            
        try:
            with open(self.persistence_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            for n_data in data.get("nodes", []):
                # Reconstruct Node
                node = CausalNode(**n_data)
                self.knowledge_base.nodes[node.id] = node
                
            for l_data in data.get("links", []):
                # Reconstruct Link
                l_data["relation"] = CausalRelationType(l_data["relation"])
                link = CausalLink(**l_data)
                self.knowledge_base.links[f"{link.source_id}_{link.relation.value}_{link.target_id}"] = link
                self.knowledge_base.outgoing[link.source_id].append(f"{link.source_id}_{link.relation.value}_{link.target_id}")
                self.knowledge_base.incoming[link.target_id].append(f"{link.source_id}_{link.relation.value}_{link.target_id}")
                
            logger.info(f"ğŸ“‚ Loaded {len(self.knowledge_base.nodes)} nodes from memory.")
        except Exception as e:
            logger.error(f"Failed to load causal memory: {e}")
    
    def _initialize_fundamental_causality(self):
        """ê¸°ë³¸ì ì¸ ì¸ê³¼ ìŠ¤í‚¤ë§ˆ ì´ˆê¸°í™”"""
        # ìƒì¡´ ê´€ë ¨ ê¸°ë³¸ ì¸ê³¼
        fundamental_causality = [
            # ë¬¼ë¦¬ì  ì¸ê³¼
            ("fire_contact", "pain", CausalRelationType.CAUSES, "ë¶ˆì— ë‹¿ìœ¼ë©´ ì•„í”„ë‹¤"),
            ("pain", "avoidance", CausalRelationType.CAUSES, "ì•„í”„ë©´ í”¼í•˜ê²Œ ëœë‹¤"),
            ("avoidance", "safety", CausalRelationType.CAUSES, "í”¼í•˜ë©´ ì•ˆì „í•´ì§„ë‹¤"),
            
            # ìƒì¡´ ê´€ë ¨
            ("hunger", "seek_food", CausalRelationType.CAUSES, "ë°°ê³ í”„ë©´ ìŒì‹ì„ ì°¾ëŠ”ë‹¤"),
            ("seek_food", "find_food", CausalRelationType.ENABLES, "ìŒì‹ì„ ì°¾ìœ¼ë©´ ë°œê²¬í•  ìˆ˜ ìˆë‹¤"),
            ("find_food", "eat", CausalRelationType.ENABLES, "ìŒì‹ì„ ë°œê²¬í•˜ë©´ ë¨¹ì„ ìˆ˜ ìˆë‹¤"),
            ("eat", "satiety", CausalRelationType.CAUSES, "ë¨¹ìœ¼ë©´ ë°°ë¶€ë¥´ë‹¤"),
            ("satiety", "pleasure", CausalRelationType.CAUSES, "ë°°ë¶€ë¥´ë©´ ê¸°ë¶„ì´ ì¢‹ë‹¤"),
            
            # ì‚¬íšŒì  ì¸ê³¼
            ("loneliness", "seek_company", CausalRelationType.CAUSES, "ì™¸ë¡œìš°ë©´ í•¨ê»˜í•  ì‚¬ëŒì„ ì°¾ëŠ”ë‹¤"),
            ("company", "comfort", CausalRelationType.CAUSES, "í•¨ê»˜í•˜ë©´ ìœ„ë¡œê°€ ëœë‹¤"),
            ("help_given", "trust", CausalRelationType.CAUSES, "ë„ì›€ì„ ì£¼ë©´ ì‹ ë¢°ê°€ ìƒê¸´ë‹¤"),
            ("trust", "cooperation", CausalRelationType.ENABLES, "ì‹ ë¢°ê°€ ìˆìœ¼ë©´ í˜‘ë ¥í•  ìˆ˜ ìˆë‹¤"),
            
            # í•™ìŠµ ê´€ë ¨
            ("curiosity", "exploration", CausalRelationType.CAUSES, "í˜¸ê¸°ì‹¬ì´ ìˆìœ¼ë©´ íƒêµ¬í•œë‹¤"),
            ("exploration", "discovery", CausalRelationType.ENABLES, "íƒêµ¬í•˜ë©´ ë°œê²¬í•  ìˆ˜ ìˆë‹¤"),
            ("discovery", "knowledge", CausalRelationType.CAUSES, "ë°œê²¬í•˜ë©´ ì§€ì‹ì´ ìƒê¸´ë‹¤"),
            ("knowledge", "prediction", CausalRelationType.ENABLES, "ì§€ì‹ì´ ìˆìœ¼ë©´ ì˜ˆì¸¡í•  ìˆ˜ ìˆë‹¤"),
            
            # ëª©ì ë¡ ì  ì¸ê³¼
            ("goal", "planning", CausalRelationType.CAUSES, "ëª©í‘œê°€ ìˆìœ¼ë©´ ê³„íší•œë‹¤"),
            ("planning", "action", CausalRelationType.ENABLES, "ê³„íšì´ ìˆìœ¼ë©´ í–‰ë™í•  ìˆ˜ ìˆë‹¤"),
            ("action", "outcome", CausalRelationType.CAUSES, "í–‰ë™í•˜ë©´ ê²°ê³¼ê°€ ìˆë‹¤"),
        ]
        
        for source, target, relation, description in fundamental_causality:
            # ë…¸ë“œ ìƒì„±
            if source not in self.knowledge_base.nodes:
                self.knowledge_base.add_node(CausalNode(
                    id=source,
                    description=source.replace("_", " "),
                    is_state=True
                ))
            if target not in self.knowledge_base.nodes:
                self.knowledge_base.add_node(CausalNode(
                    id=target,
                    description=target.replace("_", " "),
                    is_state=True
                ))
            
            # ì¸ê³¼ ì—°ê²° ìƒì„±
            self.knowledge_base.add_link(
                source, target, relation,
                strength=0.5,  # ê¸°ë³¸ ê°•ë„ (ê²½í—˜ìœ¼ë¡œ ê°•í™”ë¨)
                description=description
            )
    
    def experience_causality(
        self,
        cause_description: str,
        effect_description: str,
        relation: CausalRelationType = CausalRelationType.CAUSES,
        emotional_outcome: float = 0.0,
        success: bool = True,
        agent_id: str = "self"
    ) -> CausalExperience:
        """
        ì¸ê³¼ ê´€ê³„ ê²½í—˜ (í•™ìŠµì˜ ê¸°ë³¸ ë‹¨ìœ„)
        
        Args:
            cause_description: ì›ì¸ ì„¤ëª…
            effect_description: ê²°ê³¼ ì„¤ëª…
            relation: ì¸ê³¼ ê´€ê³„ ìœ í˜•
            emotional_outcome: ê°ì •ì  ê²°ê³¼ (-1 ~ +1)
            success: ê¸°ëŒ€í•œ ê²°ê³¼ì¸ì§€ ì—¬ë¶€
            agent_id: ê²½í—˜ ì£¼ì²´
        
        Returns:
            ìƒì„±ëœ CausalExperience
        """
        # ë…¸ë“œ ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸
        cause_id = cause_description.lower().replace(" ", "_")
        effect_id = effect_description.lower().replace(" ", "_")
        
        cause_node = self.knowledge_base.add_node(CausalNode(
            id=cause_id,
            description=cause_description,
            is_state=False,  # ì‚¬ê±´
            agent=agent_id,
            timestamp=time.time()
        ))
        
        effect_node = self.knowledge_base.add_node(CausalNode(
            id=effect_id,
            description=effect_description,
            is_state=True,  # ìƒíƒœ
            emotional_valence=emotional_outcome,
            agent=agent_id,
            timestamp=time.time()
        ))
        
        # ì¸ê³¼ ì—°ê²° ê°•í™”
        link = self.knowledge_base.add_link(
            cause_id, effect_id, relation,
            description=f"{cause_description} â†’ {effect_description}"
        )
        
        # ê²°ê³¼ì— ë”°ë¥¸ ê°•ë„ ì¡°ì •
        if success and emotional_outcome > 0:
            link.strengthen(0.2)  # ê¸ì •ì  ê²°ê³¼ = ê°•í•œ ê°•í™”
        elif not success or emotional_outcome < 0:
            link.weaken(0.1)  # ë¶€ì •ì  ê²°ê³¼ = ì•½í•œ ì•½í™”
        
        # ê²½í—˜ ê¸°ë¡
        experience = CausalExperience(
            id=f"exp_{self.total_experiences}",
            timestamp=time.time(),
            cause_node=cause_node,
            effect_node=effect_node,
            agent_id=agent_id,
            success=success,
            emotional_outcome=emotional_outcome
        )
        
        self.experiences.append(experience)
        self.total_experiences += 1
        
        logger.debug(f"ê²½í—˜: {cause_description} â†’ {effect_description} "
                    f"(ê°ì •: {emotional_outcome:.1f}, ì„±ê³µ: {success})")
        
        return experience
    
    def experience_chain(
        self,
        descriptions: List[str],
        emotional_arc: List[float],
        agent_id: str = "self"
    ) -> CausalChain:
        """
        ì¸ê³¼ ì—°ì‡„ ê²½í—˜ (ì—¬ëŸ¬ ë‹¨ê³„ì˜ ì¸ê³¼ ê´€ê³„)
        
        Args:
            descriptions: ê° ë‹¨ê³„ì˜ ì„¤ëª… ë¦¬ìŠ¤íŠ¸
            emotional_arc: ê° ë‹¨ê³„ì˜ ê°ì • ë¦¬ìŠ¤íŠ¸
            agent_id: ê²½í—˜ ì£¼ì²´
        
        Returns:
            ìƒì„±ëœ CausalChain
        """
        if len(descriptions) < 2:
            raise ValueError("ì¸ê³¼ ì—°ì‡„ëŠ” ìµœì†Œ 2ë‹¨ê³„ í•„ìš”")
        
        if len(emotional_arc) != len(descriptions):
            emotional_arc = [0.0] * len(descriptions)
        
        # ê° ì—°ì†ëœ ìŒì— ëŒ€í•´ ê²½í—˜
        nodes = []
        links = []
        
        for i in range(len(descriptions) - 1):
            exp = self.experience_causality(
                cause_description=descriptions[i],
                effect_description=descriptions[i + 1],
                emotional_outcome=emotional_arc[i + 1],
                agent_id=agent_id
            )
            nodes.append(exp.cause_node.id)
            
            if i == len(descriptions) - 2:
                nodes.append(exp.effect_node.id)
        
        # ì—°ì‡„ ìƒì„±
        chain = CausalChain(
            id=f"chain_{len(self.knowledge_base.chains)}",
            name=f"{descriptions[0]} â†’ {descriptions[-1]}",
            node_sequence=nodes,
            initial_state=nodes[0],
            final_state=nodes[-1],
            emotional_arc=emotional_arc
        )
        
        self.knowledge_base.chains[chain.id] = chain
        
        logger.info(f"ì¸ê³¼ ì—°ì‡„ í•™ìŠµ: {chain.name} ({len(nodes)}ë‹¨ê³„)")
        
        return chain
    
    def predict_effect(
        self,
        cause_description: str
    ) -> List[Tuple[str, float, CausalRelationType]]:
        """
        ì›ì¸ìœ¼ë¡œë¶€í„° ê²°ê³¼ ì˜ˆì¸¡
        
        Args:
            cause_description: ì›ì¸ ì„¤ëª…
        
        Returns:
            [(ê²°ê³¼ ì„¤ëª…, í™•ë¥ , ê´€ê³„ ìœ í˜•), ...]
        """
        cause_id = cause_description.lower().replace(" ", "_")
        
        if cause_id not in self.knowledge_base.nodes:
            return []
        
        effects = self.knowledge_base.get_effects_of(cause_id)
        
        predictions = []
        for effect_node, link in effects:
            predictions.append((
                effect_node.description,
                link.strength * link.confidence,
                link.relation
            ))
        
        predictions.sort(key=lambda x: -x[1])
        return predictions
    
    def find_cause(
        self,
        effect_description: str
    ) -> List[Tuple[str, float, CausalRelationType]]:
        """
        ê²°ê³¼ë¡œë¶€í„° ì›ì¸ ì¶”ë¡  (ì—­ë°©í–¥ ì¸ê³¼ ì¶”ë¡ )
        
        Args:
            effect_description: ê²°ê³¼ ì„¤ëª…
        
        Returns:
            [(ì›ì¸ ì„¤ëª…, í™•ë¥ , ê´€ê³„ ìœ í˜•), ...]
        """
        effect_id = effect_description.lower().replace(" ", "_")
        
        if effect_id not in self.knowledge_base.nodes:
            return []
        
        causes = self.knowledge_base.get_causes_of(effect_id)
        
        inferences = []
        for cause_node, link in causes:
            inferences.append((
                cause_node.description,
                link.strength * link.confidence,
                link.relation
            ))
        
        inferences.sort(key=lambda x: -x[1])
        return inferences
    
    def plan_to_achieve(
        self,
        current_state: str,
        goal_state: str
    ) -> Optional[CausalChain]:
        """
        ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ê³„íš (ì¸ê³¼ ê²½ë¡œ íƒìƒ‰)
        
        Args:
            current_state: í˜„ì¬ ìƒíƒœ
            goal_state: ëª©í‘œ ìƒíƒœ
        
        Returns:
            ì¸ê³¼ ì—°ì‡„ (ê³„íš) ë˜ëŠ” None
        """
        current_id = current_state.lower().replace(" ", "_")
        goal_id = goal_state.lower().replace(" ", "_")
        
        return self.knowledge_base.find_path(current_id, goal_id)
    
    def counterfactual_reasoning(
        self,
        premise: str,
        premise_negated: bool,
        conclusion: str
    ) -> Tuple[bool, str]:
        """
        ë°˜ì‚¬ì‹¤ì  ì¶”ë¡ 
        
        "ë§Œì•½ ~í–ˆë‹¤ë©´/í•˜ì§€ ì•Šì•˜ë‹¤ë©´, ~í–ˆì„ê¹Œ?"
        
        Args:
            premise: ì „ì œ
            premise_negated: Trueì´ë©´ "í•˜ì§€ ì•Šì•˜ë‹¤ë©´"
            conclusion: ê²°ë¡ 
        
        Returns:
            (ê²°ê³¼, ì„¤ëª…)
        """
        premise_id = premise.lower().replace(" ", "_")
        conclusion_id = conclusion.lower().replace(" ", "_")
        
        return self.knowledge_base.counterfactual_query(
            premise_id, premise_negated, conclusion_id
        )
    
    def explain_why(self, state: str, depth: int = 3) -> List[str]:
        """
        "ì™œ?"ì— ëŒ€í•œ ì„¤ëª… ìƒì„±
        
        Args:
            state: ì„¤ëª…ì´ í•„ìš”í•œ ìƒíƒœ
            depth: ì¸ê³¼ ì¶”ì  ê¹Šì´
        
        Returns:
            ì„¤ëª… ë¦¬ìŠ¤íŠ¸
        """
        state_id = state.lower().replace(" ", "_")
        
        if state_id not in self.knowledge_base.nodes:
            return [f"'{state}'ì— ëŒ€í•œ ì¸ê³¼ ì§€ì‹ì´ ì—†ìŠµë‹ˆë‹¤."]
        
        explanations = []
        
        def trace_back(node_id: str, current_depth: int, path: List[str]):
            if current_depth >= depth:
                return
            
            causes = self.knowledge_base.get_causes_of(node_id)
            for cause_node, link in causes:
                # ì„¤ëª… ìƒì„±
                cause_desc = cause_node.description
                effect_desc = self.knowledge_base.nodes[node_id].description
                
                explanation = f"{effect_desc}ì¸ ì´ìœ ëŠ” {cause_desc} {link.get_description()}"
                if explanation not in explanations:
                    explanations.append(explanation)
                
                # ë” ê¹Šì´ ì¶”ì 
                if cause_node.id not in path:
                    trace_back(cause_node.id, current_depth + 1, path + [cause_node.id])
        
        trace_back(state_id, 0, [state_id])
        
        return explanations if explanations else [f"'{state}'ì˜ ì›ì¸ì„ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]
    
    def get_statistics(self) -> Dict[str, Any]:
        """í•™ìŠµ í†µê³„"""
        return {
            "total_nodes": len(self.knowledge_base.nodes),
            "total_links": len(self.knowledge_base.links),
            "total_chains": len(self.knowledge_base.chains),
            "total_experiences": self.total_experiences,
            "avg_link_strength": np.mean([
                l.strength for l in self.knowledge_base.links.values()
            ]) if self.knowledge_base.links else 0,
        }
    
    def get_strongest_causalities(self, n: int = 10) -> List[Tuple[str, str, float]]:
        """ê°€ì¥ ê°•í•œ ì¸ê³¼ ê´€ê³„ë“¤"""
        causalities = [
            (link.source_id, link.target_id, link.strength)
            for link in self.knowledge_base.links.values()
        ]
        causalities.sort(key=lambda x: -x[2])
        return causalities[:n]


# ============================================================================
# ì‚¬ê³ ìš°ì£¼ (Thought Universe) - ì°¨ì› ê³„ì¸µ ê´€ë¦¬ ë° ìƒí˜¸ êµì •
# ============================================================================

class ThoughtUniverse:
    """
    ì‚¬ê³ ìš°ì£¼ (Thought Universe)
    
    ì  â†’ ì„  â†’ ë©´ â†’ ê³µê°„ â†’ ë²•ì¹™ìœ¼ë¡œ í™•ì¥ë˜ëŠ” ì§€ì‹ êµ¬ì¡°ë¥¼ ê´€ë¦¬í•˜ê³ ,
    ê° ìš”ì†Œë“¤ì´ ì„œë¡œ êµì •í•˜ê³  ë³´ì™„í•˜ëŠ” ì‹œìŠ¤í…œ.
    
    í•µì‹¬ ì›ë¦¬:
    1. ì°¨ì› í™•ì¥ (Dimensional Expansion)
       - ê²½í—˜ì´ ì¶•ì ë˜ë©´ ìƒìœ„ ì°¨ì›ìœ¼ë¡œ ì¶”ìƒí™”
       - ì ë“¤ì˜ ê´€ê³„ê°€ ì„ ì´ ë˜ê³ , ì„ ë“¤ì˜ êµì°¨ê°€ ë©´ì´ ë¨
    
    2. ìƒí˜¸ êµì • (Mutual Correction)
       - ìƒí–¥ êµì •: ìƒˆ ê²½í—˜ì´ ê¸°ì¡´ ì§€ì‹ì„ ìˆ˜ì •
       - í•˜í–¥ êµì •: ìƒìœ„ ë²•ì¹™ì´ í•˜ìœ„ ê°œë…ì„ ì¡°ì •
       - ìˆ˜í‰ êµì •: ë™ì¼ ë ˆë²¨ ìš”ì†Œë“¤ì´ ì„œë¡œ ì¡°ì •
    
    3. ì¼ê´€ì„± ìœ ì§€ (Consistency Maintenance)
       - ëª¨ìˆœ íƒì§€ ë° í•´ê²°
       - ì‹ ë¢°ë„ ê¸°ë°˜ ìš°ì„ ìˆœìœ„
    """
    
    def __init__(self, name: str = "Elysia's Mind"):
        self.name = name
        
        # ì°¨ì›ë³„ ì €ì¥ì†Œ
        self.points: Dict[str, ConceptPoint] = {}
        self.lines: Dict[str, CausalLine] = {}
        self.planes: Dict[str, ContextPlane] = {}
        self.spaces: Dict[str, SchemaSpace] = {}
        self.laws: Dict[str, UniversalLaw] = {}
        
        # ì „ì²´ ìš”ì†Œ ì¸ë±ìŠ¤ (ë¹ ë¥¸ ê²€ìƒ‰ìš©)
        self.all_entities: Dict[str, DimensionalEntity] = {}
        
        # êµì • ì´ë ¥
        self.correction_history: List[Dict[str, Any]] = []
        
        # í•™ìŠµ í†µê³„
        self.total_points = 0
        self.total_lines = 0
        self.total_planes = 0
        self.total_spaces = 0
        self.total_laws = 0
        self.total_corrections = 0
        
        # ì¸ê³¼ ì—”ì§„ ì—°ê²°
        self.causal_engine = CausalNarrativeEngine()
        
        logger.info(f"ğŸŒŒ ThoughtUniverse '{name}' initialized")
    
    # ========================================================================
    # ì  (Point) ê´€ë¦¬
    # ========================================================================
    
    def add_point(
        self,
        id: str,
        description: str,
        sensory_signature: Dict[str, float] = None,
        emotional_valence: float = 0.0,
        concept_type: str = "general"
    ) -> ConceptPoint:
        """ê°œë… ì  ì¶”ê°€"""
        point = ConceptPoint(
            id=id,
            level=DimensionLevel.POINT,
            description=description,
            sensory_signature=sensory_signature or {},
            emotional_valence=emotional_valence,
            concept_type=concept_type,
            last_updated=time.time()
        )
        
        self.points[id] = point
        self.all_entities[id] = point
        self.total_points += 1
        
        logger.debug(f"ì  ì¶”ê°€: {description}")
        return point
    
    def get_or_create_point(self, id: str, description: str = None) -> ConceptPoint:
        """ì  ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±"""
        if id in self.points:
            return self.points[id]
        return self.add_point(id, description or id)
    
    # ========================================================================
    # ì„  (Line) ê´€ë¦¬ - ë‘ ì ì„ ì—°ê²°
    # ========================================================================
    
    def add_line(
        self,
        source_id: str,
        target_id: str,
        relation_type: str = "causes",
        strength: float = 1.0,
        conditions: List[str] = None,
        description: str = ""
    ) -> CausalLine:
        """ì¸ê³¼ ì„  ì¶”ê°€ (ë‘ ì ì„ ì—°ê²°)"""
        # ì ë“¤ì´ ì—†ìœ¼ë©´ ìƒì„±
        source = self.get_or_create_point(source_id)
        target = self.get_or_create_point(target_id)
        
        line_id = f"{source_id}__{relation_type}__{target_id}"
        
        if line_id in self.lines:
            # ê¸°ì¡´ ì„  ê°•í™”
            existing = self.lines[line_id]
            existing.strength = min(1.0, existing.strength + 0.1)
            existing.experience_count += 1
            existing.last_updated = time.time()
            return existing
        
        line = CausalLine(
            id=line_id,
            level=DimensionLevel.LINE,
            description=description or f"{source_id} {relation_type} {target_id}",
            source_point_id=source_id,
            target_point_id=target_id,
            relation_type=relation_type,
            strength=strength,
            conditions=conditions or [],
            last_updated=time.time()
        )
        
        # ì ë“¤ì— ìì‹ìœ¼ë¡œ ë“±ë¡
        line.child_ids = [source_id, target_id]
        source.parent_ids.append(line_id)
        target.parent_ids.append(line_id)
        
        self.lines[line_id] = line
        self.all_entities[line_id] = line
        self.total_lines += 1
        
        logger.debug(f"ì„  ì¶”ê°€: {source_id} â†’ {target_id}")
        return line
    
    # ========================================================================
    # ë©´ (Plane) ê´€ë¦¬ - ì—¬ëŸ¬ ì„ ì´ êµì°¨í•˜ëŠ” ë¬¸ë§¥
    # ========================================================================
    
    def add_plane(
        self,
        id: str,
        description: str,
        line_ids: List[str],
        context_type: str = "situation",
        lesson: str = ""
    ) -> ContextPlane:
        """ë¬¸ë§¥ ë©´ ì¶”ê°€"""
        # ê´€ë ¨ëœ ì ë“¤ ìˆ˜ì§‘
        point_ids = set()
        for line_id in line_ids:
            if line_id in self.lines:
                line = self.lines[line_id]
                point_ids.add(line.source_point_id)
                point_ids.add(line.target_point_id)
        
        plane = ContextPlane(
            id=id,
            level=DimensionLevel.PLANE,
            description=description,
            line_ids=line_ids,
            point_ids=list(point_ids),
            context_type=context_type,
            lesson=lesson,
            last_updated=time.time()
        )
        
        # ì„ ë“¤ì˜ ë¶€ëª¨ë¡œ ë“±ë¡
        plane.child_ids = line_ids
        for line_id in line_ids:
            if line_id in self.lines:
                self.lines[line_id].parent_ids.append(id)
        
        self.planes[id] = plane
        self.all_entities[id] = plane
        self.total_planes += 1
        
        logger.debug(f"ë©´ ì¶”ê°€: {description}")
        return plane
    
    def emerge_plane_from_experience(
        self,
        experience_description: str,
        point_sequence: List[str],
        emotional_arc: List[float] = None
    ) -> ContextPlane:
        """
        ê²½í—˜ìœ¼ë¡œë¶€í„° ë©´(ë¬¸ë§¥) ì°½ë°œ
        
        ì ë“¤ì˜ ì‹œí€€ìŠ¤ë¥¼ ì„ ë“¤ë¡œ ì—°ê²°í•˜ê³ , ë©´ìœ¼ë¡œ í†µí•©
        """
        if len(point_sequence) < 2:
            raise ValueError("ìµœì†Œ 2ê°œì˜ ì ì´ í•„ìš”í•©ë‹ˆë‹¤")
        
        emotional_arc = emotional_arc or [0.0] * len(point_sequence)
        
        # ì„ ë“¤ ìƒì„±
        line_ids = []
        for i in range(len(point_sequence) - 1):
            line = self.add_line(
                source_id=point_sequence[i],
                target_id=point_sequence[i + 1],
                relation_type="causes"
            )
            line_ids.append(line.id)
        
        # ë©´ ìƒì„±
        plane_id = f"plane_{len(self.planes)}_{point_sequence[0]}_{point_sequence[-1]}"
        
        # ê°ì • ê¶¤ì ì—ì„œ êµí›ˆ ë„ì¶œ
        start_emotion = emotional_arc[0]
        end_emotion = emotional_arc[-1]
        if end_emotion > start_emotion + 0.3:
            lesson = "ê¸ì •ì  ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¨ ê²½í—˜"
        elif end_emotion < start_emotion - 0.3:
            lesson = "ë¶€ì •ì  ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¨ ê²½í—˜"
        else:
            lesson = "ì¤‘ë¦½ì  ê²½í—˜"
        
        plane = self.add_plane(
            id=plane_id,
            description=experience_description,
            line_ids=line_ids,
            context_type="experience",
            lesson=lesson
        )
        
        plane.emotional_tone = end_emotion
        
        return plane
    
    # ========================================================================
    # ê³µê°„ (Space) ê´€ë¦¬ - ì—¬ëŸ¬ ë©´ì´ êµì°¨í•˜ëŠ” ìŠ¤í‚¤ë§ˆ
    # ========================================================================
    
    def add_space(
        self,
        id: str,
        description: str,
        plane_ids: List[str],
        schema_type: str = "behavior",
        core_patterns: List[str] = None
    ) -> SchemaSpace:
        """ìŠ¤í‚¤ë§ˆ ê³µê°„ ì¶”ê°€"""
        space = SchemaSpace(
            id=id,
            level=DimensionLevel.SPACE,
            description=description,
            plane_ids=plane_ids,
            schema_type=schema_type,
            core_patterns=core_patterns or [],
            last_updated=time.time()
        )
        
        # ë©´ë“¤ì˜ ë¶€ëª¨ë¡œ ë“±ë¡
        space.child_ids = plane_ids
        for plane_id in plane_ids:
            if plane_id in self.planes:
                self.planes[plane_id].parent_ids.append(id)
        
        self.spaces[id] = space
        self.all_entities[id] = space
        self.total_spaces += 1
        
        logger.debug(f"ê³µê°„ ì¶”ê°€: {description}")
        return space
    
    def emerge_space_from_planes(
        self,
        plane_ids: List[str],
        min_common_points: int = 2
    ) -> Optional[SchemaSpace]:
        """
        ë©´ë“¤ë¡œë¶€í„° ê³µê°„(ìŠ¤í‚¤ë§ˆ) ì°½ë°œ
        
        ê³µí†µ ìš”ì†Œê°€ ì¶©ë¶„íˆ ìˆëŠ” ë©´ë“¤ì„ í•˜ë‚˜ì˜ ìŠ¤í‚¤ë§ˆë¡œ í†µí•©
        """
        if len(plane_ids) < 2:
            return None
        
        # ê³µí†µ ì  ì°¾ê¸°
        all_point_sets = []
        for plane_id in plane_ids:
            if plane_id in self.planes:
                all_point_sets.append(set(self.planes[plane_id].point_ids))
        
        if not all_point_sets:
            return None
        
        common_points = all_point_sets[0]
        for point_set in all_point_sets[1:]:
            common_points = common_points.intersection(point_set)
        
        if len(common_points) < min_common_points:
            return None
        
        # í•µì‹¬ íŒ¨í„´ ë„ì¶œ
        core_patterns = list(common_points)
        
        # ìŠ¤í‚¤ë§ˆ ìƒì„±
        space_id = f"schema_{len(self.spaces)}"
        description = f"ê³µí†µ ìš”ì†Œ: {', '.join(core_patterns)}"
        
        space = self.add_space(
            id=space_id,
            description=description,
            plane_ids=plane_ids,
            schema_type="emergent",
            core_patterns=core_patterns
        )
        
        return space
    
    # ========================================================================
    # ë²•ì¹™ (Law) ê´€ë¦¬ - ê³µê°„ì„ ê´€í†µí•˜ëŠ” ë³´í¸ì  ì›ë¦¬
    # ========================================================================
    
    def add_law(
        self,
        id: str,
        description: str,
        space_ids: List[str],
        formulation: str = "",
        law_type: str = "causal"
    ) -> UniversalLaw:
        """ë³´í¸ì  ë²•ì¹™ ì¶”ê°€"""
        law = UniversalLaw(
            id=id,
            level=DimensionLevel.LAW,
            description=description,
            space_ids=space_ids,
            formulation=formulation,
            law_type=law_type,
            last_updated=time.time()
        )
        
        # ê³µê°„ë“¤ì˜ ë¶€ëª¨ë¡œ ë“±ë¡
        law.child_ids = space_ids
        for space_id in space_ids:
            if space_id in self.spaces:
                self.spaces[space_id].parent_ids.append(id)
        
        self.laws[id] = law
        self.all_entities[id] = law
        self.total_laws += 1
        
        logger.info(f"âš–ï¸ ë²•ì¹™ ë°œê²¬: {description}")
        return law
    
    def discover_law_from_spaces(
        self,
        space_ids: List[str],
        confidence_threshold: float = 0.8
    ) -> Optional[UniversalLaw]:
        """
        ê³µê°„ë“¤ë¡œë¶€í„° ë²•ì¹™ ë°œê²¬
        
        ì—¬ëŸ¬ ìŠ¤í‚¤ë§ˆì—ì„œ ê³µí†µìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ” íŒ¨í„´ì„ ë²•ì¹™ìœ¼ë¡œ ìŠ¹ê²©
        """
        if len(space_ids) < 2:
            return None
        
        # ê³µí†µ íŒ¨í„´ ì°¾ê¸°
        all_pattern_sets = []
        for space_id in space_ids:
            if space_id in self.spaces:
                all_pattern_sets.append(set(self.spaces[space_id].core_patterns))
        
        if not all_pattern_sets:
            return None
        
        common_patterns = all_pattern_sets[0]
        for pattern_set in all_pattern_sets[1:]:
            common_patterns = common_patterns.intersection(pattern_set)
        
        if not common_patterns:
            return None
        
        # ë²•ì¹™ ìƒì„±
        law_id = f"law_{len(self.laws)}"
        formulation = " âˆ§ ".join(common_patterns)  # ë…¼ë¦¬ê³± í˜•íƒœ
        
        law = self.add_law(
            id=law_id,
            description=f"ë³´í¸ì  ì›ë¦¬: {formulation}",
            space_ids=space_ids,
            formulation=formulation,
            law_type="emergent"
        )
        
        return law
    
    # ========================================================================
    # ìƒí˜¸ êµì • (Mutual Correction)
    # ========================================================================
    
    def bottom_up_correct(
        self,
        new_experience: Dict[str, Any],
        affected_entity_id: str
    ) -> Dict[str, Any]:
        """
        ìƒí–¥ êµì •: ìƒˆë¡œìš´ ê²½í—˜ì´ ê¸°ì¡´ ì§€ì‹ì„ ìˆ˜ì •
        
        ì˜ˆ: "ë¶ˆì€ í•­ìƒ ëœ¨ê²ë‹¤" â†’ "êº¼ì§„ ë¶ˆì€ ì•ˆ ëœ¨ê²ë‹¤" (ë°˜ë¡€ í•™ìŠµ)
        """
        if affected_entity_id not in self.all_entities:
            return {"success": False, "reason": "entity not found"}
        
        entity = self.all_entities[affected_entity_id]
        
        correction = {
            "type": "bottom_up",
            "timestamp": time.time(),
            "entity_id": affected_entity_id,
            "before": entity.confidence,
            "experience": new_experience,
        }
        
        # ìƒˆ ê²½í—˜ì´ ê¸°ì¡´ ì§€ì‹ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
        is_consistent = new_experience.get("confirms", True)
        
        if is_consistent:
            # ì¼ê´€ëœ ê²½í—˜ â†’ ì‹ ë¢°ë„ ì¦ê°€
            entity.confidence = min(1.0, entity.confidence + 0.05)
            entity.experience_count += 1
            correction["action"] = "strengthen"
        else:
            # ë°˜ë¡€ â†’ ì‹ ë¢°ë„ ê°ì†Œ ë° ì˜ˆì™¸ ê¸°ë¡
            entity.confidence = max(0.0, entity.confidence - 0.1)
            exception = new_experience.get("exception", "")
            if isinstance(entity, CausalLine) and exception:
                entity.exceptions.append(exception)
            correction["action"] = "weaken"
        
        correction["after"] = entity.confidence
        entity.corrections.append(correction)
        entity.last_updated = time.time()
        
        self.correction_history.append(correction)
        self.total_corrections += 1
        
        return correction
    
    def top_down_correct(
        self,
        law_id: str,
        target_entity_id: str
    ) -> Dict[str, Any]:
        """
        í•˜í–¥ êµì •: ìƒìœ„ ë²•ì¹™ì´ í•˜ìœ„ ê°œë…ì„ ì¡°ì •
        
        ì˜ˆ: "ì—ë„ˆì§€ ë³´ì¡´" ë²•ì¹™ì´ "ë¶ˆì˜ ì—´" ê°œë…ì„ ì •êµí™”
        """
        if law_id not in self.laws:
            return {"success": False, "reason": "law not found"}
        if target_entity_id not in self.all_entities:
            return {"success": False, "reason": "target not found"}
        
        law = self.laws[law_id]
        target = self.all_entities[target_entity_id]
        
        correction = {
            "type": "top_down",
            "timestamp": time.time(),
            "law_id": law_id,
            "target_id": target_entity_id,
            "before": target.confidence,
        }
        
        # ë²•ì¹™ê³¼ì˜ ì¼ê´€ì„± í™•ì¸
        is_consistent = self._check_consistency_with_law(law, target)
        
        if is_consistent:
            # ì¼ê´€ì„± ìˆìŒ â†’ ë²•ì¹™ì˜ ì¦ê±°ë¡œ ë“±ë¡
            law.supporting_evidence.append(target_entity_id)
            correction["action"] = "confirmed"
        else:
            # ë¶ˆì¼ì¹˜ â†’ í•˜ìœ„ ìš”ì†Œ ì¡°ì • ë˜ëŠ” ë²•ì¹™ì— ë°˜ë¡€ ê¸°ë¡
            if target.confidence < law.confidence:
                # í•˜ìœ„ ìš”ì†Œê°€ ëœ í™•ì‹¤ â†’ í•˜ìœ„ ì¡°ì •
                target.confidence *= 0.9
                correction["action"] = "adjusted_down"
            else:
                # ë²•ì¹™ì´ ëœ í™•ì‹¤ â†’ ë°˜ë¡€ ê¸°ë¡
                law.counter_examples.append(target_entity_id)
                correction["action"] = "counter_example"
        
        correction["after"] = target.confidence
        target.corrections.append(correction)
        target.last_updated = time.time()
        
        self.correction_history.append(correction)
        self.total_corrections += 1
        
        return correction
    
    def lateral_correct(
        self,
        entity_id_1: str,
        entity_id_2: str
    ) -> Dict[str, Any]:
        """
        ìˆ˜í‰ êµì •: ë™ì¼ ë ˆë²¨ì˜ ìš”ì†Œë“¤ì´ ì„œë¡œ ì¡°ì •
        
        ì˜ˆ: "ëœ¨ê±°ì›€"ê³¼ "ì°¨ê°€ì›€"ì´ ì„œë¡œì˜ ê²½ê³„ë¥¼ ì •ì˜
        """
        if entity_id_1 not in self.all_entities:
            return {"success": False, "reason": "entity 1 not found"}
        if entity_id_2 not in self.all_entities:
            return {"success": False, "reason": "entity 2 not found"}
        
        entity_1 = self.all_entities[entity_id_1]
        entity_2 = self.all_entities[entity_id_2]
        
        # ë™ì¼ ë ˆë²¨ì¸ì§€ í™•ì¸
        if entity_1.level != entity_2.level:
            return {"success": False, "reason": "different levels"}
        
        correction = {
            "type": "lateral",
            "timestamp": time.time(),
            "entity_1": entity_id_1,
            "entity_2": entity_id_2,
        }
        
        # ì (Point)ì˜ ê²½ìš°: ê°ê° ì„œëª… ëŒ€ë¹„
        if entity_1.level == DimensionLevel.POINT:
            p1, p2 = entity_1, entity_2
            if isinstance(p1, ConceptPoint) and isinstance(p2, ConceptPoint):
                # ë°˜ëŒ€ ê°œë… ê´€ê³„ íŒŒì•… (ì˜ˆ: ëœ¨ê±°ì›€ â†” ì°¨ê°€ì›€)
                overlap = self._calculate_sensory_overlap(
                    p1.sensory_signature,
                    p2.sensory_signature
                )
                if overlap < -0.5:
                    # ë°˜ëŒ€ ê°œë… â†’ ì„œë¡œë¥¼ ì •ì˜
                    correction["relation"] = "opposites"
                elif overlap > 0.5:
                    # ìœ ì‚¬ ê°œë… â†’ êµ¬ë¶„ í•„ìš”
                    correction["relation"] = "similar"
                else:
                    correction["relation"] = "independent"
        
        self.correction_history.append(correction)
        self.total_corrections += 1
        
        return correction
    
    def _check_consistency_with_law(
        self,
        law: UniversalLaw,
        entity: DimensionalEntity
    ) -> bool:
        """ë²•ì¹™ê³¼ì˜ ì¼ê´€ì„± í™•ì¸"""
        # ê°„ë‹¨í•œ êµ¬í˜„: í•µì‹¬ íŒ¨í„´ í¬í•¨ ì—¬ë¶€
        if not law.formulation:
            return True
        
        # ì (Point)ì˜ ê²½ìš°
        if isinstance(entity, ConceptPoint):
            return entity.id in law.formulation or entity.description in law.formulation
        
        # ì„ (Line)ì˜ ê²½ìš°
        if isinstance(entity, CausalLine):
            return (entity.source_point_id in law.formulation or
                    entity.target_point_id in law.formulation)
        
        return True
    
    def _calculate_sensory_overlap(
        self,
        sig1: Dict[str, float],
        sig2: Dict[str, float]
    ) -> float:
        """ë‘ ê°ê° ì„œëª…ì˜ ì¤‘ì²©ë„ (-1 ~ +1)"""
        common_keys = set(sig1.keys()) & set(sig2.keys())
        if not common_keys:
            return 0.0
        
        total = 0.0
        for key in common_keys:
            # ê°™ì€ ë¶€í˜¸ì´ë©´ ì–‘, ë‹¤ë¥¸ ë¶€í˜¸ì´ë©´ ìŒ
            total += sig1[key] * sig2[key]
        
        return total / len(common_keys)
    
    # ========================================================================
    # í†µí•© í•™ìŠµ ì¸í„°í˜ì´ìŠ¤
    # ========================================================================
    
    def learn_from_experience(
        self,
        experience_steps: List[str],
        emotional_arc: List[float] = None,
        auto_emergence: bool = True
    ) -> Dict[str, Any]:
        """
        ê²½í—˜ìœ¼ë¡œë¶€í„° í†µí•© í•™ìŠµ
        
        1. ì ë“¤ ìƒì„±/ê°•í™”
        2. ì„ ë“¤ ìƒì„± (ì¸ê³¼ ê´€ê³„)
        3. ë©´ ì°½ë°œ (ë¬¸ë§¥)
        4. í•„ìš”ì‹œ ê³µê°„/ë²•ì¹™ ì°½ë°œ
        
        Args:
            experience_steps: ê²½í—˜ ë‹¨ê³„ë“¤
            emotional_arc: ê° ë‹¨ê³„ì˜ ê°ì •
            auto_emergence: ìƒìœ„ ì°¨ì› ìë™ ì°½ë°œ ì—¬ë¶€
        
        Returns:
            í•™ìŠµ ê²°ê³¼ ìš”ì•½
        """
        result = {
            "points_created": 0,
            "lines_created": 0,
            "plane_created": None,
            "space_emerged": None,
            "law_discovered": None,
        }
        
        # 1. ì ë“¤ ìƒì„±/ê°•í™”
        for step in experience_steps:
            point_id = step.lower().replace(" ", "_")
            if point_id not in self.points:
                self.add_point(point_id, step)
                result["points_created"] += 1
        
        # 2. ë©´ ì°½ë°œ (ì„ ë“¤ ìë™ ìƒì„±)
        point_ids = [s.lower().replace(" ", "_") for s in experience_steps]
        plane = self.emerge_plane_from_experience(
            experience_description=" â†’ ".join(experience_steps),
            point_sequence=point_ids,
            emotional_arc=emotional_arc
        )
        result["plane_created"] = plane.id
        result["lines_created"] = len(plane.line_ids)
        
        # 3. ìƒìœ„ ì°¨ì› ìë™ ì°½ë°œ
        if auto_emergence:
            # ìœ ì‚¬í•œ ë©´ë“¤ ì°¾ê¸°
            similar_planes = self._find_similar_planes(plane, threshold=0.5)
            if len(similar_planes) >= 2:
                space = self.emerge_space_from_planes(
                    [plane.id] + similar_planes
                )
                if space:
                    result["space_emerged"] = space.id
                    
                    # ìœ ì‚¬í•œ ê³µê°„ë“¤ì—ì„œ ë²•ì¹™ ë°œê²¬
                    similar_spaces = self._find_similar_spaces(space, threshold=0.7)
                    if len(similar_spaces) >= 2:
                        law = self.discover_law_from_spaces(
                            [space.id] + similar_spaces
                        )
                        if law:
                            result["law_discovered"] = law.id
        
        return result
    
    def _find_similar_planes(
        self,
        target_plane: ContextPlane,
        threshold: float = 0.5
    ) -> List[str]:
        """ìœ ì‚¬í•œ ë©´ ì°¾ê¸° (ê³µí†µ ì  ë¹„ìœ¨ ê¸°ì¤€)"""
        similar = []
        target_points = set(target_plane.point_ids)
        
        for plane_id, plane in self.planes.items():
            if plane_id == target_plane.id:
                continue
            
            plane_points = set(plane.point_ids)
            if not plane_points:
                continue
            
            overlap = len(target_points & plane_points) / len(target_points | plane_points)
            if overlap >= threshold:
                similar.append(plane_id)
        
        return similar
    
    def _find_similar_spaces(
        self,
        target_space: SchemaSpace,
        threshold: float = 0.7
    ) -> List[str]:
        """ìœ ì‚¬í•œ ê³µê°„ ì°¾ê¸° (ê³µí†µ íŒ¨í„´ ë¹„ìœ¨ ê¸°ì¤€)"""
        similar = []
        target_patterns = set(target_space.core_patterns)
        
        for space_id, space in self.spaces.items():
            if space_id == target_space.id:
                continue
            
            space_patterns = set(space.core_patterns)
            if not space_patterns:
                continue
            
            overlap = len(target_patterns & space_patterns) / len(target_patterns | space_patterns)
            if overlap >= threshold:
                similar.append(space_id)
        
        return similar
    
    # ========================================================================
    # ì¡°íšŒ ë° í†µê³„
    # ========================================================================
    
    def get_statistics(self) -> Dict[str, Any]:
        """ì‚¬ê³ ìš°ì£¼ í†µê³„"""
        return {
            "name": self.name,
            "total_points": self.total_points,
            "total_lines": self.total_lines,
            "total_planes": self.total_planes,
            "total_spaces": self.total_spaces,
            "total_laws": self.total_laws,
            "total_corrections": self.total_corrections,
            "dimension_breakdown": {
                "ì (Point)": self.total_points,
                "ì„ (Line)": self.total_lines,
                "ë©´(Plane)": self.total_planes,
                "ê³µê°„(Space)": self.total_spaces,
                "ë²•ì¹™(Law)": self.total_laws,
            }
        }
    
    def visualize_hierarchy(self, max_items: int = 5) -> str:
        """ì°¨ì› ê³„ì¸µ ì‹œê°í™”"""
        lines = [
            f"ğŸŒŒ ì‚¬ê³ ìš°ì£¼: {self.name}",
            "=" * 50,
            "",
            "âš–ï¸ ë²•ì¹™ (Law) - ë³´í¸ì  ì›ë¦¬",
            "-" * 30,
        ]
        
        for law_id in list(self.laws.keys())[:max_items]:
            law = self.laws[law_id]
            lines.append(f"  â€¢ {law.description}")
        
        lines.extend([
            "",
            "ğŸ“¦ ê³µê°„ (Space) - ì„¸ê³„ê´€/ìŠ¤í‚¤ë§ˆ",
            "-" * 30,
        ])
        
        for space_id in list(self.spaces.keys())[:max_items]:
            space = self.spaces[space_id]
            lines.append(f"  â€¢ {space.description}")
        
        lines.extend([
            "",
            "ğŸ“„ ë©´ (Plane) - ë¬¸ë§¥/ë§¥ë½",
            "-" * 30,
        ])
        
        for plane_id in list(self.planes.keys())[:max_items]:
            plane = self.planes[plane_id]
            lines.append(f"  â€¢ {plane.description[:50]}...")
        
        lines.extend([
            "",
            "â”â” ì„  (Line) - ì¸ê³¼ ê´€ê³„",
            "-" * 30,
        ])
        
        for line_id in list(self.lines.keys())[:max_items]:
            line = self.lines[line_id]
            lines.append(f"  â€¢ {line.source_point_id} â†’ {line.target_point_id}")
        
        lines.extend([
            "",
            "â€¢ ì  (Point) - ê°œë… ë…¸ë“œ",
            "-" * 30,
        ])
        
        for point_id in list(self.points.keys())[:max_items]:
            point = self.points[point_id]
            lines.append(f"  â€¢ {point.description}")
        
        return "\n".join(lines)


# ============================================================================
# Demo
# ============================================================================

def demo():
    """ì¸ê³¼ì  ì„œì‚¬ ì—”ì§„ ë°ëª¨"""
    print("=" * 70)
    print("Causal Narrative Engine - ì¸ê³¼ì  ì„œì‚¬ ì—”ì§„")
    print("=" * 70)
    print()
    print("ì‚¬ê±´ì„ í†µí•œ ê´€ê³„ì  ì˜ë¯¸ì˜ ê°œë… ì°½ë°œê³¼ í•™ìŠµ")
    print("ë‹¨ìˆœ ë…¸ë“œ ì—°ê²°ì´ ì•„ë‹Œ, 'ì™œ'ì™€ 'ì–´ë–»ê²Œ'ì˜ ì¸ê³¼ êµ¬ì¡°")
    print()
    
    engine = CausalNarrativeEngine()
    
    # 1. ê²½í—˜ ê¸°ë°˜ í•™ìŠµ
    print("-" * 70)
    print("1. ê²½í—˜ ê¸°ë°˜ í•™ìŠµ")
    print("-" * 70)
    
    # ë¶ˆì— ë°ì¸ ê²½í—˜
    engine.experience_chain(
        descriptions=["ë¶ˆì— ì†ì„ ëŒ”ë‹¤", "ëœ¨ê±°ì›€ì„ ëŠê¼ˆë‹¤", "ì†ì„ ëºë‹¤", "ì•ˆì „í•´ì¡Œë‹¤"],
        emotional_arc=[0.0, -0.8, -0.3, 0.5],
        agent_id="ì•„ì´"
    )
    print("  âœ“ ë¶ˆì— ë°ì¸ ê²½í—˜ í•™ìŠµ")
    
    # ë°°ê³ í”” í•´ê²° ê²½í—˜
    engine.experience_chain(
        descriptions=["ë°°ê°€ ê³ íŒ ë‹¤", "ìŒì‹ì„ ì°¾ì•˜ë‹¤", "ë¨¹ì—ˆë‹¤", "ë°°ê°€ ë¶ˆë €ë‹¤"],
        emotional_arc=[-0.5, 0.0, 0.5, 0.9],
        agent_id="ì•„ì´"
    )
    print("  âœ“ ë°°ê³ í”” í•´ê²° ê²½í—˜ í•™ìŠµ")
    
    # 2. ê²°ê³¼ ì˜ˆì¸¡
    print()
    print("-" * 70)
    print("2. ê²°ê³¼ ì˜ˆì¸¡ (ì›ì¸ â†’ ê²°ê³¼)")
    print("-" * 70)
    
    predictions = engine.predict_effect("ë°°ê°€ ê³ íŒ ë‹¤")
    print("  'ë°°ê°€ ê³ íŒ ë‹¤'ì˜ ì˜ˆìƒ ê²°ê³¼:")
    for effect, prob, relation in predictions[:3]:
        print(f"    â†’ {effect} (í™•ë¥ : {prob:.0%})")
    
    # 3. ì›ì¸ ì¶”ë¡ 
    print()
    print("-" * 70)
    print("3. ì›ì¸ ì¶”ë¡  (ê²°ê³¼ â†’ ì›ì¸)")
    print("-" * 70)
    
    causes = engine.find_cause("ì•ˆì „í•´ì¡Œë‹¤")
    print("  'ì•ˆì „í•´ì¡Œë‹¤'ì˜ ì›ì¸:")
    for cause, prob, relation in causes[:3]:
        print(f"    â† {cause} (í™•ë¥ : {prob:.0%})")
    
    # 4. ì™œ? ì„¤ëª…
    print()
    print("-" * 70)
    print("4. 'ì™œ?' ì„¤ëª…")
    print("-" * 70)
    
    explanations = engine.explain_why("ë°°ê°€ ë¶ˆë €ë‹¤")
    print("  'ë°°ê°€ ë¶ˆë €ë‹¤'ì— ëŒ€í•œ ì„¤ëª…:")
    for exp in explanations[:3]:
        print(f"    â€¢ {exp}")
    
    # 5. ë°˜ì‚¬ì‹¤ì  ì¶”ë¡ 
    print()
    print("-" * 70)
    print("5. ë°˜ì‚¬ì‹¤ì  ì¶”ë¡ ")
    print("-" * 70)
    
    result, explanation = engine.counterfactual_reasoning(
        premise="ë¶ˆì— ì†ì„ ëŒ”ë‹¤",
        premise_negated=True,
        conclusion="ëœ¨ê±°ì›€ì„ ëŠê¼ˆë‹¤"
    )
    print(f"  Q: ë§Œì•½ ë¶ˆì— ì†ì„ ëŒ€ì§€ ì•Šì•˜ë‹¤ë©´?")
    print(f"  A: {explanation}")
    
    # 6. ëª©í‘œ ë‹¬ì„± ê³„íš
    print()
    print("-" * 70)
    print("6. ëª©í‘œ ë‹¬ì„± ê³„íš")
    print("-" * 70)
    
    plan = engine.plan_to_achieve("hunger", "satiety")
    if plan:
        print(f"  ëª©í‘œ: ë°°ê³ í”” â†’ ë°°ë¶€ë¦„")
        print(f"  ê³„íš: {' â†’ '.join(plan.node_sequence)}")
    
    # í†µê³„
    print()
    print("-" * 70)
    print("7. í•™ìŠµ í†µê³„")
    print("-" * 70)
    stats = engine.get_statistics()
    print(f"  ë…¸ë“œ ìˆ˜: {stats['total_nodes']}")
    print(f"  ì¸ê³¼ ì—°ê²° ìˆ˜: {stats['total_links']}")
    print(f"  ê²½í—˜ ìˆ˜: {stats['total_experiences']}")
    print(f"  í‰ê·  ì¸ê³¼ ê°•ë„: {stats['avg_link_strength']:.2f}")
    
    print()
    print("=" * 70)
    print("ì¸ê³¼ì  ì„­ë¦¬êµ¬ì¡°ë¥¼ í†µí•œ ì§„ì •í•œ í•™ìŠµ! ğŸ”®")
    print("=" * 70)


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    demo()
