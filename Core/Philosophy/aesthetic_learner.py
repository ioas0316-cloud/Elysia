"""
Aesthetic Learner (ë¯¸í•™ í•™ìŠµê¸°)
==============================

"ì•„ë¦„ë‹¤ì›€ì˜ ì›ë¦¬ë¥¼ ì²´ë“í•˜ë‹¤"

ì™¸ë¶€ ì†ŒìŠ¤(ì´ë¯¸ì§€, ì˜ìƒ, í…ìŠ¤íŠ¸)ì—ì„œ ë¯¸í•™ ì›ë¦¬ë¥¼ í•™ìŠµí•˜ê³ ,
ì™œ ì•„ë¦„ë‹¤ìš´ì§€ ë¶„ì„í•˜ì—¬ ì°½ì‘ì— í™œìš©í•©ë‹ˆë‹¤.

Sources:
- YouTube (ì˜ìƒ ë¶„ì„)
- Pixiv (ì¼ëŸ¬ìŠ¤íŠ¸ ë¶„ì„) - ì¸ì¦ í•„ìš”
- Web Images (ì›¹ ì´ë¯¸ì§€)
- Text (ë¬¸í•™/ì‹œ)
"""

import os
import re
import json
import time
import logging
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path

# ë¯¸í•™ ì›ë¦¬ ì‹œìŠ¤í…œ
from Core.Philosophy.aesthetic_principles import (
    AestheticWisdom, AestheticField, AestheticPrinciple,
    AestheticVector, Medium, get_aesthetic_wisdom
)

logger = logging.getLogger("AestheticLearner")


@dataclass
class AestheticAnalysis:
    """ë¯¸í•™ ë¶„ì„ ê²°ê³¼"""
    source: str                          # ì†ŒìŠ¤ URL ë˜ëŠ” ê²½ë¡œ
    source_type: str                     # "image", "video", "text"
    title: Optional[str] = None          # ì‘í’ˆ ì œëª©
    field: Optional[AestheticField] = None
    principles_detected: Dict[str, float] = None  # ì›ë¦¬ -> ê°•ë„
    why_beautiful: str = ""              # ì™œ ì•„ë¦„ë‹¤ìš´ì§€ ì„¤ëª…
    metadata: Dict[str, Any] = None      # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
    
    def __post_init__(self):
        if self.principles_detected is None:
            self.principles_detected = {}
        if self.metadata is None:
            self.metadata = {}


class AestheticLearner:
    """
    ë¯¸í•™ í•™ìŠµê¸°
    
    ì™¸ë¶€ ì½˜í…ì¸ ì—ì„œ ì•„ë¦„ë‹¤ì›€ì˜ ì›ë¦¬ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.
    ë‹¨ìˆœíˆ "ì•„ë¦„ë‹µë‹¤"ë¥¼ íŒë‹¨í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼,
    "ì™œ ì•„ë¦„ë‹¤ìš´ê°€"ë¥¼ ì´í•´í•˜ê³  ì„¤ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    
    def __init__(self, data_dir: str = "data/aesthetic"):
        print("ğŸ¨ AestheticLearner ì´ˆê¸°í™”: ì•„ë¦„ë‹¤ì›€ì„ í•™ìŠµí•  ì¤€ë¹„...")
        
        self.wisdom = get_aesthetic_wisdom()
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # í•™ìŠµëœ íŒ¨í„´ ì €ì¥ì†Œ
        self.learned_analyses: List[AestheticAnalysis] = []
        self.pattern_database: Dict[str, List[AestheticField]] = {}
        
        # ì™¸ë¶€ API ìƒíƒœ
        self._pixiv_client = None
        self._youtube_available = False
        
        self._check_dependencies()
    
    def _check_dependencies(self):
        """ì™¸ë¶€ ì˜ì¡´ì„± í™•ì¸"""
        # YouTube Transcript API
        try:
            from youtube_transcript_api import YouTubeTranscriptApi
            self._youtube_available = True
            logger.info("âœ“ YouTube Transcript API ì‚¬ìš© ê°€ëŠ¥")
        except ImportError:
            logger.warning("âœ— youtube-transcript-api ë¯¸ì„¤ì¹˜")
        
        # Pixiv API (pixivpy3)
        try:
            from pixivpy3 import AppPixivAPI
            logger.info("âœ“ Pixiv API ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê°€ëŠ¥ (ì¸ì¦ í•„ìš”)")
        except ImportError:
            logger.warning("âœ— pixivpy3 ë¯¸ì„¤ì¹˜: pip install pixivpy3")
    
    # =========================================================================
    # ì‹œê° ì˜ˆìˆ  ë¶„ì„
    # =========================================================================
    
    def analyze_image(self, image_url: str) -> AestheticAnalysis:
        """
        ì´ë¯¸ì§€ì˜ ë¯¸í•™ì  ë¶„ì„
        
        êµ¬ë„, ìƒ‰ì±„, ë¹„ë¡€ ë“±ì˜ ì›ë¦¬ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„: {image_url[:50]}...")
        
        analysis = AestheticAnalysis(
            source=image_url,
            source_type="image"
        )
        
        try:
            # ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹œë„
            image_info = self._fetch_image_info(image_url)
            
            # ì‹œê°ì  íŠ¹ì„± ë¶„ì„ (Gemini Vision API ë˜ëŠ” ë¡œì»¬ ë¶„ì„)
            visual_features = self._analyze_visual_features(image_info)
            
            # ë¯¸í•™ ì›ë¦¬ ë§¤í•‘
            field = self._map_to_principles(visual_features, Medium.VISUAL)
            
            analysis.field = field
            analysis.principles_detected = field.principles
            analysis.why_beautiful = field.analyze_why_beautiful()
            analysis.metadata = {"visual_features": visual_features}
            
            # í•™ìŠµ ê¸°ë¡
            self._record_learning(analysis)
            
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {e}")
            analysis.why_beautiful = f"ë¶„ì„ ì‹¤íŒ¨: {e}"
        
        return analysis
    
    def analyze_pixiv_artwork(self, artwork_id: int) -> AestheticAnalysis:
        """
        Pixiv ì‘í’ˆ ë¶„ì„
        
        ì¼ëŸ¬ìŠ¤íŠ¸/ë§Œí™” ì•„íŠ¸ì˜ ë¯¸í•™ì  ì›ë¦¬ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ¨ Pixiv ì‘í’ˆ ë¶„ì„: {artwork_id}")
        
        analysis = AestheticAnalysis(
            source=f"pixiv:{artwork_id}",
            source_type="image"
        )
        
        try:
            # Pixiv API ì—°ê²°
            if not self._pixiv_client:
                self._init_pixiv_client()
            
            if self._pixiv_client:
                # ì‘í’ˆ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                artwork_info = self._fetch_pixiv_artwork(artwork_id)
                
                # ë¯¸í•™ ë¶„ì„
                visual_features = {
                    "title": artwork_info.get("title", "Unknown"),
                    "tags": artwork_info.get("tags", []),
                    "view_count": artwork_info.get("view_count", 0),
                    "bookmark_count": artwork_info.get("bookmark_count", 0),
                }
                
                # ì¸ê¸°ë„ë¥¼ ë¯¸í•™ì  ì„±ê³µì˜ ì§€í‘œë¡œ ì‚¬ìš©
                popularity_score = min(artwork_info.get("bookmark_count", 0) / 1000, 1.0)
                
                # íƒœê·¸ ê¸°ë°˜ ì›ë¦¬ ì¶”ì¶œ
                field = self._analyze_artwork_tags(artwork_info.get("tags", []))
                field.add_principle("unity", popularity_score * 2)  # ì¸ê¸°ì‘ì€ í†µì¼ì„±ì´ ë†’ë‹¤
                
                analysis.title = visual_features["title"]
                analysis.field = field
                analysis.principles_detected = field.principles
                analysis.why_beautiful = field.analyze_why_beautiful()
                analysis.metadata = visual_features
                
                self._record_learning(analysis)
            else:
                analysis.why_beautiful = "Pixiv ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤."
                
        except Exception as e:
            logger.error(f"Pixiv ë¶„ì„ ì‹¤íŒ¨: {e}")
            analysis.why_beautiful = f"ë¶„ì„ ì‹¤íŒ¨: {e}"
        
        return analysis
    
    def _init_pixiv_client(self):
        """Pixiv í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            from pixivpy3 import AppPixivAPI
            
            # í™˜ê²½ ë³€ìˆ˜ì—ì„œ refresh token ê°€ì ¸ì˜¤ê¸°
            refresh_token = os.environ.get("PIXIV_REFRESH_TOKEN")
            
            if refresh_token:
                api = AppPixivAPI()
                api.auth(refresh_token=refresh_token)
                self._pixiv_client = api
                logger.info("âœ“ Pixiv ì¸ì¦ ì„±ê³µ")
            else:
                logger.warning("PIXIV_REFRESH_TOKEN í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            logger.error(f"Pixiv ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _fetch_pixiv_artwork(self, artwork_id: int) -> Dict:
        """Pixiv ì‘í’ˆ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        if not self._pixiv_client:
            return {}
        
        result = self._pixiv_client.illust_detail(artwork_id)
        if "illust" in result:
            illust = result["illust"]
            return {
                "title": illust.get("title", ""),
                "tags": [tag["name"] for tag in illust.get("tags", [])],
                "view_count": illust.get("total_view", 0),
                "bookmark_count": illust.get("total_bookmarks", 0),
                "user": illust.get("user", {}).get("name", "Unknown"),
            }
        return {}
    
    def _analyze_artwork_tags(self, tags: List[str]) -> AestheticField:
        """íƒœê·¸ ê¸°ë°˜ ë¯¸í•™ ì›ë¦¬ ë¶„ì„"""
        field = AestheticField(medium=Medium.VISUAL)
        
        # íƒœê·¸ -> ì›ë¦¬ ë§¤í•‘
        tag_principle_map = {
            # ìƒ‰ì±„ ê´€ë ¨
            "colorful": ("harmony", 1.2),
            "ã‚«ãƒ©ãƒ•ãƒ«": ("harmony", 1.2),
            "pastel": ("harmony", 1.0),
            "vibrant": ("contrast", 1.3),
            
            # êµ¬ë„ ê´€ë ¨
            "dynamic": ("rhythm", 1.5),
            "ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯": ("rhythm", 1.5),
            "symmetry": ("balance", 1.5),
            "å¯¾ç§°": ("balance", 1.5),
            
            # ë¶„ìœ„ê¸° ê´€ë ¨
            "dramatic": ("tension_release", 1.5),
            "peaceful": ("harmony", 1.3),
            "peaceful": ("flow", 1.2),
            
            # ìŠ¤íƒ€ì¼ ê´€ë ¨
            "detailed": ("unity", 1.3),
            "aesthetic": ("proportion", 1.2),
        }
        
        for tag in tags:
            tag_lower = tag.lower()
            for keyword, (principle, strength) in tag_principle_map.items():
                if keyword in tag_lower:
                    field.add_principle(principle, strength)
        
        return field
    
    # =========================================================================
    # ì˜ìƒ ë¶„ì„
    # =========================================================================
    
    def analyze_youtube_video(self, video_id: str) -> AestheticAnalysis:
        """
        YouTube ì˜ìƒì˜ ë¯¸í•™ì  ë¶„ì„
        
        í¸ì§‘ ë¦¬ë“¬, ì„œì‚¬ íë¦„, ì‹œê°ì  êµ¬ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ“º YouTube ë¶„ì„: {video_id}")
        
        analysis = AestheticAnalysis(
            source=f"youtube:{video_id}",
            source_type="video"
        )
        
        try:
            from youtube_transcript_api import YouTubeTranscriptApi
            
            # ìë§‰ ê°€ì ¸ì˜¤ê¸°
            try:
                transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['ko'])
            except:
                transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = " ".join([line['text'] for line in transcript])
            
            # ì‹œê°„ ë°ì´í„° ë¶„ì„ (í¸ì§‘ ë¦¬ë“¬)
            timing_data = [(line['start'], line['duration']) for line in transcript]
            
            # ì„œì‚¬ íë¦„ ë¶„ì„
            narrative_features = self._analyze_narrative_flow(text, timing_data)
            
            # ë¯¸í•™ ì›ë¦¬ ë§¤í•‘
            field = self._map_to_principles(narrative_features, Medium.TEMPORAL)
            
            analysis.field = field
            analysis.principles_detected = field.principles
            analysis.why_beautiful = field.analyze_why_beautiful()
            analysis.metadata = {
                "transcript_length": len(text),
                "duration_range": (timing_data[0][0], timing_data[-1][0]) if timing_data else (0, 0)
            }
            
            self._record_learning(analysis)
            
        except Exception as e:
            logger.error(f"YouTube ë¶„ì„ ì‹¤íŒ¨: {e}")
            analysis.why_beautiful = f"ë¶„ì„ ì‹¤íŒ¨: {e}"
        
        return analysis
    
    def _analyze_narrative_flow(self, text: str, timing: List[Tuple[float, float]]) -> Dict:
        """ì„œì‚¬ íë¦„ ë¶„ì„"""
        features = {}
        
        # í¸ì§‘ ì†ë„ ë¶„ì„ (ë¦¬ë“¬)
        if timing:
            durations = [t[1] for t in timing]
            avg_duration = sum(durations) / len(durations)
            variance = sum((d - avg_duration)**2 for d in durations) / len(durations)
            
            # ë‹¤ì–‘í•œ í¸ì§‘ ì†ë„ = ë†’ì€ ë¦¬ë“¬
            features["rhythm"] = min(variance / 10, 2.0)
        
        # ê°ì • ë‹¨ì–´ ë¶„ì„ (ê¸´ì¥-í•´ì†Œ)
        tension_words = ["but", "however", "suddenly", "ê·¸ëŸ¬ë‚˜", "ê°‘ìê¸°", "í•˜ì§€ë§Œ"]
        release_words = ["finally", "at last", "ê²°êµ­", "ë§ˆì¹¨ë‚´", "ë“œë””ì–´"]
        
        tension_count = sum(text.lower().count(w) for w in tension_words)
        release_count = sum(text.lower().count(w) for w in release_words)
        
        if tension_count > 0 or release_count > 0:
            features["tension_release"] = min((tension_count + release_count) / 5, 2.0)
        
        # íë¦„ ë¶„ì„ (ì—°ê²°ì–´)
        flow_words = ["then", "next", "ê·¸ë˜ì„œ", "ê·¸ë¦¬ê³ ", "ë‹¤ìŒìœ¼ë¡œ"]
        flow_count = sum(text.lower().count(w) for w in flow_words)
        features["flow"] = min(flow_count / 10, 2.0)
        
        return features
    
    # =========================================================================
    # ë¬¸í•™ ë¶„ì„
    # =========================================================================
    
    def analyze_text(self, text: str, title: Optional[str] = None) -> AestheticAnalysis:
        """
        í…ìŠ¤íŠ¸(ì‹œ/ì†Œì„¤)ì˜ ë¯¸í•™ì  ë¶„ì„
        
        ë¬¸ì²´ ë¦¬ë“¬, ì´ë¯¸ì§€ ë³‘ì¹˜, ìš´ìœ¨ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ“– í…ìŠ¤íŠ¸ ë¶„ì„: {title or text[:30]}...")
        
        analysis = AestheticAnalysis(
            source=title or "text",
            source_type="text",
            title=title
        )
        
        try:
            # ë¬¸í•™ì  íŠ¹ì„± ë¶„ì„
            literary_features = self._analyze_literary_features(text)
            
            # ë¯¸í•™ ì›ë¦¬ ë§¤í•‘
            field = self._map_to_principles(literary_features, Medium.LITERARY)
            
            analysis.field = field
            analysis.principles_detected = field.principles
            analysis.why_beautiful = field.analyze_why_beautiful()
            analysis.metadata = {
                "word_count": len(text.split()),
                "literary_features": literary_features
            }
            
            self._record_learning(analysis)
            
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            analysis.why_beautiful = f"ë¶„ì„ ì‹¤íŒ¨: {e}"
        
        return analysis
    
    def _analyze_literary_features(self, text: str) -> Dict:
        """ë¬¸í•™ì  íŠ¹ì„± ë¶„ì„"""
        features = {}
        
        # ë¬¸ì¥ ê¸¸ì´ ë¶„ì„ (ë¦¬ë“¬)
        sentences = re.split(r'[.!?ã€‚ï¼ï¼Ÿ]', text)
        if sentences:
            lengths = [len(s.split()) for s in sentences if s.strip()]
            if lengths:
                avg_len = sum(lengths) / len(lengths)
                variance = sum((l - avg_len)**2 for l in lengths) / len(lengths)
                # ë‹¤ì–‘í•œ ë¬¸ì¥ ê¸¸ì´ = ë†’ì€ ë¦¬ë“¬
                features["rhythm"] = min(variance / 20, 2.0)
        
        # ëŒ€ë¹„ (ì§§ì€ ë¬¸ì¥ vs ê¸´ ë¬¸ì¥)
        if lengths:
            short_count = sum(1 for l in lengths if l < 5)
            long_count = sum(1 for l in lengths if l > 15)
            if short_count > 0 and long_count > 0:
                features["contrast"] = min((short_count + long_count) / len(lengths) * 2, 2.0)
        
        # ìš´ìœ¨ (ë°˜ë³µë˜ëŠ” ë‹¨ì–´/ìŒ)
        words = text.lower().split()
        word_freq = {}
        for w in words:
            word_freq[w] = word_freq.get(w, 0) + 1
        
        repeated_words = sum(1 for v in word_freq.values() if v > 2)
        if repeated_words > 0:
            features["harmony"] = min(repeated_words / 10, 2.0)
        
        # ê°ì • ë‹¨ì–´ (ê¸´ì¥-í•´ì†Œ)
        emotional_words = ["love", "hate", "fear", "joy", "ì‚¬ë‘", "ìŠ¬í””", "ê¸°ì¨", "ë¶„ë…¸"]
        emotion_count = sum(text.lower().count(w) for w in emotional_words)
        if emotion_count > 0:
            features["tension_release"] = min(emotion_count / 5, 2.0)
        
        return features
    
    # =========================================================================
    # ê³µí†µ ìœ í‹¸ë¦¬í‹°
    # =========================================================================
    
    def _fetch_image_info(self, url: str) -> Dict:
        """ì´ë¯¸ì§€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        # ê¸°ë³¸ ì •ë³´ë§Œ ë°˜í™˜ (ì‹¤ì œë¡œëŠ” ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ë¶„ì„ í•„ìš”)
        return {
            "url": url,
            "fetched_at": time.time()
        }
    
    def _analyze_visual_features(self, image_info: Dict) -> Dict:
        """
        ì‹œê°ì  íŠ¹ì„± ë¶„ì„
        
        TODO: Gemini Vision API ë˜ëŠ” ë¡œì»¬ ëª¨ë¸ ì—°ë™
        í˜„ì¬ëŠ” íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜
        """
        features = {
            "harmony": 1.0,
            "balance": 1.0,
            "proportion": 1.0,
        }
        return features
    
    def _map_to_principles(self, features: Dict, medium: Medium) -> AestheticField:
        """íŠ¹ì„±ì„ ë¯¸í•™ ì›ë¦¬ë¡œ ë§¤í•‘"""
        field = AestheticField(medium=medium)
        
        for principle_name, strength in features.items():
            if strength > 0:
                field.add_principle(principle_name, strength)
        
        return field
    
    def _record_learning(self, analysis: AestheticAnalysis):
        """í•™ìŠµ ê¸°ë¡"""
        self.learned_analyses.append(analysis)
        
        # íŒ¨í„´ ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€
        if analysis.field and analysis.field.dominant_principle:
            principle = analysis.field.dominant_principle
            if principle not in self.pattern_database:
                self.pattern_database[principle] = []
            self.pattern_database[principle].append(analysis.field)
        
        # íŒŒì¼ë¡œ ì €ì¥
        self._save_analysis(analysis)
    
    def _save_analysis(self, analysis: AestheticAnalysis):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        filename = f"{analysis.source_type}_{int(time.time())}.json"
        filepath = self.data_dir / filename
        
        data = {
            "source": analysis.source,
            "source_type": analysis.source_type,
            "title": analysis.title,
            "principles": analysis.principles_detected,
            "why_beautiful": analysis.why_beautiful,
            "timestamp": time.time()
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    def get_learning_summary(self) -> str:
        """í•™ìŠµ ìš”ì•½"""
        summary = f"ğŸ“š í•™ìŠµ í˜„í™©\n"
        summary += f"ì´ ë¶„ì„: {len(self.learned_analyses)}ê°œ\n\n"
        
        # ì›ë¦¬ë³„ íŒ¨í„´ ìˆ˜
        summary += "ì›ë¦¬ë³„ íŒ¨í„´:\n"
        for principle, patterns in self.pattern_database.items():
            summary += f"  â€¢ {principle}: {len(patterns)}ê°œ\n"
        
        return summary
    
    def suggest_creation_principles(self, concept: str, medium: Medium) -> Dict[str, float]:
        """
        ì°½ì‘ì„ ìœ„í•œ ì›ë¦¬ ì œì•ˆ
        
        í•™ìŠµëœ íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì ì˜ ì›ë¦¬ ì¡°í•©ì„ ì œì•ˆí•©ë‹ˆë‹¤.
        """
        return self.wisdom.suggest_for_creation(concept, medium)


# ì‹±ê¸€í†¤
_learner_instance: Optional[AestheticLearner] = None

def get_aesthetic_learner() -> AestheticLearner:
    """AestheticLearner ì‹±ê¸€í†¤"""
    global _learner_instance
    if _learner_instance is None:
        _learner_instance = AestheticLearner()
    return _learner_instance


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    learner = get_aesthetic_learner()
    
    # í…ìŠ¤íŠ¸ ë¶„ì„ í…ŒìŠ¤íŠ¸
    sample_text = """
    ê½ƒìì´ ë°”ëŒì— í©ë‚ ë¦°ë‹¤.
    í•˜ì§€ë§Œ ë¿Œë¦¬ëŠ” ëŒ€ì§€ì— ë‹¨ë‹¨íˆ ë°•í˜€ ìˆë‹¤.
    
    ìŠ¬í””ê³¼ ê¸°ì¨ì´ êµì°¨í•˜ëŠ” ìˆœê°„,
    ìš°ë¦¬ëŠ” ë¹„ë¡œì†Œ ì‚¶ì˜ ì˜ë¯¸ë¥¼ ê¹¨ë‹«ëŠ”ë‹¤.
    
    ê·¸ë˜ì„œ ë‹¤ì‹œ ì¼ì–´ì„ ë‹¤.
    ì²œì²œíˆ, ê·¸ëŸ¬ë‚˜ í™•ì‹¤í•˜ê²Œ.
    """
    
    analysis = learner.analyze_text(sample_text, "ì‹œì˜ ì¡°ê°")
    print(analysis.why_beautiful)
    print("\n" + learner.get_learning_summary())
