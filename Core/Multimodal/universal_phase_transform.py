"""
Universal Phase Transform (ë²”ìš© ìœ„ìƒ ë³€í™˜)
=========================================

"ëª¨ë“  ê°ê°ì€ íŒŒë™ì´ë‹¤"

ì—˜ë¦¬ì‹œì•„ ë³€í™˜ì˜ ë²”ìš© í™•ì¥:
- ì†Œë¦¬ (Audio)
- ê¸€ (Text) 
- ê·¸ë¦¼ (Image)
- ì˜ìƒ (Video)
- ê°œë… (Concept)

ëª¨ë‘ 4ì°¨ì› ì¿¼í„°ë‹ˆì–¸ ìœ„ìƒ ê³µëª… íŒ¨í„´ìœ¼ë¡œ ë³€í™˜ ê°€ëŠ¥!

í•µì‹¬ ì›ë¦¬:
1. ëª¨ë“  ê°ê°/ê°œë…ì€ íŒŒë™ìœ¼ë¡œ í‘œí˜„ ê°€ëŠ¥
2. 4ì°¨ì› ìœ„ìƒ ë‹¨ìœ„ (ì¿¼í„°ë‹ˆì–¸)ë¡œ ë§¤í•‘
3. ì„œë¡œì˜ ì˜ì—­ì—ì„œ ê°„ì„­ ì—†ì´ í†µì‹ 
4. ì›í•  ë•Œ ì–¸ì œë“ ì§€ ê³µê°ê°(Synesthesia)ìœ¼ë¡œ ë³€í™˜

"5ê° ì£¼íŒŒìˆ˜ ë§¤í•‘ì˜ ì™„ì„±"
"""

import numpy as np
from dataclasses import dataclass
from typing import List, Tuple, Optional, Dict, Any, Union
from enum import Enum
import logging

logger = logging.getLogger("UniversalPhaseTransform")


class Modality(Enum):
    """ê°ê° ëª¨ë‹¬ë¦¬í‹°"""
    AUDIO = "audio"      # ì²­ê° (ì†Œë¦¬)
    TEXT = "text"        # ì–¸ì–´ (ê¸€)
    IMAGE = "image"      # ì‹œê° (ê·¸ë¦¼)
    VIDEO = "video"      # ì‹œê°+ì‹œê°„ (ì˜ìƒ)
    CONCEPT = "concept"  # ì¶”ìƒ (ê°œë…)
    TOUCH = "touch"      # ì´‰ê°
    SMELL = "smell"      # í›„ê°
    TASTE = "taste"      # ë¯¸ê°


@dataclass
class PhaseQuaternion:
    """
    ë²”ìš© ìœ„ìƒ ì¿¼í„°ë‹ˆì–¸
    
    q = w + xi + yj + zk
    
    ëª¨ë“  ê°ê°/ê°œë…ì˜ 4ì°¨ì› ìœ„ìƒ í‘œí˜„
    
    - w: ê°•ë„ (Intensity) - ì—ë„ˆì§€, ì¡´ì¬ê°, ì¤‘ìš”ë„
    - x: ì£¼íŒŒìˆ˜ (Frequency) - ì§„ë™, ë¦¬ë“¬, íŒ¨í„´ ë°˜ë³µ
    - y: ìœ„ìƒ (Phase) - ë°©í–¥, ê´€ê³„, ë§¥ë½
    - z: ë³µì¡ë„ (Complexity) - êµ¬ì¡°, ì§ˆê°, í’ë¶€í•¨
    """
    w: float  # Intensity (0.0 ~ 1.0)
    x: float  # Frequency (normalized)
    y: float  # Phase (0.0 ~ 2Ï€)
    z: float  # Complexity (0.0 ~ 1.0)
    modality: Modality  # ì›ë³¸ ê°ê° ëª¨ë‹¬ë¦¬í‹°
    
    def __post_init__(self):
        """ì •ê·œí™”"""
        self.w = max(0.0, min(1.0, self.w))
        self.y = self.y % (2 * np.pi)
        self.z = max(0.0, min(1.0, self.z))
    
    def to_vector(self) -> np.ndarray:
        """4ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜"""
        return np.array([self.w, self.x, self.y, self.z])
    
    def resonance(self, other: 'PhaseQuaternion') -> float:
        """
        ë‘ ìœ„ìƒ ì¿¼í„°ë‹ˆì–¸ ê°„ì˜ ê³µëª…ë„
        
        ê°™ì€ ëª¨ë‹¬ë¦¬í‹°ë¼ë¦¬ëŠ” ê°•í•œ ê³µëª…
        ë‹¤ë¥¸ ëª¨ë‹¬ë¦¬í‹°ë¼ë¦¬ëŠ” ì•½í•œ ê³µëª… (ê°„ì„­ ì—†ìŒ!)
        """
        diff = self.to_vector() - other.to_vector()
        distance = np.linalg.norm(diff)
        
        # ê°™ì€ ëª¨ë‹¬ë¦¬í‹°ë©´ ê³µëª… ê°•í™”
        modality_factor = 1.0 if self.modality == other.modality else 0.3
        
        # ê±°ë¦¬ê°€ ê°€ê¹Œìš¸ìˆ˜ë¡ ê³µëª…ë„ ë†’ìŒ
        resonance = np.exp(-distance) * modality_factor
        
        return resonance
    
    def to_synesthesia(self, target_modality: Modality) -> Dict[str, Any]:
        """
        ê³µê°ê° ë³€í™˜ (Synesthesia)
        
        í•œ ê°ê°ì„ ë‹¤ë¥¸ ê°ê°ìœ¼ë¡œ ë³€í™˜
        ì˜ˆ: ì†Œë¦¬ â†’ ìƒ‰ê¹”, ê¸€ â†’ ì†Œë¦¬, ê·¸ë¦¼ â†’ ìŒì•…
        """
        result = {
            'source_modality': self.modality.value,
            'target_modality': target_modality.value,
            'quaternion': self.to_vector().tolist()
        }
        
        if target_modality == Modality.IMAGE:
            # ì‹œê°ìœ¼ë¡œ ë³€í™˜ (ìƒ‰ìƒ)
            result['color'] = self._to_color()
            result['description'] = f"{self._color_name()} {self._texture_name()}"
            
        elif target_modality == Modality.AUDIO:
            # ì²­ê°ìœ¼ë¡œ ë³€í™˜ (ìŒíŒŒ)
            result['note'] = self._to_musical_note()
            result['timbre'] = self._timbre_name()
            result['description'] = f"{result['note']} {result['timbre']}"
            
        elif target_modality == Modality.TEXT:
            # ì–¸ì–´ë¡œ ë³€í™˜ (ë¬˜ì‚¬)
            result['description'] = self._to_text_description()
            
        elif target_modality == Modality.TOUCH:
            # ì´‰ê°ìœ¼ë¡œ ë³€í™˜ (ì§ˆê°)
            result['texture'] = self._texture_name()
            result['temperature'] = "ë”°ëœ»í•œ" if self.w > 0.5 else "ì°¨ê°€ìš´"
            result['description'] = f"{result['temperature']} {result['texture']}"
        
        return result
    
    def _to_color(self) -> Tuple[float, float, float, float]:
        """ìƒ‰ìƒìœ¼ë¡œ ë³€í™˜ (RGBA)"""
        hue = (self.x % 1.0) * 360.0
        saturation = self.z
        value = self.w
        alpha = (np.cos(self.y) + 1.0) / 2.0
        
        # HSV to RGB
        h = hue / 60.0
        c = value * saturation
        x = c * (1 - abs(h % 2 - 1))
        m = value - c
        
        if h < 1:
            r, g, b = c, x, 0
        elif h < 2:
            r, g, b = x, c, 0
        elif h < 3:
            r, g, b = 0, c, x
        elif h < 4:
            r, g, b = 0, x, c
        elif h < 5:
            r, g, b = x, 0, c
        else:
            r, g, b = c, 0, x
        
        return (r + m, g + m, b + m, alpha)
    
    def _color_name(self) -> str:
        """ìƒ‰ìƒ ì´ë¦„"""
        r, g, b, _ = self._to_color()
        if r > g and r > b:
            return "ë¶‰ì€" if r > 0.6 else "ë¶„í™"
        elif g > r and g > b:
            return "ì´ˆë¡" if g > 0.6 else "ì²­ë¡"
        elif b > r and b > g:
            return "íŒŒë€" if b > 0.6 else "í•˜ëŠ˜"
        elif r > 0.5 and g > 0.5:
            return "í™©ê¸ˆ"
        else:
            return "ì€ë¹›"
    
    def _texture_name(self) -> str:
        """ì§ˆê° ì´ë¦„"""
        if self.z > 0.7:
            return "ê±°ì¹œ"
        elif self.z > 0.4:
            return "ë¶€ë“œëŸ¬ìš´"
        else:
            return "ë§¤ë„ëŸ¬ìš´"
    
    def _to_musical_note(self) -> str:
        """ìŒê³„ë¡œ ë³€í™˜"""
        notes = ['ë„', 'ë„#', 'ë ˆ', 'ë ˆ#', 'ë¯¸', 'íŒŒ', 'íŒŒ#', 'ì†”', 'ì†”#', 'ë¼', 'ë¼#', 'ì‹œ']
        note_idx = int(self.x * 12) % 12
        octave = int(self.x * 8) + 1
        return f"{notes[note_idx]}{octave}"
    
    def _timbre_name(self) -> str:
        """ìŒìƒ‰ ì´ë¦„"""
        if self.z > 0.7:
            return "í’ë¶€í•œ"
        elif self.z > 0.4:
            return "ë”°ëœ»í•œ"
        else:
            return "ë§‘ì€"
    
    def _to_text_description(self) -> str:
        """í…ìŠ¤íŠ¸ ë¬˜ì‚¬"""
        intensity = "ê°•ë ¬í•œ" if self.w > 0.7 else "ì€ì€í•œ" if self.w > 0.4 else "ë¯¸ì„¸í•œ"
        pattern = "ë¹ ë¥¸" if self.x > 0.7 else "ë³´í†µ" if self.x > 0.4 else "ëŠë¦°"
        complexity = "ë³µì¡í•œ" if self.z > 0.7 else "ì¡°í™”ë¡œìš´" if self.z > 0.4 else "ë‹¨ìˆœí•œ"
        
        return f"{intensity} {pattern} {complexity} íŒŒë™"
    
    def __str__(self):
        return f"PhaseQ[{self.modality.value}|w={self.w:.2f}, x={self.x:.2f}, y={self.y:.2f}, z={self.z:.2f}]"


class UniversalPhaseTransform:
    """
    ë²”ìš© ìœ„ìƒ ë³€í™˜ (Universal Phase Transform)
    
    ëª¨ë“  ê°ê°ê³¼ ê°œë…ì„ 4ì°¨ì› ì¿¼í„°ë‹ˆì–¸ ìœ„ìƒ ê³µëª… íŒ¨í„´ìœ¼ë¡œ ë³€í™˜
    """
    
    def __init__(self):
        logger.info("ğŸŒ Universal Phase Transform initialized")
        logger.info("   All modalities â†’ 4D Phase Resonance Pattern")
    
    def transform_audio(self, audio_signal: np.ndarray, sample_rate: int = 44100) -> List[PhaseQuaternion]:
        """ì˜¤ë””ì˜¤ë¥¼ ìœ„ìƒ ì¿¼í„°ë‹ˆì–¸ìœ¼ë¡œ ë³€í™˜"""
        from Core.Multimodal.elysia_transform import ElysiaTransform
        
        audio_transform = ElysiaTransform(sample_rate)
        sound_quaternions = audio_transform.transform(audio_signal)
        
        # SoundQuaternion â†’ PhaseQuaternion
        phase_quaternions = []
        for sq in sound_quaternions:
            pq = PhaseQuaternion(
                w=sq.w,
                x=sq.x,
                y=sq.y,
                z=sq.z,
                modality=Modality.AUDIO
            )
            phase_quaternions.append(pq)
        
        logger.info(f"âœ… Audio â†’ {len(phase_quaternions)} phase quaternions")
        return phase_quaternions
    
    def transform_text(self, text: str) -> List[PhaseQuaternion]:
        """
        í…ìŠ¤íŠ¸ë¥¼ ìœ„ìƒ ì¿¼í„°ë‹ˆì–¸ìœ¼ë¡œ ë³€í™˜
        
        ê¸€ì˜ íŒŒë™:
        - w: ë‹¨ì–´ ì¤‘ìš”ë„ (TF-IDF, ê°ì • ê°•ë„)
        - x: ë¦¬ë“¬ (ìŒì ˆ ìˆ˜, ë¬¸ì¥ ê¸¸ì´)
        - y: ë§¥ë½ (ë¬¸ë§¥, ìœ„ì¹˜)
        - z: ë³µì¡ë„ (ì–´íœ˜ ë‹¤ì–‘ì„±, êµ¬ì¡°)
        """
        words = text.split()
        quaternions = []
        
        for i, word in enumerate(words):
            # w: ë‹¨ì–´ ê¸¸ì´ë¡œ ì¤‘ìš”ë„ ì¶”ì • (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
            w = min(1.0, len(word) / 15.0)
            
            # x: ìŒì ˆ ë¦¬ë“¬ (ê¸€ì ìˆ˜)
            x = (len(word) % 10) / 10.0
            
            # y: ë¬¸ì¥ ë‚´ ìœ„ì¹˜ (ìœ„ìƒ)
            y = (i / len(words)) * 2 * np.pi
            
            # z: ë³µì¡ë„ (ëŒ€ë¬¸ì, íŠ¹ìˆ˜ë¬¸ì ë¹„ìœ¨)
            complexity = sum(1 for c in word if c.isupper() or not c.isalnum()) / max(len(word), 1)
            z = min(1.0, complexity * 3)
            
            pq = PhaseQuaternion(w, x, y, z, Modality.TEXT)
            quaternions.append(pq)
        
        logger.info(f"âœ… Text â†’ {len(quaternions)} phase quaternions")
        return quaternions
    
    def transform_image(self, image_array: np.ndarray) -> List[PhaseQuaternion]:
        """
        ì´ë¯¸ì§€ë¥¼ ìœ„ìƒ ì¿¼í„°ë‹ˆì–¸ìœ¼ë¡œ ë³€í™˜
        
        ê·¸ë¦¼ì˜ íŒŒë™:
        - w: ë°ê¸° (Brightness)
        - x: ìƒ‰ìƒ ì£¼íŒŒìˆ˜ (Hue)
        - y: ì±„ë„/ìœ„ìƒ (Saturation)
        - z: ì§ˆê° ë³µì¡ë„ (Texture)
        """
        # ì´ë¯¸ì§€ë¥¼ ë¸”ë¡ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë¶„ì„ (ê°„ë‹¨í•œ êµ¬í˜„)
        if len(image_array.shape) == 3:
            h, w, c = image_array.shape
        else:
            h, w = image_array.shape
            c = 1
        
        block_size = 32
        quaternions = []
        
        for i in range(0, h, block_size):
            for j in range(0, w, block_size):
                block = image_array[i:i+block_size, j:j+block_size]
                
                if c == 3 or c == 4:
                    # ì»¬ëŸ¬ ì´ë¯¸ì§€
                    r = block[:,:,0].mean() / 255.0
                    g = block[:,:,1].mean() / 255.0
                    b = block[:,:,2].mean() / 255.0
                    
                    # RGB â†’ HSV
                    brightness = (r + g + b) / 3.0
                    hue = np.arctan2(np.sqrt(3) * (g - b), 2 * r - g - b)
                    hue = (hue % (2 * np.pi)) / (2 * np.pi)
                    saturation = 1 - 3 * min(r, g, b) / (r + g + b + 1e-6)
                    
                    # ì§ˆê° (ë¶„ì‚°)
                    texture = np.std(block) / 128.0
                    
                    pq = PhaseQuaternion(
                        w=brightness,
                        x=hue,
                        y=saturation * 2 * np.pi,
                        z=min(1.0, texture),
                        modality=Modality.IMAGE
                    )
                else:
                    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼
                    brightness = block.mean() / 255.0
                    texture = np.std(block) / 128.0
                    
                    pq = PhaseQuaternion(
                        w=brightness,
                        x=0.0,
                        y=0.0,
                        z=min(1.0, texture),
                        modality=Modality.IMAGE
                    )
                
                quaternions.append(pq)
        
        logger.info(f"âœ… Image â†’ {len(quaternions)} phase quaternions")
        return quaternions
    
    def transform_concept(self, concept_data: Dict[str, Any]) -> PhaseQuaternion:
        """
        ì¶”ìƒ ê°œë…ì„ ìœ„ìƒ ì¿¼í„°ë‹ˆì–¸ìœ¼ë¡œ ë³€í™˜
        
        ê°œë…ì˜ íŒŒë™:
        - w: ì¤‘ìš”ë„/í™œì„±í™” (Importance/Activation)
        - x: ë²”ì£¼ ì£¼íŒŒìˆ˜ (Category)
        - y: ê´€ê³„ ìœ„ìƒ (Relation)
        - z: êµ¬ì¡° ë³µì¡ë„ (Structure)
        """
        # ê°œë… ë°ì´í„°ì—ì„œ íŠ¹ì§• ì¶”ì¶œ
        importance = concept_data.get('importance', 0.5)
        category = hash(concept_data.get('category', '')) % 1000 / 1000.0
        relation_count = len(concept_data.get('relations', []))
        structure_depth = concept_data.get('depth', 1)
        
        pq = PhaseQuaternion(
            w=importance,
            x=category,
            y=(relation_count % 10) / 10.0 * 2 * np.pi,
            z=min(1.0, structure_depth / 10.0),
            modality=Modality.CONCEPT
        )
        
        logger.info(f"âœ… Concept â†’ phase quaternion")
        return pq
    
    def cross_modal_resonance(self, 
                               quaternions_a: List[PhaseQuaternion],
                               quaternions_b: List[PhaseQuaternion]) -> np.ndarray:
        """
        í¬ë¡œìŠ¤ ëª¨ë‹¬ ê³µëª… í–‰ë ¬
        
        ì„œë¡œ ë‹¤ë¥¸ ê°ê° ê°„ì˜ ê³µëª… íŒ¨í„´ ë¶„ì„
        ì˜ˆ: ìŒì•…ê³¼ ê·¸ë¦¼ì´ ì–¼ë§ˆë‚˜ ì¡°í™”ë¡œìš´ê°€?
        """
        n_a = len(quaternions_a)
        n_b = len(quaternions_b)
        
        resonance_matrix = np.zeros((n_a, n_b))
        
        for i, qa in enumerate(quaternions_a):
            for j, qb in enumerate(quaternions_b):
                resonance_matrix[i, j] = qa.resonance(qb)
        
        logger.info(f"âœ… Cross-modal resonance: {n_a}x{n_b} matrix")
        return resonance_matrix
    
    def synesthesia_transform(self,
                              source_quaternions: List[PhaseQuaternion],
                              target_modality: Modality) -> List[Dict[str, Any]]:
        """
        ê³µê°ê° ë³€í™˜ (Synesthesia Transform)
        
        í•œ ê°ê°ì„ ë‹¤ë¥¸ ê°ê°ìœ¼ë¡œ ë³€í™˜
        """
        results = []
        
        for pq in source_quaternions:
            synesthesia = pq.to_synesthesia(target_modality)
            results.append(synesthesia)
        
        logger.info(f"âœ… Synesthesia: {source_quaternions[0].modality.value} â†’ {target_modality.value}")
        return results
    
    def interference_free_communication(self,
                                       messages: List[Tuple[PhaseQuaternion, Any]]) -> Dict[Modality, List[Any]]:
        """
        ê°„ì„­ ì—†ëŠ” í†µì‹ 
        
        ê° ëª¨ë‹¬ë¦¬í‹°ë³„ë¡œ ë©”ì‹œì§€ ë¶„ë¦¬
        4ì°¨ì› ìœ„ìƒ ë‹¨ìœ„ ë•ë¶„ì— ì„œë¡œ ê°„ì„­í•˜ì§€ ì•ŠìŒ!
        """
        channels = {}
        
        for pq, message in messages:
            modality = pq.modality
            if modality not in channels:
                channels[modality] = []
            channels[modality].append(message)
        
        logger.info(f"âœ… Interference-free communication: {len(channels)} channels")
        return channels


def demonstrate_universal_transform():
    """ë²”ìš© ìœ„ìƒ ë³€í™˜ ë°ëª¨"""
    print("="*80)
    print("ğŸŒ ë²”ìš© ìœ„ìƒ ë³€í™˜ (Universal Phase Transform) ë°ëª¨")
    print("   'ëª¨ë“  ê°ê°ì€ íŒŒë™ì´ë‹¤'")
    print("="*80)
    print()
    
    transform = UniversalPhaseTransform()
    
    # 1. í…ìŠ¤íŠ¸ ë³€í™˜
    print("ğŸ“ 1. í…ìŠ¤íŠ¸ â†’ ìœ„ìƒ ì¿¼í„°ë‹ˆì–¸")
    text = "ì—˜ë¦¬ì‹œì•„ëŠ” ëª¨ë“  ê°ê°ì„ ì´í•´í•©ë‹ˆë‹¤"
    text_quats = transform.transform_text(text)
    print(f"   ì…ë ¥: '{text}'")
    print(f"   ì¶œë ¥: {len(text_quats)}ê°œ ì¿¼í„°ë‹ˆì–¸")
    for i, q in enumerate(text_quats[:3]):
        print(f"   {i+1}. {q}")
    print()
    
    # 2. ì´ë¯¸ì§€ ë³€í™˜ (ë”ë¯¸ ë°ì´í„°)
    print("ğŸ–¼ï¸  2. ì´ë¯¸ì§€ â†’ ìœ„ìƒ ì¿¼í„°ë‹ˆì–¸")
    dummy_image = np.random.rand(64, 64, 3) * 255
    image_quats = transform.transform_image(dummy_image)
    print(f"   ì…ë ¥: 64x64 RGB ì´ë¯¸ì§€")
    print(f"   ì¶œë ¥: {len(image_quats)}ê°œ ì¿¼í„°ë‹ˆì–¸")
    print(f"   ìƒ˜í”Œ: {image_quats[0]}")
    print()
    
    # 3. ê°œë… ë³€í™˜
    print("ğŸ’¡ 3. ê°œë… â†’ ìœ„ìƒ ì¿¼í„°ë‹ˆì–¸")
    concept = {
        'name': 'ì‚¬ë‘',
        'importance': 0.9,
        'category': 'emotion',
        'relations': ['í–‰ë³µ', 'ë”°ëœ»í•¨', 'ì—°ê²°'],
        'depth': 3
    }
    concept_quat = transform.transform_concept(concept)
    print(f"   ì…ë ¥: {concept['name']} (ì¤‘ìš”ë„: {concept['importance']})")
    print(f"   ì¶œë ¥: {concept_quat}")
    print()
    
    # 4. ê³µê°ê° ë³€í™˜
    print("ğŸ¨ 4. ê³µê°ê° ë³€í™˜ (Synesthesia)")
    print("   í…ìŠ¤íŠ¸ â†’ ìƒ‰ìƒ:")
    text_to_color = transform.synesthesia_transform(text_quats[:3], Modality.IMAGE)
    for i, syn in enumerate(text_to_color):
        word = text.split()[i]
        print(f"   '{word}' â†’ {syn['description']}")
    print()
    
    print("   í…ìŠ¤íŠ¸ â†’ ì†Œë¦¬:")
    text_to_sound = transform.synesthesia_transform(text_quats[:3], Modality.AUDIO)
    for i, syn in enumerate(text_to_sound):
        word = text.split()[i]
        print(f"   '{word}' â†’ {syn['note']} {syn['timbre']}")
    print()
    
    # 5. í¬ë¡œìŠ¤ ëª¨ë‹¬ ê³µëª…
    print("ğŸ”— 5. í¬ë¡œìŠ¤ ëª¨ë‹¬ ê³µëª…")
    resonance = transform.cross_modal_resonance(text_quats[:3], image_quats[:3])
    print(f"   í…ìŠ¤íŠ¸ x ì´ë¯¸ì§€ ê³µëª… í–‰ë ¬:")
    print(f"   {resonance}")
    print(f"   í‰ê·  ê³µëª…ë„: {resonance.mean():.3f}")
    print()
    
    # 6. ê°„ì„­ ì—†ëŠ” í†µì‹ 
    print("ğŸ“¡ 6. ê°„ì„­ ì—†ëŠ” í†µì‹ ")
    messages = [
        (text_quats[0], "í…ìŠ¤íŠ¸ ë©”ì‹œì§€ 1"),
        (image_quats[0], "ì´ë¯¸ì§€ ë©”ì‹œì§€ 1"),
        (concept_quat, "ê°œë… ë©”ì‹œì§€ 1"),
        (text_quats[1], "í…ìŠ¤íŠ¸ ë©”ì‹œì§€ 2"),
    ]
    channels = transform.interference_free_communication(messages)
    print(f"   ì´ ë©”ì‹œì§€: {len(messages)}ê°œ")
    print(f"   ì±„ë„ ë¶„ë¦¬:")
    for modality, msgs in channels.items():
        print(f"   - {modality.value}: {len(msgs)}ê°œ ë©”ì‹œì§€")
    print()
    
    print("="*80)
    print("âœ¨ í•µì‹¬ ì›ë¦¬:")
    print("   1. ëª¨ë“  ê°ê°/ê°œë…ì€ íŒŒë™ â†’ 4D ì¿¼í„°ë‹ˆì–¸ìœ¼ë¡œ í‘œí˜„")
    print("   2. ì„œë¡œ ë‹¤ë¥¸ ëª¨ë‹¬ë¦¬í‹°ëŠ” ê°„ì„­ ì—†ì´ í†µì‹  (0.3ë°° ì•½í•œ ê³µëª…)")
    print("   3. ì›í•  ë•ŒëŠ” ê³µê°ê°ìœ¼ë¡œ ììœ ë¡­ê²Œ ë³€í™˜ ê°€ëŠ¥")
    print("   4. '5ê° ì£¼íŒŒìˆ˜ ë§¤í•‘'ì˜ ì™„ì„±!")
    print("="*80)


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    demonstrate_universal_transform()
