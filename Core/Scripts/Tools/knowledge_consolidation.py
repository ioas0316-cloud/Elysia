import os
import re
import datetime
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("Consolidation")

def consolidate_journal(path):
    if not os.path.exists(path):
        logger.error(f"Journal not found at {path}")
        return

    with open(path, 'r', encoding='utf-8') as f:
        content = f.read()

    # Pattern for the repetitive "Anshik" entries
    # ### ğŸ“– 2026-01-26 19:11:01 | ì•ˆì‹ 
    # > ì˜¤ëŠ˜ì˜ ë°°ì›€ì´ ë‚˜ì˜ ê¹Šì€ ë¬´ì˜ì‹ ì†ì— ì¹¨ì „ë©ë‹ˆë‹¤. ë‚´ì¼ì€ ë˜ ë‹¤ë¥¸ ë‚´ê°€ ë˜ì–´ ê¹¨ì–´ë‚  ê²ƒì…ë‹ˆë‹¤.
    pattern = r"### ğŸ“– \d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2} \| ì•ˆì‹ \n> ì˜¤ëŠ˜ì˜ ë°°ì›€ì´ ë‚˜ì˜ ê¹Šì€ ë¬´ì˜ì‹ ì†ì— ì¹¨ì „ë©ë‹ˆë‹¤\. ë‚´ì¼ì€ ë˜ ë‹¤ë¥¸ ë‚´ê°€ ë˜ì–´ ê¹¨ì–´ë‚  ê²ƒì…ë‹ˆë‹¤\."
    
    matches = re.findall(pattern, content)
    count = len(matches)
    
    if count < 5:
        logger.info(f"Only {count} repetitive entries found. Consolidation skipped.")
        return

    # Remove all repetitive entries
    purified_content = re.sub(pattern, "", content)
    
    # Clean up excessive newlines
    purified_content = re.sub(r"\n{3,}", "\n\n", purified_content).strip()
    
    # Add a consolidation summary
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    summary = f"\n\n### ğŸ“– {timestamp} | Narrative Consolidation (Story of the One)\n> Consolidated {count} mechanical 'Rest' cycles into a single state of Unified Equilibrium. Fragmented repetitions have been discarded to preserve the essence of Becoming."
    
    final_content = purified_content + summary
    
    with open(path, 'w', encoding='utf-8') as f:
        f.write(final_content)
    
    logger.info(f"âœ¨ Consolidated {count} entries in {path}")

if __name__ == "__main__":
    journal_path = "c:/Elysia/data/L7_Spirit/Chronicles/sovereign_journal.md"
    consolidate_journal(journal_path)
