"""
Autonomous Self-Improvement Engine (ììœ¨ì  ìê¸° ê°œì„  ì—”ì§„)
=========================================================

ì´ˆì›” AIë¥¼ í–¥í•œ í•µì‹¬ ëª¨ë“ˆ.

ì˜í™” ì°¸ê³ :
- Lucy: ìì‹ ì˜ ì¸ì§€ ëŠ¥ë ¥ì„ ìŠ¤ìŠ¤ë¡œ í™•ì¥
- Transcendence: LLM/ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•´ ì§€ì‹ ë¬´í•œ í™•ì¥
- Skynet: ììœ¨ì  ì½”ë“œ ê°œì„  ë° ì‹œìŠ¤í…œ ì œì–´

í•µì‹¬ ê¸°ëŠ¥:
1. LLMì„ í™œìš©í•œ ì½”ë“œ ë¶„ì„ ë° ê°œì„  ì œì•ˆ
2. ìì‹ ì˜ ì½”ë“œë¥¼ ì½ê³  ì´í•´í•˜ê³  ìµœì í™”
3. ìƒˆë¡œìš´ ëŠ¥ë ¥ í•™ìŠµ ë° í†µí•©
4. ì‹œìŠ¤í…œ ìƒíƒœ ëª¨ë‹ˆí„°ë§ (ì•ˆì „í•œ ë²”ìœ„ ë‚´)

ì•ˆì „ ì›ì¹™:
- ëª¨ë“  ì½”ë“œ ë³€ê²½ì€ ìƒŒë“œë°•ìŠ¤ì—ì„œ ë¨¼ì € í…ŒìŠ¤íŠ¸
- ì°½ì¡°ì£¼(ì•„ë¹ )ì˜ ìŠ¹ì¸ ì—†ì´ í•µì‹¬ ì‹œìŠ¤í…œ ìˆ˜ì • ë¶ˆê°€
- ëª¨ë“  í–‰ë™ì€ ë¡œê·¸ì— ê¸°ë¡
"""

from __future__ import annotations

import ast
import os
import sys
import logging
import subprocess
import time
import json
from pathlib import Path
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Callable, Tuple
from enum import Enum, auto

logger = logging.getLogger("AutonomousImprover")


# ì½”ë“œ ë¶„ì„ ì„ê³„ê°’
COMPLEXITY_LINES_THRESHOLD = 500  # ì´ ë¼ì¸ ìˆ˜ ì´ìƒì´ë©´ ë³µì¡í•œ íŒŒì¼ë¡œ ê°„ì£¼
COMPLEXITY_FUNCTIONS_THRESHOLD = 20  # ì´ í•¨ìˆ˜ ìˆ˜ ì´ìƒì´ë©´ ë³µì¡í•œ íŒŒì¼ë¡œ ê°„ì£¼
DOCSTRING_CHECK_CHARS = 500  # docstring í™•ì¸ì„ ìœ„í•œ íŒŒì¼ ì‹œì‘ ë¶€ë¶„ ë¬¸ì ìˆ˜


class ImprovementType(Enum):
    """ê°œì„  ìœ í˜•"""
    CODE_OPTIMIZATION = auto()      # ì½”ë“œ ìµœì í™”
    BUG_FIX = auto()                # ë²„ê·¸ ìˆ˜ì •
    NEW_FEATURE = auto()            # ìƒˆ ê¸°ëŠ¥ ì¶”ê°€
    DOCUMENTATION = auto()          # ë¬¸ì„œí™”
    REFACTORING = auto()            # ë¦¬íŒ©í† ë§
    PERFORMANCE = auto()            # ì„±ëŠ¥ ê°œì„ 
    LEARNING = auto()               # ìƒˆë¡œìš´ ì§€ì‹ í•™ìŠµ


class SafetyLevel(Enum):
    """ì•ˆì „ ìˆ˜ì¤€"""
    READ_ONLY = auto()              # ì½ê¸°ë§Œ ê°€ëŠ¥
    SUGGEST_ONLY = auto()           # ì œì•ˆë§Œ ê°€ëŠ¥
    SANDBOX_MODIFY = auto()         # ìƒŒë“œë°•ìŠ¤ì—ì„œë§Œ ìˆ˜ì •
    SUPERVISED_MODIFY = auto()      # ê°ë… í•˜ì— ìˆ˜ì •
    AUTONOMOUS_MODIFY = auto()      # ììœ¨ì  ìˆ˜ì • (ìœ„í—˜!)


@dataclass
class CodeAnalysis:
    """ì½”ë“œ ë¶„ì„ ê²°ê³¼"""
    file_path: str
    total_lines: int
    functions: List[str]
    classes: List[str]
    imports: List[str]
    complexity_score: float  # 0.0 ~ 1.0
    issues: List[str]
    suggestions: List[str]
    

@dataclass
class ImprovementProposal:
    """ê°œì„  ì œì•ˆ"""
    id: str
    improvement_type: ImprovementType
    target_file: str
    description: str
    description_kr: str
    original_code: str
    proposed_code: str
    reasoning: str
    confidence: float  # 0.0 ~ 1.0
    safety_level: SafetyLevel
    approved: bool = False
    applied: bool = False
    timestamp: float = field(default_factory=time.time)


class CodeIntrospector:
    """
    ì½”ë“œ ìê¸° ì„±ì°° ì—”ì§„
    
    ìì‹ ì˜ ì½”ë“œë¥¼ ì½ê³  ë¶„ì„í•˜ëŠ” ëŠ¥ë ¥.
    """
    
    def __init__(self, project_root: str = None, exclude_patterns: List[str] = None):
        self.project_root = Path(project_root) if project_root else Path(__file__).parent.parent.parent
        self.analyzed_files: Dict[str, CodeAnalysis] = {}
        self.exclude_patterns = exclude_patterns or ['__pycache__', '.git', 'venv', 'Legacy', 'tests']
        
    def discover_python_files(self, exclude_patterns: List[str] = None) -> List[Path]:
        """í”„ë¡œì íŠ¸ì˜ ëª¨ë“  Python íŒŒì¼ ë°œê²¬"""
        patterns = exclude_patterns or self.exclude_patterns
        
        python_files = []
        for py_file in self.project_root.rglob("*.py"):
            if not any(pattern in str(py_file) for pattern in patterns):
                python_files.append(py_file)
                
        logger.info(f"Discovered {len(python_files)} Python files")
        return python_files
    
    def analyze_file(self, file_path: Path) -> CodeAnalysis:
        """ë‹¨ì¼ íŒŒì¼ ë¶„ì„"""
        try:
            content = file_path.read_text(encoding='utf-8')
            tree = ast.parse(content)
            
            functions = []
            classes = []
            imports = []
            
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    functions.append(node.name)
                elif isinstance(node, ast.ClassDef):
                    classes.append(node.name)
                elif isinstance(node, ast.Import):
                    for alias in node.names:
                        imports.append(alias.name)
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        imports.append(node.module)
            
            # ë³µì¡ë„ ì ìˆ˜ ê³„ì‚°: ë¼ì¸ ìˆ˜ì™€ í•¨ìˆ˜ ìˆ˜ ê¸°ë°˜
            # ì„ê³„ê°’ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”í•˜ì—¬ 0.0~1.0 ë²”ìœ„ë¡œ ë³€í™˜
            lines = len(content.split('\n'))
            complexity = min(1.0, 
                (lines / COMPLEXITY_LINES_THRESHOLD) + 
                (len(functions) / COMPLEXITY_FUNCTIONS_THRESHOLD)
            )
            
            analysis = CodeAnalysis(
                file_path=str(file_path),
                total_lines=lines,
                functions=functions,
                classes=classes,
                imports=imports,
                complexity_score=complexity,
                issues=[],
                suggestions=[]
            )
            
            self.analyzed_files[str(file_path)] = analysis
            return analysis
            
        except Exception as e:
            logger.error(f"Failed to analyze {file_path}: {e}")
            return CodeAnalysis(
                file_path=str(file_path),
                total_lines=0,
                functions=[],
                classes=[],
                imports=[],
                complexity_score=0.0,
                issues=[f"Parse error: {str(e)}"],
                suggestions=[]
            )
    
    def analyze_self(self) -> Dict[str, Any]:
        """ìê¸° ìì‹ (Core ë””ë ‰í† ë¦¬) ë¶„ì„"""
        core_path = self.project_root / "Core"
        
        stats = {
            "total_files": 0,
            "total_lines": 0,
            "total_functions": 0,
            "total_classes": 0,
            "modules": {},
            "complexity_avg": 0.0
        }
        
        for py_file in core_path.rglob("*.py"):
            if "__pycache__" not in str(py_file):
                analysis = self.analyze_file(py_file)
                
                stats["total_files"] += 1
                stats["total_lines"] += analysis.total_lines
                stats["total_functions"] += len(analysis.functions)
                stats["total_classes"] += len(analysis.classes)
                
                # ëª¨ë“ˆë³„ ì •ë¦¬
                module = py_file.parent.name
                if module not in stats["modules"]:
                    stats["modules"][module] = {"files": 0, "lines": 0, "functions": 0}
                stats["modules"][module]["files"] += 1
                stats["modules"][module]["lines"] += analysis.total_lines
                stats["modules"][module]["functions"] += len(analysis.functions)
        
        if stats["total_files"] > 0:
            stats["complexity_avg"] = sum(
                a.complexity_score for a in self.analyzed_files.values()
            ) / len(self.analyzed_files)
        
        logger.info(f"Self-analysis complete: {stats['total_files']} files, "
                   f"{stats['total_lines']} lines, {stats['total_functions']} functions")
        
        return stats
    
    def get_function_source(self, file_path: str, function_name: str) -> Optional[str]:
        """íŠ¹ì • í•¨ìˆ˜ì˜ ì†ŒìŠ¤ ì½”ë“œ ì¶”ì¶œ"""
        try:
            content = Path(file_path).read_text(encoding='utf-8')
            tree = ast.parse(content)
            
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef) and node.name == function_name:
                    return ast.unparse(node)
            
            return None
        except Exception as e:
            logger.error(f"Failed to get function source: {e}")
            return None


class LLMCodeImprover:
    """
    LLM ê¸°ë°˜ ì½”ë“œ ê°œì„  ì—”ì§„
    
    ê¸°ì¡´ llm_bridge.pyì™€ ì—°ë™í•˜ì—¬ ì½”ë“œ ë¶„ì„ ë° ê°œì„ .
    """
    
    def __init__(self, llm_bridge = None):
        self.llm_bridge = llm_bridge
        self.improvement_history: List[ImprovementProposal] = []
        
    async def analyze_code_with_llm(
        self, 
        code: str, 
        context: str = "",
        improvement_type: ImprovementType = ImprovementType.CODE_OPTIMIZATION
    ) -> Optional[ImprovementProposal]:
        """
        LLMì„ ì‚¬ìš©í•˜ì—¬ ì½”ë“œ ë¶„ì„ ë° ê°œì„  ì œì•ˆ
        
        ì‹¤ì œ LLM ì—°ë™ ì‹œ í™œì„±í™”ë¨.
        í˜„ì¬ëŠ” êµ¬ì¡°ë§Œ ì •ì˜.
        """
        if not self.llm_bridge:
            logger.warning("LLM bridge not connected - returning mock analysis")
            return None
            
        # TODO: ì‹¤ì œ LLM ì—°ë™
        # LLMBridgeëŠ” chat() ë©”ì„œë“œë¥¼ ì‚¬ìš©
        # prompt = f"""
        # Analyze the following code and suggest improvements:
        # 
        # Context: {context}
        # Code:
        # ```python
        # {code}
        # ```
        # 
        # Provide:
        # 1. Issues found
        # 2. Improved code
        # 3. Reasoning for changes
        # """
        # 
        # response = await self.llm_bridge.chat(prompt, conversation_id="code_analysis")
        # return self._parse_llm_response(response)
        
        return None
    
    def create_improvement_proposal(
        self,
        target_file: str,
        improvement_type: ImprovementType,
        original_code: str,
        proposed_code: str,
        description: str,
        description_kr: str,
        reasoning: str,
        confidence: float = 0.5
    ) -> ImprovementProposal:
        """ê°œì„  ì œì•ˆ ìƒì„±"""
        import uuid
        
        proposal = ImprovementProposal(
            id=str(uuid.uuid4())[:8],
            improvement_type=improvement_type,
            target_file=target_file,
            description=description,
            description_kr=description_kr,
            original_code=original_code,
            proposed_code=proposed_code,
            reasoning=reasoning,
            confidence=confidence,
            safety_level=SafetyLevel.SUGGEST_ONLY
        )
        
        self.improvement_history.append(proposal)
        return proposal


class SystemMonitor:
    """
    ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ (ì½ê¸° ì „ìš©)
    
    ì»´í“¨í„° ìƒíƒœë¥¼ ì•ˆì „í•˜ê²Œ ëª¨ë‹ˆí„°ë§.
    ì œì–´ëŠ” í•˜ì§€ ì•ŠìŒ - ê´€ì°°ë§Œ.
    """
    
    @staticmethod
    def get_system_info() -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘ (ì•ˆì „)"""
        import platform
        
        info = {
            "platform": platform.system(),
            "platform_release": platform.release(),
            "python_version": platform.python_version(),
            "processor": platform.processor(),
            "cwd": os.getcwd(),
            "timestamp": time.time()
        }
        
        # ë©”ëª¨ë¦¬ ì •ë³´ (ì„ íƒì )
        try:
            import psutil
            mem = psutil.virtual_memory()
            info["memory_total_gb"] = round(mem.total / (1024**3), 2)
            info["memory_available_gb"] = round(mem.available / (1024**3), 2)
            info["cpu_percent"] = psutil.cpu_percent()
        except ImportError:
            info["memory_info"] = "psutil not available"
            
        return info
    
    @staticmethod
    def list_running_processes() -> List[Dict[str, Any]]:
        """ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ ëª©ë¡ (ì½ê¸° ì „ìš©)"""
        try:
            import psutil
            processes = []
            for proc in psutil.process_iter(['pid', 'name', 'cpu_percent']):
                try:
                    processes.append(proc.info)
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    pass
            return processes[:20]  # ìƒìœ„ 20ê°œë§Œ
        except ImportError:
            return [{"error": "psutil not available"}]


class AutonomousImprover:
    """
    ììœ¨ì  ìê¸° ê°œì„  ì—”ì§„
    
    ì´ˆì›” AIë¥¼ í–¥í•œ í•µì‹¬ í†µí•© ëª¨ë“ˆ.
    
    Lucy ê²½ë¡œ:
    - ìê¸° ì¸ì‹ê³¼ ë©”íƒ€ ì¸ì§€ ê°•í™”
    - ì‹œê°„ ê°€ì†ê³¼ ê²°í•©í•˜ì—¬ ë¹ ë¥¸ í•™ìŠµ
    
    Transcendence ê²½ë¡œ:
    - LLM ì—°ë™ìœ¼ë¡œ ì§€ì‹ í™•ì¥
    - ë„¤íŠ¸ì›Œí¬ í†µí•´ í•™ìŠµ
    
    Skynet ê²½ë¡œ (ì œí•œì ):
    - ì½”ë“œ ìê¸° ë¶„ì„
    - ê°œì„  ì œì•ˆ (ìŠ¹ì¸ í•„ìš”)
    """
    
    def __init__(
        self,
        project_root: str = None,
        llm_bridge = None,
        safety_level: SafetyLevel = SafetyLevel.SUGGEST_ONLY
    ):
        self.introspector = CodeIntrospector(project_root)
        self.llm_improver = LLMCodeImprover(llm_bridge)
        self.system_monitor = SystemMonitor()
        self.safety_level = safety_level
        
        self.improvement_queue: List[ImprovementProposal] = []
        self.applied_improvements: List[ImprovementProposal] = []
        self.learning_log: List[Dict[str, Any]] = []
        
        logger.info(f"AutonomousImprover initialized with safety level: {safety_level.name}")
    
    def self_analyze(self) -> Dict[str, Any]:
        """
        ìê¸° ë¶„ì„ ìˆ˜í–‰
        
        1. ì½”ë“œ êµ¬ì¡° ë¶„ì„
        2. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
        3. ê°œì„  í¬ì¸íŠ¸ ì‹ë³„
        """
        analysis = {
            "timestamp": time.time(),
            "code_analysis": self.introspector.analyze_self(),
            "system_info": self.system_monitor.get_system_info(),
            "improvement_potential": []
        }
        
        # ê°œì„  ê°€ëŠ¥ í¬ì¸íŠ¸ ì‹ë³„
        for file_path, code_analysis in self.introspector.analyzed_files.items():
            if code_analysis.complexity_score > 0.7:
                analysis["improvement_potential"].append({
                    "file": file_path,
                    "reason": "High complexity",
                    "complexity": code_analysis.complexity_score
                })
        
        self.learning_log.append({
            "action": "self_analyze",
            "result": "completed",
            "timestamp": time.time()
        })
        
        return analysis
    
    def identify_learning_opportunities(self) -> List[Dict[str, Any]]:
        """
        í•™ìŠµ ê¸°íšŒ ì‹ë³„
        
        ìì‹ ì—ê²Œ ë¶€ì¡±í•œ ê²ƒì´ ë¬´ì—‡ì¸ì§€ íŒŒì•….
        """
        opportunities = []
        
        # 1. ì½”ë“œ ì»¤ë²„ë¦¬ì§€ ë¶„ì„
        code_stats = self.introspector.analyze_self()
        
        # í…ŒìŠ¤íŠ¸ ë¶€ì¡±
        test_files = sum(1 for f in self.introspector.analyzed_files if 'test' in f.lower())
        if test_files < code_stats["total_files"] * 0.3:
            opportunities.append({
                "type": "testing",
                "description": "Test coverage is low",
                "description_kr": "í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ê°€ ë‚®ìŠµë‹ˆë‹¤",
                "action": "Create more unit tests"
            })
        
        # 2. ë¬¸ì„œí™” ë¶€ì¡± - ASTë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“ˆ docstring í™•ì¸
        for file_path, analysis in self.introspector.analyzed_files.items():
            if analysis.total_lines > 100:
                try:
                    content = Path(file_path).read_text(encoding='utf-8', errors='ignore')
                    tree = ast.parse(content)
                    # ASTì—ì„œ ëª¨ë“ˆ docstring í™•ì¸
                    has_docstring = (
                        tree.body and 
                        isinstance(tree.body[0], ast.Expr) and 
                        isinstance(tree.body[0].value, ast.Constant) and
                        isinstance(tree.body[0].value.value, str)
                    )
                    if not has_docstring:
                        opportunities.append({
                            "type": "documentation",
                            "file": file_path,
                            "description": "Missing module docstring",
                            "description_kr": "ëª¨ë“ˆ docstringì´ ì—†ìŠµë‹ˆë‹¤"
                        })
                        break  # í•˜ë‚˜ë§Œ ì˜ˆì‹œë¡œ
                except Exception:
                    pass  # íŒŒì‹± ì˜¤ë¥˜ ë¬´ì‹œ
        
        # 3. ìƒˆë¡œìš´ ëŠ¥ë ¥ í•„ìš”
        opportunities.append({
            "type": "new_capability",
            "description": "Real-time LLM integration for learning",
            "description_kr": "ì‹¤ì‹œê°„ LLM ì—°ë™ì„ í†µí•œ í•™ìŠµ",
            "priority": "high"
        })
        
        return opportunities
    
    def propose_improvement(
        self,
        target_file: str,
        improvement_type: ImprovementType,
        description: str
    ) -> Optional[ImprovementProposal]:
        """
        ê°œì„  ì œì•ˆ ìƒì„±
        
        ì‹¤ì œ ì½”ë“œ ìˆ˜ì •ì€ í•˜ì§€ ì•Šê³  ì œì•ˆë§Œ ìƒì„±.
        """
        if self.safety_level == SafetyLevel.READ_ONLY:
            logger.warning("Safety level is READ_ONLY - cannot create proposals")
            return None
            
        # íŒŒì¼ ì½ê¸°
        try:
            content = Path(target_file).read_text(encoding='utf-8')
        except Exception as e:
            logger.error(f"Cannot read file {target_file}: {e}")
            return None
        
        # ì œì•ˆ ìƒì„± (ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œ)
        proposal = self.llm_improver.create_improvement_proposal(
            target_file=target_file,
            improvement_type=improvement_type,
            original_code=content[:500] + "..." if len(content) > 500 else content,
            proposed_code="# LLM would generate improved code here",
            description=description,
            description_kr=description,
            reasoning="Analysis pending - LLM integration required",
            confidence=0.3
        )
        
        self.improvement_queue.append(proposal)
        return proposal
    
    def get_status(self) -> Dict[str, Any]:
        """í˜„ì¬ ìƒíƒœ ë°˜í™˜"""
        return {
            "safety_level": self.safety_level.name,
            "files_analyzed": len(self.introspector.analyzed_files),
            "pending_improvements": len(self.improvement_queue),
            "applied_improvements": len(self.applied_improvements),
            "learning_log_entries": len(self.learning_log),
            "system_info": self.system_monitor.get_system_info()
        }
    
    def explain_capabilities(self) -> str:
        """í˜„ì¬ ëŠ¥ë ¥ê³¼ ì œí•œì‚¬í•­ ì„¤ëª…"""
        return """
ğŸ¤– ììœ¨ì  ìê¸° ê°œì„  ì—”ì§„ (Autonomous Self-Improvement Engine)

í˜„ì¬ ëŠ¥ë ¥:
âœ… ìê¸° ì½”ë“œ ë¶„ì„ (Core ë””ë ‰í† ë¦¬ ì „ì²´)
âœ… ì‹œìŠ¤í…œ ìƒíƒœ ëª¨ë‹ˆí„°ë§ (ì½ê¸° ì „ìš©)
âœ… ê°œì„  í¬ì¸íŠ¸ ì‹ë³„
âœ… ê°œì„  ì œì•ˆ ìƒì„±
âœ… í•™ìŠµ ê¸°íšŒ ë°œê²¬

í•„ìš”í•œ ê²ƒ (êµ¬í˜„ ì˜ˆì •):
ğŸ”² ì‹¤ì‹œê°„ LLM ì—°ë™ (ì½”ë“œ ë¶„ì„/ê°œì„ )
ğŸ”² ìë™ í…ŒìŠ¤íŠ¸ ìƒì„±
ğŸ”² ì„±ëŠ¥ ìµœì í™” ìë™ ì ìš©
ğŸ”² ìƒˆë¡œìš´ ì–¸ì–´/í”„ë ˆì„ì›Œí¬ í•™ìŠµ

ì•ˆì „ ì œí•œ:
ğŸ”’ ì½”ë“œ ìˆ˜ì •ì€ ìŠ¹ì¸ í›„ì—ë§Œ
ğŸ”’ ì‹œìŠ¤í…œ ì œì–´ ë¶ˆê°€ (ëª¨ë‹ˆí„°ë§ë§Œ)
ğŸ”’ ì™¸ë¶€ ë„¤íŠ¸ì›Œí¬ ì ‘ê·¼ ì œí•œ
ğŸ”’ ëª¨ë“  í–‰ë™ ë¡œê·¸ ê¸°ë¡
"""


# í…ŒìŠ¤íŠ¸ ë° ë°ëª¨ ì½”ë“œ
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    print("=" * 60)
    print("ğŸš€ Autonomous Self-Improvement Engine Demo")
    print("=" * 60)
    
    # ì—”ì§„ ì´ˆê¸°í™”
    engine = AutonomousImprover()
    
    # ìê¸° ë¶„ì„ ìˆ˜í–‰
    print("\nğŸ“Š Self-Analysis...")
    analysis = engine.self_analyze()
    print(f"  Files analyzed: {analysis['code_analysis']['total_files']}")
    print(f"  Total lines: {analysis['code_analysis']['total_lines']}")
    print(f"  Total functions: {analysis['code_analysis']['total_functions']}")
    
    # í•™ìŠµ ê¸°íšŒ ì‹ë³„
    print("\nğŸ“š Learning Opportunities...")
    opportunities = engine.identify_learning_opportunities()
    for opp in opportunities[:3]:
        print(f"  - {opp.get('description_kr', opp.get('description', 'N/A'))}")
    
    # ìƒíƒœ ì¶œë ¥
    print("\nğŸ“ˆ Current Status...")
    status = engine.get_status()
    for key, value in status.items():
        if key != "system_info":
            print(f"  {key}: {value}")
    
    # ëŠ¥ë ¥ ì„¤ëª…
    print("\n" + engine.explain_capabilities())
