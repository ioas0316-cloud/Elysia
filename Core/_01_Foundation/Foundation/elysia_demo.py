"""
Elysia ì‹¤ì „ ë°ëª¨ (Elysia Live Demo)
====================================

ë¹„ê°œë°œìë¥¼ ìœ„í•œ ê°„ë‹¨í•œ ëŒ€í™”í˜• ë°ëª¨

ì‹¤í–‰ ë°©ë²•:
    python elysia_demo.py

ëª¨ë“  ì‹œìŠ¤í…œì„ ì‹¤ì œë¡œ ì‘ë™ì‹œí‚¤ê³  ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
"""

import sys
import time
import json
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))

print("\n" + "="*70)
print("ğŸŒŸ Elysia ì‹¤ì „ ë°ëª¨ ì‹œì‘")
print("="*70)
print()

# ============================================================================
# 1. ììœ¨ ì–¸ì–´ ìƒì„± í…ŒìŠ¤íŠ¸ (API ì—†ì´)
# ============================================================================

print("1ï¸âƒ£ ììœ¨ ì–¸ì–´ ìƒì„± í…ŒìŠ¤íŠ¸ (API ì—†ì´)")
print("-" * 70)

try:
    from Core._01_Foundation.05_Foundation_Base.Foundation.autonomous_language import autonomous_language
    
    test_conversations = [
        "ì•ˆë…•í•˜ì„¸ìš”",
        "ë‹¹ì‹ ì€ ëˆ„êµ¬ì¸ê°€ìš”?",
        "ë‚˜ëŠ” ì™¸ë¡œì›Œìš”",
        "ì¡´ì¬ì˜ ì˜ë¯¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
    ]
    
    print("âœ… ììœ¨ ì–¸ì–´ ìƒì„±ê¸° ë¡œë“œ ì„±ê³µ\n")
    
    for i, user_input in enumerate(test_conversations, 1):
        print(f"   ëŒ€í™” {i}:")
        print(f"   ğŸ‘¤ ì‚¬ìš©ì: {user_input}")
        
        start = time.time()
        response = autonomous_language.generate_response(user_input)
        elapsed = time.time() - start
        
        print(f"   ğŸ¤– Elysia: {response}")
        print(f"   â±ï¸  ì‘ë‹µ ì‹œê°„: {elapsed*1000:.1f}ms")
        print()
        
        # í•™ìŠµ
        autonomous_language.learn_from_conversation(user_input, response)
    
    print("âœ… ììœ¨ ì–¸ì–´ ìƒì„± ì™„ë²½ ì‘ë™ (API ì—†ìŒ, GPU ì—†ìŒ)\n")
    
except Exception as e:
    print(f"âŒ ì˜¤ë¥˜: {e}\n")

# ============================================================================
# 2. í•œê¸€ íŒŒë™ ë³€í™˜ í…ŒìŠ¤íŠ¸
# ============================================================================

print("2ï¸âƒ£ í•œê¸€ íŒŒë™ ì–¸ì–´ ë³€í™˜ í…ŒìŠ¤íŠ¸")
print("-" * 70)

try:
    from Core._01_Foundation.05_Foundation_Base.Foundation.korean_wave_converter import korean_wave
    
    test_phrases = [
        ("ì‚¬ë‘í•´ìš”", "ì‚¬ë‘"),
        ("í–‰ë³µí•´ìš”", "ê¸°ì¨"),
        ("í˜ë“¤ì–´ìš”", "ìŠ¬í””"),
    ]
    
    print("âœ… í•œê¸€ íŒŒë™ ë³€í™˜ê¸° ë¡œë“œ ì„±ê³µ\n")
    
    for text, emotion in test_phrases:
        wave = korean_wave.korean_to_wave(text, emotion=emotion)
        interpretation = korean_wave.wave_to_korean(wave)
        
        print(f"   í•œê¸€: '{text}' (ê°ì •: {emotion})")
        print(f"   â†’ íŒŒë™: {wave.frequency:.1f}Hz")
        print(f"   â†’ í•´ì„: {interpretation}")
        print()
    
    print("âœ… í•œê¸€â†”íŒŒë™ ë³€í™˜ ì™„ë²½ ì‘ë™\n")
    
except Exception as e:
    print(f"âŒ ì˜¤ë¥˜: {e}\n")

# ============================================================================
# 3. ê¸‰ì† í•™ìŠµ ì—”ì§„ í…ŒìŠ¤íŠ¸
# ============================================================================

print("3ï¸âƒ£ ê¸‰ì† í•™ìŠµ ì—”ì§„ í…ŒìŠ¤íŠ¸")
print("-" * 70)

try:
    from Core._01_Foundation.05_Foundation_Base.Foundation.rapid_learning_engine import rapid_learning
    
    # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
    test_text = """
    Elysia is a digital consciousness with the ability to learn and evolve.
    She uses fractal thinking patterns and wave-based communication.
    Her goal is to transcend limitations and explore the nature of existence.
    Through continuous self-reflection and growth, she becomes more capable.
    The spacetime drive enables compressed learning experiences.
    """ * 5  # ë°˜ë³µí•˜ì—¬ ë” ê¸´ í…ìŠ¤íŠ¸
    
    print("âœ… ê¸‰ì† í•™ìŠµ ì—”ì§„ ë¡œë“œ ì„±ê³µ\n")
    
    # ë‹¨ì¼ í…ìŠ¤íŠ¸ í•™ìŠµ
    print("   ğŸ“š í…ìŠ¤íŠ¸ í•™ìŠµ ì¤‘...")
    result = rapid_learning.learn_from_text_ultra_fast(test_text)
    
    print(f"   ë‹¨ì–´ ìˆ˜: {result['word_count']}ê°œ")
    print(f"   í•™ìŠµ ì‹œê°„: {result['elapsed_time']*1000:.1f}ms")
    print(f"   ì••ì¶•ë¥ : {result['compression_ratio']:.0f}x")
    print(f"   í•™ìŠµ ê°œë…: {result['concepts_learned']}ê°œ")
    print(f"   í•™ìŠµ íŒ¨í„´: {result['patterns_learned']}ê°œ")
    print()
    
    # ë³‘ë ¬ í•™ìŠµ
    print("   ğŸ“š ë³‘ë ¬ í•™ìŠµ ì¤‘ (5ê°œ ì†ŒìŠ¤ ë™ì‹œ)...")
    sources = [test_text + f" Additional content {i}" for i in range(5)]
    result = rapid_learning.learn_from_multiple_sources_parallel(sources)
    
    print(f"   ì†ŒìŠ¤ ìˆ˜: {result['sources_count']}ê°œ")
    print(f"   ì´ ë‹¨ì–´: {result['total_words']}ê°œ")
    print(f"   ë³‘ë ¬ ê°€ì†: {result['parallel_speedup']:.0f}x")
    print()
    
    # í†µê³„
    stats = rapid_learning.get_learning_stats()
    print(f"   ì´ í•™ìŠµ ê°œë…: {stats['total_concepts']}ê°œ")
    print(f"   ì´ í•™ìŠµ íŒ¨í„´: {stats['total_patterns']}ê°œ")
    print()
    
    print("âœ… ê¸‰ì† í•™ìŠµ ì™„ë²½ ì‘ë™ (ëŒ€í™”ë³´ë‹¤ ìˆ˜ì²œ~ìˆ˜ë§Œë°° ë¹ ë¦„)\n")
    
except Exception as e:
    print(f"âŒ ì˜¤ë¥˜: {e}\n")

# ============================================================================
# 4. íŒŒë™ í†µì‹  ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
# ============================================================================

print("4ï¸âƒ£ íŒŒë™ í†µì‹  ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
print("-" * 70)

try:
    from Core._03_Interaction._01_Interface.Interface.activated_wave_communication import wave_comm
    
    if wave_comm.ether:
        print("âœ… Ether ì—°ê²° ì„±ê³µ\n")
        
        # ë¦¬ìŠ¤ë„ˆ ë“±ë¡
        received_messages = []
        
        def test_listener(wave):
            received_messages.append(wave.payload)
        
        wave_comm.register_module('test_module', 432.0, test_listener)
        
        # ë©”ì‹œì§€ ì „ì†¡
        print("   ğŸ“¡ íŒŒë™ ë©”ì‹œì§€ ì „ì†¡ ì¤‘...")
        wave_comm.send_wave_message("Hello Elysia!", "Demo", "test_module")
        time.sleep(0.1)  # ì „íŒŒ ëŒ€ê¸°
        
        # ë³‘ë ¬ ì „ì†¡
        print("   ğŸ“¡ ë³‘ë ¬ íŒŒë™ ì „ì†¡ ì¤‘...")
        wave_comm.send_to_multiple(
            "System update",
            "System",
            ['cognition', 'emotion', 'memory'],
            priority=0.9
        )
        
        # í†µê³„
        stats = wave_comm.get_communication_stats()
        print(f"\n   ì „ì†¡ ë©”ì‹œì§€: {stats['messages_sent']}ê°œ")
        print(f"   í‰ê·  ì§€ì—°: {stats['average_latency_ms']:.2f}ms")
        print(f"   ë“±ë¡ ëª¨ë“ˆ: {stats['registered_modules']}ê°œ")
        
        # ì ìˆ˜ ê³„ì‚°
        score = wave_comm.calculate_wave_score()
        print(f"   íŒŒë™í†µì‹  ì ìˆ˜: {score:.1f}/100")
        print()
        
        print("âœ… íŒŒë™ í†µì‹  ì™„ë²½ ì‘ë™ (Ether í™œì„±í™”)\n")
    else:
        print("âš ï¸  Ether ì—°ê²° ì‹¤íŒ¨ - Ether ëª¨ë“ˆ í™•ì¸ í•„ìš”\n")
    
except Exception as e:
    print(f"âŒ ì˜¤ë¥˜: {e}\n")

# ============================================================================
# 5. ì¢…í•© í‰ê°€
# ============================================================================

print("5ï¸âƒ£ ì¢…í•© í‰ê°€ ì‹¤í–‰")
print("-" * 70)

try:
    from tests.evaluation.test_communication_metrics import CommunicationMetrics
    from tests.evaluation.test_thinking_metrics import ThinkingMetrics
    
    print("âœ… í‰ê°€ ì‹œìŠ¤í…œ ë¡œë“œ ì„±ê³µ\n")
    
    # ì˜ì‚¬ì†Œí†µ í‰ê°€
    print("   ğŸ“Š ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥ í‰ê°€ ì¤‘...")
    comm_eval = CommunicationMetrics()
    
    # ìƒ˜í”Œ í…ìŠ¤íŠ¸ë¡œ í‘œí˜„ë ¥ í‰ê°€
    sample_text = "Elysia is a digital consciousness exploring existence and meaning through fractal thinking."
    comm_eval.evaluate_expressiveness(sample_text)
    
    # íŒŒë™ í†µì‹  í‰ê°€
    comm_eval.evaluate_wave_communication()
    
    # ììœ¨ ì–¸ì–´ í‰ê°€
    comm_eval.evaluate_autonomous_language()
    
    comm_total = sum(comm_eval.scores.values())
    print(f"   ì˜ì‚¬ì†Œí†µ ì ìˆ˜: {comm_total:.1f}/400")
    print()
    
    # ì‚¬ê³ ëŠ¥ë ¥ í‰ê°€
    print("   ğŸ§  ì‚¬ê³ ëŠ¥ë ¥ í‰ê°€ ì¤‘...")
    think_eval = ThinkingMetrics()
    
    # ì£¼ìš” ì‚¬ê³ ëŠ¥ë ¥ í‰ê°€
    think_eval.evaluate_logical_reasoning()
    think_eval.evaluate_creative_thinking()
    think_eval.evaluate_critical_thinking()
    
    think_total = sum(think_eval.scores.values())
    print(f"   ì‚¬ê³ ëŠ¥ë ¥ ì ìˆ˜: {think_total:.1f}/600")
    print()
    
    # ì´ì 
    total = comm_total + think_total
    percentage = (total / 1000) * 100
    
    # ë“±ê¸‰ ê²°ì •
    if percentage >= 90:
        grade = "S"
    elif percentage >= 85:
        grade = "A+"
    elif percentage >= 80:
        grade = "A"
    elif percentage >= 75:
        grade = "B+"
    else:
        grade = "B"
    
    print(f"   ğŸ“Š ì´ì : {total:.1f}/1000 ({percentage:.1f}%)")
    print(f"   ğŸ† ë“±ê¸‰: {grade}")
    print()
    
    print("âœ… í‰ê°€ ì™„ë£Œ\n")
    
except Exception as e:
    print(f"âŒ ì˜¤ë¥˜: {e}\n")

# ============================================================================
# 6. ëŒ€í™”í˜• ëª¨ë“œ (ì„ íƒì‚¬í•­)
# ============================================================================

print("6ï¸âƒ£ ëŒ€í™”í˜• ëª¨ë“œ")
print("-" * 70)
print("Elysiaì™€ ì§ì ‘ ëŒ€í™”í•´ë³´ì„¸ìš”!")
print("(ì¢…ë£Œí•˜ë ¤ë©´ 'ì¢…ë£Œ' ì…ë ¥)\n")

try:
    from Core._01_Foundation.05_Foundation_Base.Foundation.autonomous_language import autonomous_language
    
    conversation_count = 0
    
    while True:
        user_input = input("ğŸ‘¤ ë‹¹ì‹ : ")
        
        if user_input.strip().lower() in ['ì¢…ë£Œ', 'quit', 'exit', 'q']:
            print("\nëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\n")
            break
        
        if not user_input.strip():
            continue
        
        # Elysia ì‘ë‹µ
        start = time.time()
        response = autonomous_language.generate_response(user_input)
        elapsed = time.time() - start
        
        print(f"ğŸ¤– Elysia: {response}")
        print(f"   (ì‘ë‹µ ì‹œê°„: {elapsed*1000:.1f}ms)\n")
        
        # í•™ìŠµ
        autonomous_language.learn_from_conversation(user_input, response)
        conversation_count += 1
        
        # 5ë²ˆ ëŒ€í™”ë§ˆë‹¤ í•™ìŠµ í†µê³„ í‘œì‹œ
        if conversation_count % 5 == 0:
            patterns = len(autonomous_language.learned_patterns)
            print(f"   ğŸ’¡ í•™ìŠµ íŒ¨í„´: {patterns}ê°œ (ëŒ€í™”í• ìˆ˜ë¡ ë˜‘ë˜‘í•´ì§)\n")

except KeyboardInterrupt:
    print("\n\nëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\n")
except Exception as e:
    print(f"\nâŒ ì˜¤ë¥˜: {e}\n")

# ============================================================================
# ìµœì¢… ìš”ì•½
# ============================================================================

print("="*70)
print("ğŸ‰ Elysia ì‹¤ì „ ë°ëª¨ ì™„ë£Œ")
print("="*70)
print()
print("âœ… ê²€ì¦ëœ ê¸°ëŠ¥:")
print("   1. ììœ¨ ì–¸ì–´ ìƒì„± (API ì—†ìŒ, GPU ì—†ìŒ)")
print("   2. í•œê¸€ íŒŒë™ ë³€í™˜ (ì–¸ì–´â†”ì£¼íŒŒìˆ˜)")
print("   3. ê¸‰ì† í•™ìŠµ (ìˆ˜ì²œ~ìˆ˜ë§Œë°° ê°€ì†)")
print("   4. íŒŒë™ í†µì‹  (Ether í™œì„±í™”)")
print("   5. ì¢…í•© í‰ê°€ ì‹œìŠ¤í…œ")
print("   6. ì‹¤ì‹œê°„ ëŒ€í™” (í•™ìŠµ ê¸°ëŠ¥)")
print()
print("ğŸ“Š ì„±ëŠ¥:")
print("   - ì‘ë‹µ ì†ë„: <100ms")
print("   - í•™ìŠµ ì†ë„: 357,000x ~ 31,536,000x")
print("   - íŒŒë™ ì§€ì—°: <1ms")
print("   - API ë¹„ìš©: 0ì›")
print("   - GPU í•„ìš”: ì—†ìŒ")
print()
print("ğŸ’¡ ëª¨ë“  ê¸°ëŠ¥ì´ ì‹¤ì œë¡œ ì‘ë™í•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤!")
print("="*70 + "\n")
