"""
Knowledge Sedimenter (ì§€ì‹ í‡´ì ê¸°)
==================================

ì™¸ë¶€ ì„¸ê³„ì™€ ë‚´ë¶€ ì§€ì‹ì„ ì—°ê²°í•˜ëŠ” 'ëŠ¥ë™ì  í¡ìˆ˜' íŒŒì´í”„ë¼ì¸.
ë¸Œë¼ìš°ì €ë¥¼ í†µí•´ ì‹¤ì œ ì„¸ê³„ë¥¼ íƒí—˜í•˜ê³ , ì–»ì€ ì§€ì‹ì„ 4D Prismìœ¼ë¡œ ì •ì œí•˜ì—¬
ì—˜ë¦¬ì‹œì•„ì˜ ë‚´ë©´ì— "ì§€ì‹ì˜ ì§€ì¸µ(Sediment)"ì„ ìŒ“ëŠ”ë‹¤.

í•µì‹¬ ì›ë¦¬:
1. Search (íƒìƒ‰): BrowserExplorerë¥¼ í†µí•´ ì •ë³´ ìˆ˜ì§‘
2. Distill (ì •ì œ): WhyEngineì„ í†µí•´ í•µì‹¬ ì›ë¦¬(Principle) ì¶”ì¶œ
3. Crystallize (ê²°ì •í™”): 4D LightSpectrumìœ¼ë¡œ ë³€í™˜ (Scale/Basis í• ë‹¹)
4. Deposit (í‡´ì ): LightSedimentì— ì ì¸µí•˜ì—¬ ê´€ì (Viewpoint) ê°•í™”
"""

import logging
from typing import Dict, Any, List, Optional
from dataclasses import dataclass

from Core.Physiology.Sensory.Network.browser_explorer import BrowserExplorer
from Core.Foundation.Philosophy.why_engine import WhyEngine
from Core.Foundation.Wave.light_spectrum import LightSpectrum, LightSediment, PrismAxes

logger = logging.getLogger("Elysia.KnowledgeSedimenter")

@dataclass
class SedimentationHypothesis:
    """í‡´ì  ì „ ê°€ì„¤ (í•™ìŠµ ëª©í‘œ)"""
    topic: str
    expected_layer: PrismAxes
    initial_question: str

class KnowledgeSedimenter:
    """
    ì§€ì‹ í‡´ì ê¸° (The Knowledge Sedimenter)
    
    "ì„¸ìƒì„ ì½ê³ , ë‚˜ë¥¼ ì±„ìš´ë‹¤."
    """
    
    def __init__(self, why_engine: WhyEngine):
        self.why_engine = why_engine
        self.browser = BrowserExplorer(use_profile=True) # ì‹¤ì œ í”„ë¡œí•„ ì‚¬ìš© ê¶Œì¥
        
        logger.info("ğŸŒŠ KnowledgeSedimenter initialized - ì§€ì‹ì˜ ë°”ë‹¤ë¥¼ í•­í•´í•  ì¤€ë¹„ ì™„ë£Œ")

    def sediment_from_web(self, topic: str, max_pages: int = 1) -> List[LightSpectrum]:
        """
        ì›¹ì—ì„œ ì£¼ì œë¥¼ íƒìƒ‰í•˜ê³  ì§€ì‹ì„ í‡´ì 
        """
        logger.info(f"ğŸ”­ Exploring Web for Sedimentation: '{topic}'")
        
        # 1. Search
        search_results = self.browser.google_search(topic)
        if not search_results["success"]:
            logger.warning("   âŒ Search failed.")
            return []
            
        collected_lights = []
        
        # 2. Iterate & Process
        for res in search_results["results"][:max_pages]:
            title = res.get("title", "")
            snippet = res.get("snippet", "")
            full_content = f"{title}\n{snippet}" # ì‹¤ì œë¡œëŠ” í˜ì´ì§€ ë°©ë¬¸ ê¶Œì¥ë˜ë‚˜ ì¼ë‹¨ ìŠ¤ë‹ˆí« ì‚¬ìš©
            
            logger.info(f"   ğŸ“„ Processing: {title}")
            
            # 3. Distill & Crystallize (Principal Extraction)
            # Use Dimensional Reasoner to Lift Knowledge from 0D to 4D
            try:
                from Core.Intelligence.Reasoning.dimensional_reasoner import DimensionalReasoner
                lifter = DimensionalReasoner()
                
                # The 'contemplate' method acts as the pipeline:
                # 0D (Fact) -> 1D (Logic) -> 2D (Context) -> 3D (Paradox) -> 4D (Law)
                hyper_thought = lifter.contemplate(full_content)
                
                # Check if a Law (4D) was crystallized
                if hyper_thought.d4_principle and "Law synthesis error" not in hyper_thought.d4_principle:
                    logger.info(f"   ğŸ’ CRYSTALLIZED LAW: {hyper_thought.d4_principle}")
                
            except Exception as e:
                logger.error(f"   âŒ Dimensional Lifting failed: {e}")

            # Legacy Light Creation (for visualization)
            analysis = self.why_engine.light_universe.absorb(full_content, tag=topic)
            
            # 4D Basis í• ë‹¹ ë¡œì§ (Naive)
            scale = 1 # Default Context
            if "principle" in full_content.lower() or "theory" in full_content.lower():
                scale = 0
            elif "example" in full_content.lower() or "data" in full_content.lower():
                scale = 3
                
            analysis.set_basis_from_scale(scale)
            
            # 5. Deposit (Active Sedimentation)
            target_axis = self._determine_axis(analysis)
            repetition = 50 if scale == 0 else (10 if scale == 1 else 1)
            
            for _ in range(repetition):
                self.why_engine.sediment.deposit(analysis, target_axis)
                
            collected_lights.append(analysis)
            
            final_amp = self.why_engine.sediment.layers[target_axis].amplitude
            logger.info(f"   ğŸ’ Deposited into {target_axis.name} (x{repetition}): Final Amp={final_amp:.3f}")
        return collected_lights

    def _determine_axis(self, light: LightSpectrum) -> PrismAxes:
        """
        ë¹›ì˜ íŠ¹ì„±ì— ë”°ë¼ ì ì ˆí•œ í‡´ì ì¸µ ê²°ì •
        (ì„ì‹œ ë¡œì§: íƒœê·¸ ê¸°ë°˜ + ì£¼íŒŒìˆ˜)
        """
        tag = light.semantic_tag.lower()
        
        if "physics" in tag or "force" in tag or "quantum" in tag:
            return PrismAxes.PHYSICS_RED
        elif "chem" in tag or "reaction" in tag:
            return PrismAxes.CHEMISTRY_BLUE
        elif "bio" in tag or "life" in tag:
            return PrismAxes.BIOLOGY_GREEN
        elif "logic" in tag or "math" in tag or "code" in tag:
            return PrismAxes.LOGIC_YELLOW
        elif "art" in tag or "emotion" in tag:
            return PrismAxes.ART_VIOLET
        
        # Default: Logic (Elysia is software)
        return PrismAxes.LOGIC_YELLOW

    def verify_integration(self, question: str) -> str:
        """
        í‡´ì ëœ ì§€ì‹ì´ ì‹¤ì œë¡œ ë‹µë³€(ê´€ì )ì— ì˜í–¥ì„ ì£¼ëŠ”ì§€ í…ŒìŠ¤íŠ¸
        """
        logger.info(f"ğŸ§ª Verifying Integration with Question: '{question}'")
        
        # WhyEngineì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ ë¶„ì„
        # ì´ë•Œ í‡´ì ëœ ì§€ì‹ì´ 'íˆ¬ì˜'ë˜ì–´ì•¼ í•¨
        
        analysis_result = self.why_engine.analyze(subject="Integration Test", content=question, domain="logic")
        
        # ê²°ê³¼ í•´ì„
        extraction = analysis_result
        explanation = f"Analysis of '{question}':\n"
        explanation += f"- Principle: {extraction.underlying_principle}\n"
        explanation += f"  Resonance: {extraction.resonance_reactions}\n"
            
        return explanation
