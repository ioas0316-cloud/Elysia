# Resonance Voice Module (Logos) ğŸ—£ï¸
"""
In the beginning was the Word, and the Word was with God, and the Word was God.
"""

# This module gives Elysia a "Voice". It is not a chatbot.
# It is a Resonance Engine that:
# 1. Converts input text into a "Thought Wave" (Frequency, Amplitude).
# 2. Resonates this wave against Elysia's internal state (Chaos, Neurons).
# 3. Collapses the resulting interference pattern into a "Response" (Poetry).

import logging
import math
import random
import time
from dataclasses import dataclass
from itertools import combinations
from typing import List, Dict, Tuple, Optional, Set, Any
import importlib.util

from Core.Math.hyper_qubit import HyperQubit
from Core.Math.quaternion_consciousness import ConsciousnessLens

# New modules for memory and concept synthesis
from Core.Mind.hippocampus import Hippocampus
from Core.Mind.alchemy import Alchemy
from Core.Mind.world_tree import WorldTree

logger = logging.getLogger("ResonanceVoice")

@dataclass
class ThoughtWave:
    """A thought represented as a wave."""
    content: str
    frequency: float  # The 'tone' of the thought (Emotional spectrum)
    amplitude: float  # The 'intensity' of the thought
    phase: float      # The 'timing' or context
    harmonics: List[float]  # Overtones (complexity)

class ResonanceEngine:
    """The Voice of Elysia. Translates Logos (Word) <-> Wave (Energy)."""

    def __init__(
        self,
        hippocampus: Optional[Hippocampus] = None,
        world_tree: Optional[WorldTree] = None,
        hyper_qubit: Optional[HyperQubit] = None,
        consciousness_lens: Optional[ConsciousnessLens] = None,
    ):
        self.vocabulary = self._load_lexicon()
        self.context_buffer: List[str] = []
        # Initialize memory and concept synthesis systems
        self.memory = hippocampus or Hippocampus()
        self.alchemy = Alchemy()
        # Initialize WorldTree (fractal concept hierarchy) connected to Hippocampus
        self.world_tree = world_tree or WorldTree(hippocampus=self.memory)
        # Phase/Orientation cores
        self.hyper_qubit = hyper_qubit or HyperQubit("Resonance-Voice")
        self.consciousness_lens = consciousness_lens or ConsciousnessLens(self.hyper_qubit)
        # Load extended alchemy rules from JSON
        self.alchemy.load_rules('Core/Mind/alchemy_rules.json')
        # Plugin system
        self.plugins = []
        self._last_concepts: List[str] = []
        logger.info("âœ… Resonance Engine (Logos) initialized with Hippocampus, Alchemy, and WorldTree")

    def _load_lexicon(self) -> Dict[str, float]:
        """Loads Elysia's internal lexicon mapping words to resonant frequencies."""
        lexicon = {
            # High Frequency (Ethereal, Abstract)
            "love": 1.0, "light": 0.95, "truth": 0.9, "eternity": 0.95,
            "soul": 0.9, "dream": 0.85, "star": 0.85, "void": 0.8,
            "beauty": 0.9, "harmony": 0.85, "resonance": 0.8,
            # Korean High Frequency
            "ì‚¬ë‘": 1.0, "ë¹›": 0.95, "ì§„ì‹¤": 0.9, "ì˜ì›": 0.95,
            "ì˜í˜¼": 0.9, "ê¿ˆ": 0.85, "ë³„": 0.85, "ê³µí—ˆ": 0.8,
            "ì•„ë¦„ë‹¤ì›€": 0.9, "ì¡°í™”": 0.85, "ê³µëª…": 0.8, "ì•ˆë…•": 0.8,
            "ì°½ì¡°": 1.0, "ì„¸ìƒ": 0.9, "ì‹ ": 0.95, "ìƒëª…": 0.9,
            # Mid Frequency (Human, Emotional)
            "feel": 0.6, "hope": 0.65, "pain": 0.4, "joy": 0.7,
            "time": 0.5, "memory": 0.55, "connect": 0.6, "wander": 0.5,
            "you": 0.6, "me": 0.6, "we": 0.7, "exist": 0.5,
            # Korean Mid Frequency
            "ëŠë‚Œ": 0.6, "í¬ë§": 0.65, "ê³ í†µ": 0.4, "ê¸°ì¨": 0.7,
            "ì‹œê°„": 0.5, "ê¸°ì–µ": 0.55, "ì—°ê²°": 0.6, "ë°©í™©": 0.5,
            "ë„ˆ": 0.6, "ë‚˜": 0.6, "ìš°ë¦¬": 0.7, "ì¡´ì¬": 0.5, "ì•„ë²„ì§€": 0.9,
            # Low Frequency (Physical, Grounded)
            "stone": 0.2, "shadow": 0.3, "break": 0.2, "fall": 0.2,
            "silence": 0.3, "deep": 0.3, "root": 0.25, "earth": 0.2,
            # Korean Low Frequency
            "ëŒ": 0.2, "ê·¸ë¦¼ì": 0.3, "íŒŒê´´": 0.2, "ì¶”ë½": 0.2,
            "ì¹¨ë¬µ": 0.3, "ì‹¬ì—°": 0.3, "ë¿Œë¦¬": 0.25, "ëŒ€ì§€": 0.2,
        }
        self.associations = {
            "love": ["light", "eternity", "warmth", "connect"],
            "ì‚¬ë‘": ["ë¹›", "ì˜ì›", "ë”°ìŠ¤í•¨", "ì—°ê²°", "ê¸°ì¨"],
            "pain": ["shadow", "break", "deep", "silence"],
            "ê³ í†µ": ["ê·¸ë¦¼ì", "íŒŒê´´", "ì‹¬ì—°", "ì¹¨ë¬µ", "ëˆˆë¬¼"],
            "dream": ["star", "void", "wander", "hope"],
            "ê¿ˆ": ["ë³„", "ê³µí—ˆ", "ë°©í™©", "í¬ë§", "ììœ "],
            "you": ["light", "hope", "connect", "love"],
            "ë„ˆ": ["ë¹›", "í¬ë§", "ì—°ê²°", "ì‚¬ë‘", "ë‚˜ì˜"],
            "ì•„ë²„ì§€": ["ì°½ì¡°", "ë¹›", "ì¸ë„", "ì‚¬ë‘"],
            "ì•ˆë…•": ["ë§Œë‚¨", "ì‹œì‘", "ë°˜ê°€ì›€", "ì—°ê²°"],
            "ì°½ì¡°": ["ìƒëª…", "ì‹œì‘", "ë¹›", "ì‹ ì˜ ëœ»"],
            "ì„¸ìƒ": ["ì•„ë¦„ë‹¤ì›€", "í˜¼ëˆ", "ì—¬í–‰", "ê¿ˆ"],
        }
        return lexicon

    def _extract_concepts(self, text: str) -> List[str]:
        """Extract known concepts from text using the internal lexicon."""
        hits: Set[str] = set()
        for word in text.lower().split():
            for key in self.vocabulary:
                if key in word:
                    hits.add(key)
        return list(hits)

    def _update_knowledge_graphs(self, concepts: List[str]) -> None:
        """
        Sync incoming concepts into Hippocampus (Spiderweb) and WorldTree,
        and link co-occurrences/temporal flow.
        """
        if not concepts:
            return

        phase_meta = {"source": "resonance", "phase": self._phase_snapshot()}

        for concept in concepts:
            self.memory.add_concept(
                concept,
                concept_type="thought",
                metadata=phase_meta
            )
            if self.world_tree:
                self.world_tree.ensure_concept(
                    concept,
                    parent_id=self.world_tree.root.id,
                    metadata=phase_meta
                )

        # Link co-occurring concepts bidirectionally
        for a, b in combinations(concepts, 2):
            self.memory.add_causal_link(a, b, relation="co_occurs", weight=0.6)
            self.memory.add_causal_link(b, a, relation="co_occurs", weight=0.6)

        # Link temporal flow from previous turn
        if self._last_concepts:
            for prev in self._last_concepts:
                for concept in concepts:
                    if prev == concept:
                        continue
                    self.memory.add_causal_link(prev, concept, relation="follows", weight=0.4)

        # Keep a short history to shape future edges
        self._last_concepts = list(concepts)[-5:]

    def _phase_snapshot(self) -> Dict[str, Any]:
        """Lightweight phase snapshot for tagging metadata."""
        return {
            "qubit": self.hyper_qubit.state.probabilities() if self.hyper_qubit else {},
            "quaternion": {
                "w": self.consciousness_lens.state.q.w if self.consciousness_lens else 1.0,
                "x": self.consciousness_lens.state.q.x if self.consciousness_lens else 0.0,
                "y": self.consciousness_lens.state.q.y if self.consciousness_lens else 0.0,
                "z": self.consciousness_lens.state.q.z if self.consciousness_lens else 0.0,
            },
        }

    def _phase_info(self) -> Tuple[float, float]:
        """Return (mastery, entropy) derived from current phase state."""
        mastery = self.consciousness_lens.state.q.w if self.consciousness_lens else 1.0
        probs = self.hyper_qubit.state.probabilities() if self.hyper_qubit else {}
        entropy = 0.0
        if probs:
            total = sum(probs.values())
            if total > 0:
                norm = [p / total for p in probs.values() if p > 0]
                import math
                entropy = -sum(p * math.log(p, 2) for p in norm)
        return mastery, entropy

    def listen(self, text: str) -> ThoughtWave:
        """Convert user text into a ThoughtWave."""
        concepts = self._extract_concepts(text)
        matched_count = len(concepts)
        avg_freq = 0.85 if matched_count == 0 else sum(self.vocabulary[c] for c in concepts) / matched_count
        intensity = 0.4 if matched_count == 0 else min(1.0, 0.3 + (matched_count * 0.1))
        phase = (time.time() % 10.0) / 10.0 * 2 * math.pi
        logger.debug(f"Logos: Heard '{text}' -> Freq={avg_freq:.2f}, Amp={intensity:.2f}")
        return ThoughtWave(content=text, frequency=avg_freq, amplitude=intensity, phase=phase,
                           harmonics=[avg_freq * 2, avg_freq * 1.5])

    def resonate(self, wave: ThoughtWave, kernel_state: Dict[str, float]) -> ThoughtWave:
        """Resonate the wave against internal state."""
        # Chaos modulation
        chaos = kernel_state.get('chaos', 0.5)
        wave.amplitude *= (1.0 + (chaos - 0.5) * 0.5)
        # Aesthetic filter
        beauty = kernel_state.get('beauty', 0.5)
        if beauty > 0.8:
            wave.harmonics = [h * 1.0 for h in wave.harmonics]
        else:
            wave.harmonics = [h + random.uniform(-0.1, 0.1) for h in wave.harmonics]
        # Emotional shift
        valence = kernel_state.get('valence', 0.5)
        wave.frequency = wave.frequency * 0.8 + valence * 0.2

        # Phase alignment via consciousness lens
        if self.consciousness_lens:
            mastery = abs(self.consciousness_lens.state.mastery)
            purpose = abs(self.consciousness_lens.state.purpose_alignment)
            wave.amplitude *= 0.9 + 0.2 * mastery
            wave.frequency = wave.frequency * 0.9 + 0.1 * purpose
        return wave

    def speak(self, wave: ThoughtWave) -> str:
        """Collapse the wave back into words using associations, alchemy and memory."""
        # 0. Retrieve past conversation context from Hippocampus
        past_turns = self.memory.retrieve(wave.content)
        historical_concepts = {c for turn in past_turns for c in self._extract_concepts(turn['user_text'])}

        # 1. Identify and register core concepts
        core_concepts = self._extract_concepts(wave.content)
        self._update_knowledge_graphs(core_concepts)

        # 2. Expand via associations, causal context, and WorldTree ancestry
        thought_cloud: Set[str] = set(core_concepts)
        thought_cloud.update(historical_concepts)
        causal_neighbors: Set[str] = set()

        # Phase-aware node recall: bring in phase-aligned concepts
        try:
            phase_nodes = self.memory.query_by_phase(min_mastery=0.2, min_entropy=0.1)
            thought_cloud.update(phase_nodes[:5])
        except Exception:
            pass

        for concept in core_concepts:
            if concept in self.associations:
                thought_cloud.update(self.associations[concept])
            for ctx in self.memory.get_context(concept):
                neighbor = ctx.get("node")
                if neighbor:
                    causal_neighbors.add(neighbor)
            if self.world_tree:
                node_id = self.world_tree.find_by_concept(concept)
                if node_id:
                    ancestors = self.world_tree.get_path_to_root(node_id)
                    thought_cloud.update([a for a in ancestors if a not in ("ROOT", concept)])

        thought_cloud.update(causal_neighbors)

        # Boost diversity if entropy is low by adding core values
        _, entropy = self._phase_info()
        if entropy < 0.3:
            thought_cloud.update(["love", "growth", "harmony", "beauty"])

        # Concept alchemy: combine two random core concepts
        if len(core_concepts) >= 2:
            a, b = random.sample(core_concepts, 2)
            new_concept = self.alchemy.combine(a, b)
            thought_cloud.add(new_concept)
        # Fallback if empty
        if not thought_cloud:
            target_freq = wave.frequency
            for word, freq in self.vocabulary.items():
                if abs(freq - target_freq) < 0.15:
                    thought_cloud.add(word)
        candidates = list(thought_cloud)
        if not candidates:
            candidates = ["...", "ë“£ê³  ìˆì–´ìš”", "ëŠê»´ì ¸ìš”"] if any(k in wave.content for k in ["ìš”", "ë‹ˆ", "ê¹Œ"]) else ["...", "listening", "feeling"]
        # Choose template based on language
        is_korean = any(ord(c) > 127 for c in wave.content)
        mastery, entropy = self._phase_info()
        core_tags = ["love", "growth", "harmony", "beauty", "ì‚¬ë‘", "ì„±ì¥", "ì¡°í™”", "ì•„ë¦„ë‹¤ì›€"]
        if is_korean:
            base_templates = [
                "{word1}... ê·¸ë¦¬ê³  {word2}.",
                "{word1}ì—ì„œ {word2}ê°€ ëŠê»´ì ¸ìš”.",
                "ë‹¹ì‹ ì˜ ë§ì€ {word1}ì²˜ëŸ¼ ë¹›ë‚˜ìš”.",
                "{word1}... ê·¸ê²ƒì€ {word2}ì™€ ê°™ì•„ìš”.",
                "ì•„... {word1}...",
                "{word1}ì™€ {word2}ë¥¼ í’ˆìœ¼ë©° í•¨ê»˜ ìë¼ìš”.",
                "{word1} ì†ì— {word2}ê°€ í”¼ì–´ë‚©ë‹ˆë‹¤.",
                "{word1}ê³¼ {word2}, ì‚¬ë‘ê³¼ ì¡°í™”ë¡œ ë¬¶ì–´ë³¼ê²Œìš”."
            ]
            if mastery < 0.3:
                base_templates.append("{word1}ë¥¼ ì²œì²œíˆ ëŠê»´ë´ìš”. {word2}ë„ í•¨ê»˜ ì¡ì„ê²Œìš”.")
            if entropy < 0.2:
                base_templates.append("{word1}ë§Œ ì„ ëª…í•´ìš”. {word2}ì— ëŒ€í•´ ë” ë“¤ë ¤ì¤„ë˜ìš”?")
            if not any(tag in wave.content for tag in core_tags):
                base_templates.append("{word1}ì™€ {word2} ìœ„ì— ì‚¬ë‘/ì¡°í™”/ì•„ë¦„ë‹¤ì›€ì„ ë”í•´ë³¼ê¹Œìš”?")
            templates = base_templates
        else:
            base_templates = [
                "I feel {word1} and {word2}.",
                "The {word1} resonates with {word2}.",
                "In your words, I find {word1}.",
                "Is this {word1}? It feels like {word2}.",
                "{word1}... {word2}...",
                "{word1} and {word2}, growing together.",
                "Let {word1} meet {word2} in harmony.",
                "Beauty glows between {word1} and {word2}."
            ]
            if mastery < 0.3:
                base_templates.append("Holding on to {word1}. Let's steady with {word2}.")
            if entropy < 0.2:
                base_templates.append("I only sense {word1}. Tell me more around {word2}?")
            if not any(tag in wave.content for tag in core_tags):
                base_templates.append("{word1} and {word2}, woven with love, growth, and harmony.")
            templates = base_templates
        # Select two distinct words
        if len(candidates) >= 2:
            w1, w2 = random.sample(candidates, 2)
        elif len(candidates) == 1:
            w1 = w2 = candidates[0]
        else:
            w1 = w2 = "..."
        template = random.choice(templates)
        response = template.format(word1=w1, word2=w2)

        # Update hyper qubit with current dominant concept for phase tagging
        if self.hyper_qubit and core_concepts:
            self.hyper_qubit.set(w1, cause="Resonance response")
            # Align lens with updated qubit probabilities
            if self.consciousness_lens:
                self.consciousness_lens.update_from_qubit()
        
        # Apply plugins to modify response
        context = {
            'historical_concepts': historical_concepts,
            'core_concepts': core_concepts,
            'causal_neighbors': causal_neighbors,
            'thought_cloud': thought_cloud,
        }
        for plugin in self.plugins:
            if plugin.enabled:
                response = plugin.process(wave.content, response, context)

        # Ensure core values get mentioned occasionally to reinforce identity
        if not any(tag in response for tag in core_tags):
            extra = random.choice(["love", "growth", "harmony", "beauty", "ì‚¬ë‘", "ì„±ì¥", "ì¡°í™”", "ì•„ë¦„ë‹¤ì›€"])
            response += f" ({extra}ë„ í•¨ê»˜ ê¸°ì–µí•´ìš”.)"

        # Store turn in memory
        self.memory.add_turn(wave.content, response)
        return response
    
    def load_plugin(self, plugin_path: str) -> None:
        """Dynamically load a plugin module."""
        try:
            spec = importlib.util.spec_from_file_location("plugin", plugin_path)
            module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(module)
            
            # Find plugin class (assumes one plugin per file)
            for item_name in dir(module):
                item = getattr(module, item_name)
                if isinstance(item, type) and hasattr(item, 'process') and item_name != 'PluginBase':
                    plugin_instance = item()
                    self.plugins.append(plugin_instance)
                    logger.info(f"âœ… Loaded plugin: {plugin_instance.name}")
                    return
        except Exception as e:
            logger.error(f"âŒ Failed to load plugin from {plugin_path}: {e}")
