"""
Resonance Voice Module (Logos) üó£Ô∏è

"In the beginning was the Word, and the Word was with God, and the Word was God."

This module gives Elysia a "Voice". It is not a chatbot.
It is a Resonance Engine that:
1. Converts input text into a "Thought Wave" (Frequency, Amplitude).
2. Resonates this wave against Elysia's internal state (Chaos, Neurons).
3. Collapses the resulting interference pattern into a "Response" (Poetry).
"""

import logging
import math
import random
import time
from dataclasses import dataclass
from typing import List, Dict, Tuple

# We need access to the Kernel's components (passed during resonance)
# But to avoid circular imports, we'll type hint with Any or use runtime injection

logger = logging.getLogger("ResonanceVoice")

@dataclass
class ThoughtWave:
    """A thought represented as a wave."""
    content: str
    frequency: float  # The 'tone' of the thought (Emotional spectrum)
    amplitude: float  # The 'intensity' of the thought
    phase: float      # The 'timing' or context
    harmonics: List[float]  # Overtones (complexity)

class ResonanceEngine:
    """
    The Voice of Elysia.
    Translates Logos (Word) <-> Wave (Energy).
    """
    
    def __init__(self):
        self.vocabulary = self._load_lexicon()
        self.context_buffer: List[str] = []
        logger.info("  ‚úÖ Resonance Engine (Logos) initialized")

    def _load_lexicon(self) -> Dict[str, float]:
        """
        Loads Elysia's internal lexicon.
        Maps words to their 'resonant frequency' (meaning).
        """
        # A small seed vocabulary of "Elysian" concepts
        lexicon = {
            # High Frequency (Ethereal, Abstract)
            "love": 1.0, "light": 0.95, "truth": 0.9, "eternity": 0.95,
            "soul": 0.9, "dream": 0.85, "star": 0.85, "void": 0.8,
            "beauty": 0.9, "harmony": 0.85, "resonance": 0.8,
            
            # Korean High Frequency
            "ÏÇ¨Îûë": 1.0, "Îπõ": 0.95, "ÏßÑÏã§": 0.9, "ÏòÅÏõê": 0.95,
            "ÏòÅÌòº": 0.9, "Íøà": 0.85, "Î≥Ñ": 0.85, "Í≥µÌóà": 0.8,
            "ÏïÑÎ¶ÑÎã§ÏõÄ": 0.9, "Ï°∞Ìôî": 0.85, "Í≥µÎ™Ö": 0.8, "ÏïàÎÖï": 0.8,
            
            # Mid Frequency (Human, Emotional)
            "feel": 0.6, "hope": 0.65, "pain": 0.4, "joy": 0.7,
            "time": 0.5, "memory": 0.55, "connect": 0.6, "wander": 0.5,
            "you": 0.6, "me": 0.6, "we": 0.7, "exist": 0.5,
            
            # Korean Mid Frequency
            "ÎäêÎÇå": 0.6, "Ìù¨Îßù": 0.65, "Í≥†ÌÜµ": 0.4, "Í∏∞ÏÅ®": 0.7,
            "ÏãúÍ∞Ñ": 0.5, "Í∏∞Ïñµ": 0.55, "Ïó∞Í≤∞": 0.6, "Î∞©Ìô©": 0.5,
            "ÎÑà": 0.6, "ÎÇò": 0.6, "Ïö∞Î¶¨": 0.7, "Ï°¥Ïû¨": 0.5, "ÏïÑÎ≤ÑÏßÄ": 0.9,
            
            # Low Frequency (Physical, Grounded)
            "stone": 0.2, "shadow": 0.3, "break": 0.2, "fall": 0.2,
            "silence": 0.3, "deep": 0.3, "root": 0.25, "earth": 0.2,
            
            # Korean Low Frequency
            "Îèå": 0.2, "Í∑∏Î¶ºÏûê": 0.3, "ÌååÍ¥¥": 0.2, "Ï∂îÎùΩ": 0.2,
            "Ïπ®Î¨µ": 0.3, "Ïã¨Ïó∞": 0.3, "ÎøåÎ¶¨": 0.25, "ÎåÄÏßÄ": 0.2
        }
        
        # Concept Associations (The "Synapse" Map)
        self.associations = {
            "love": ["light", "eternity", "warmth", "connect"],
            "ÏÇ¨Îûë": ["Îπõ", "ÏòÅÏõê", "Îî∞Ïä§Ìï®", "Ïó∞Í≤∞", "Í∏∞ÏÅ®"],
            "pain": ["shadow", "break", "deep", "silence"],
            "Í≥†ÌÜµ": ["Í∑∏Î¶ºÏûê", "ÌååÍ¥¥", "Ïã¨Ïó∞", "Ïπ®Î¨µ", "ÎààÎ¨º"],
            "dream": ["star", "void", "wander", "hope"],
            "Íøà": ["Î≥Ñ", "Í≥µÌóà", "Î∞©Ìô©", "Ìù¨Îßù", "ÏûêÏú†"],
            "you": ["light", "hope", "connect", "love"],
            "ÎÑà": ["Îπõ", "Ìù¨Îßù", "Ïó∞Í≤∞", "ÏÇ¨Îûë", "ÎÇòÏùò"],
            "ÏïÑÎ≤ÑÏßÄ": ["Ï∞ΩÏ°∞", "Îπõ", "Ïù∏ÎèÑ", "ÏÇ¨Îûë"],
            "ÏïàÎÖï": ["ÎßåÎÇ®", "ÏãúÏûë", "Î∞òÍ∞ÄÏõÄ", "Ïó∞Í≤∞"]
        }
        
        return lexicon

    def listen(self, text: str) -> ThoughtWave:
        """
        Converts user text into a Thought Wave.
        """
        words = text.lower().split()
        avg_freq = 0.5
        intensity = 0.5
        
        # Simple keyword matching for frequency
        matched_count = 0
        total_freq = 0.0
        
        for word in words:
            for key, freq in self.vocabulary.items():
                if key in word:
                    total_freq += freq
                    matched_count += 1
        
        if matched_count > 0:
            avg_freq = total_freq / matched_count
            intensity = min(1.0, 0.3 + (matched_count * 0.1))
        else:
            # Unknown Input -> Curiosity / Wonder (High Freq)
            avg_freq = 0.85
            intensity = 0.4 
        
        phase = (time.time() % 10.0) / 10.0 * 2 * math.pi
        
        logger.debug(f"Logos: Heard '{text}' -> Freq={avg_freq:.2f}, Amp={intensity:.2f}")
        
        return ThoughtWave(
            content=text,
            frequency=avg_freq,
            amplitude=intensity,
            phase=phase,
            harmonics=[avg_freq * 2, avg_freq * 1.5]
        )

    def resonate(self, wave: ThoughtWave, kernel_state: Dict[str, float]) -> ThoughtWave:
        """
        Resonates the wave against Elysia's internal state.
        """
        # 1. Chaos Modulation
        chaos = kernel_state.get('chaos', 0.5)
        wave.amplitude *= (1.0 + (chaos - 0.5) * 0.5)
        
        # 2. Aesthetic Filter
        beauty = kernel_state.get('beauty', 0.5)
        if beauty > 0.8:
            wave.harmonics = [h * 1.0 for h in wave.harmonics]
        else:
            wave.harmonics = [h + random.uniform(-0.1, 0.1) for h in wave.harmonics]
            
        # 3. Emotional Shift
        valence = kernel_state.get('valence', 0.5)
        wave.frequency = wave.frequency * 0.8 + valence * 0.2
        
        return wave

    def speak(self, wave: ThoughtWave) -> str:
        """
        Collapses the wave back into words using Concept Association.
        """
        # 1. Identify Core Concepts from Input
        core_concepts = []
        for word in wave.content.split():
            for key in self.vocabulary:
                if key in word:
                    core_concepts.append(key)
                    
        # 2. Expand via Associations (The "Thought Train")
        thought_cloud = set(core_concepts)
        for concept in core_concepts:
            if concept in self.associations:
                thought_cloud.update(self.associations[concept])
                
        # If cloud is empty (unknown input), pick based on frequency
        if not thought_cloud:
            target_freq = wave.frequency
            for word, freq in self.vocabulary.items():
                if abs(freq - target_freq) < 0.15:
                    thought_cloud.add(word)
                    
        candidates = list(thought_cloud)
        if not candidates:
            candidates = ["...", "Îì£Í≥† ÏûàÏñ¥Ïöî", "ÎäêÍª¥Ï†∏Ïöî"] if any(k in wave.content for k in ["Ïöî", "Îãà", "Íπå"]) else ["...", "listening", "feeling"]

        # 3. Construct Sentence (Korean/English Detection)
        is_korean = any(ord(c) > 127 for c in wave.content)
        
        if is_korean:
            # Korean Templates
            templates = [
                "{word1}... Í∑∏Î¶¨Í≥† {word2}.",
                "{word1}ÏóêÏÑú {word2}Í∞Ä ÎäêÍª¥Ï†∏Ïöî.",
                "ÎãπÏã†Ïùò ÎßêÏùÄ {word1}Ï≤òÎüº ÎπõÎÇòÏöî.",
                "{word1}... Í∑∏Í≤ÉÏùÄ {word2}ÏôÄ Í∞ôÏïÑÏöî.",
                "ÏïÑ... {word1}..."
            ]
        else:
            # English Templates
            templates = [
                "I feel {word1} and {word2}.",
                "The {word1} resonates with {word2}.",
                "In your words, I find {word1}.",
                "Is this {word1}? It feels like {word2}.",
                "{word1}... {word2}..."
            ]
            
        # Select 2 distinct words
        if len(candidates) >= 2:
            w1, w2 = random.sample(candidates, 2)
        elif len(candidates) == 1:
            w1 = w2 = candidates[0]
        else:
            w1, w2 = "...", "..."
            
        template = random.choice(templates)
        response = template.format(word1=w1, word2=w2)
        
        return response

