"""
Logos Engine (The Rhetorical Bridge)
====================================
"In the beginning was the Word, and the Word was with God."

The Logos Engine is responsible for the *Art of Speech*.
It takes raw, abstract insights from the ReasoningEngine and transforms them
into sophisticated, culturally rich, and metaphorically resonant language.

It acts as the "Harmonizer" between:
1. Logic (CausalNarrativeEngine) - The Skeleton
2. Metaphor (InternalUniverse) - The Flesh
3. Expression (DialogueInterface) - The Voice
"""

import logging
import random
import re
import json
from pathlib import Path
from collections import defaultdict
from typing import List, Optional, Union
from Core.Foundation.internal_universe import InternalUniverse
from Core.Foundation.reasoning_engine import Insight
from Core.Foundation.Math.wave_tensor import WaveTensor
from Core.Foundation.fractal_concept import ConceptDecomposer # AXIOM INTEGRATION

logger = logging.getLogger("LogosEngine")

class LogosEngine:
    def __init__(self):
        self.universe = InternalUniverse()
        self.decomposer = ConceptDecomposer() # THE AXIOM BRIDGE
        self.genome_path = Path("Core/Memory/style_genome.json")
        self.genome = self._load_genome()
        logger.info(f"ğŸ—£ï¸ Logos Engine Initialized with Axiom System. Evolution Stage: {self.genome.get('evolution_stage', 0)}")
        
        # Rhetorical Templates (Default)
        self.transition_matrix = {
            "thesis": ["ê·¼ë³¸ì ìœ¼ë¡œ,", "ìš°ì„ ,", "í•µì‹¬ì„ ì§šì–´ë³´ìë©´,"],
            "antithesis": ["í—ˆë‚˜,", "ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³ ,", "ë°˜ë©´,", "í•˜ì§€ë§Œ ê¹Šì´ ë“¤ì—¬ë‹¤ë³´ë©´,"],
            "synthesis": ["ê²°êµ­,", "ë”°ë¼ì„œ,", "ì´ëŸ¬í•œ ëª¨ìˆœ ì†ì—ì„œ ì €ëŠ” ê¹¨ë‹«ìŠµë‹ˆë‹¤.", "ê· í˜•ì€ ê·¸ ì‚¬ì´ì— ìˆìŠµë‹ˆë‹¤."]
        }
        
    def _load_genome(self):
        if not self.genome_path.exists():
            return {"rhetoric": {"vocabulary_bank": {}}}
        try:
            with open(self.genome_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.warning(f"Failed to load genome: {e}")
            return {"rhetoric": {"vocabulary_bank": {}}}

    def weave_speech(self, desire: str, insight: Union[Insight, str], context: List[str], rhetorical_shape: str = "Balance", entropy: float = 0.3) -> str:
        """
        Weaves Logic, Metaphor, and Narrative.
        Now includes 'Entropy' (0.0 - 1.0) to simulate organic imperfection.
        """
        # Handle simple string insights
        content = insight.content if hasattr(insight, 'content') else str(insight)
        
        # 0. Entropy Check: Sometimes, just be raw (Human-like)
        # Lowered chance (changed from 0.5 factor to 0.2) to prefer styled output
        if random.random() < entropy * 0.2:
             # Raw, direct response without rhetorical flourish
            return f"{content}"

        # 1. Select Vocabulary Bank based on Shape
        # Entropy allows mixing vocabularies (e.g. Sharp words in Round structure)
        if random.random() < entropy:
            # Mix registers (Removed 'Block' to prevent random System messages in conversation)
            rhetorical_shape = random.choice(["Sharp", "Round", "Balance"])
            
        # 1.5 Try using Learned Templates (The Linguistic Bridge)
        learned_templates = self.genome.get("rhetoric", {}).get("templates", {})
        
        # Map shape to template type
        template_type_map = {
            "Block": "Definition",
            "Balance": "Contrast", 
            "Sharp": "Causal",
            "Round": "Conditional"
        }
        target_type = template_type_map.get(rhetorical_shape, "Definition")
        
        if target_type in learned_templates and learned_templates[target_type]:
             # High chance to use template if available
             if random.random() < 0.9:
                 template = random.choice(learned_templates[target_type])
                 
                 # Pattern Filling Logic (Style Injection)
                 parts = template.split(',')
                 if len(parts) > 1:
                     context_part = parts[0].strip() # "ìš´ëª…ì€ ì”í˜¹í•˜ì§€ë§Œ"
                     return f"{context_part}, {content}."
                 else:
                     # Fallback for definitions "AëŠ” Bì´ë‹¤"
                     # If template is "AëŠ” Bì´ë‹¤", replace A with our topic?
                     # Simple: Just append content for flow
                     return f"{template} {content}"

        vocab = self._get_vocab_for_shape(rhetorical_shape)
        
        # 2. Construct Sentence Structure
        # Entropy disrupts the perfect grammar/structure
        
        # 2. Construct Sentence Structure (Paragraph Level)
        # Entropy disrupts the perfect grammar/structure
        
        if rhetorical_shape == "Sharp": # Action / Conflict
            # Chain: Opener -> Action -> Consequence
            p1 = random.choice(vocab['openers'])
            p2 = random.choice(vocab['verbs'])
            p3 = random.choice(vocab['closers'])
            
            # Make it a sequence for impact
            return f"{p1} {content}. {p2}...... {p3}!"
            
        elif rhetorical_shape == "Round": # Magic / Mystery
            # Chain: Atmosphere -> Connection -> Revelation
            p1 = random.choice(vocab['openers'])
            p2 = random.choice(vocab['connectors'])
            p3 = random.choice(vocab['closers'])
            
            # Poetic flow
            return f"{p1}, {content}... {p2}, ë§ˆì¹¨ë‚´ {p3}."
            
        elif rhetorical_shape == "Block": # System / Logic
            p1 = random.choice(vocab['openers'])
            # Systems are concise, but let's make it detailed
            return f"[{p1}] {content} :: [í”„ë¡œì„¸ìŠ¤ í™•ì •] -> ê²°ê³¼ ë„ì¶œ."
            
        elif rhetorical_shape == "Synthesis": # Higher Order
            # Sometimes fail to synthesize (Open-ended)
            if random.random() < entropy:
                return f"{content}... ì´ê²ƒì´ ê³¼ì—° ì •ë‹µì¼ê¹Œìš”? í•´ë‹µì€ ì¹¨ë¬µ ì†ì— ìˆìŠµë‹ˆë‹¤."
                
            p1 = random.choice(vocab['openers'])
            return f"{p1} {content}. ê·¸ê²ƒì´ ìš°ë¦¬ê°€ ë‚˜ì•„ê°€ì•¼ í•  ê¸¸ì…ë‹ˆë‹¤."
            
        else: # Balance / Default
            # Construct a Micro-Dialectic (Thesis -> Antithesis -> Synthesis)
            opener = random.choice(vocab['openers'])
            connector = random.choice(vocab['connectors'])
            closer = random.choice(vocab['closers'])
            
            # A full paragraph
            return f"{opener} {content}. {connector} ê·¸ ì´ë©´ì—ëŠ” ë‹¤ë¥¸ ì§„ì‹¤ì´ ìˆ¨ì‰¬ê³  ìˆìŠµë‹ˆë‹¤. {closer}"

    def _get_vocab_for_shape(self, shape: str) -> dict:
        """Returns vocabulary keyed by geometric feel (Korean Manhwa Style) + Learned Genome."""
        
        # Base Vocab
        base_vocab = {}
        if shape == "Sharp":
            base_vocab = {
                "openers": ["ë² ì–´ë¼.", "ë‹¨ìˆ¨ì—.", "ì§€ê¸ˆì´ë‹¤.", "ëš«ì–´ë²„ë ¤.", "ë§ì„¤ì´ì§€ ë§ˆë¼."],
                "verbs": ["íŒŒê´´í•œë‹¤", "ì°¢ì–´ë°œê¸´ë‹¤", "ê´€í†µí•œë‹¤", "ëë‚¸ë‹¤"],
                "closers": ["ì ì„.", "ì´ í™˜ìƒì„.", "ì•½í•œ ë§ˆìŒì„.", "ëª¨ë“  ê²ƒì„."]
            }
        elif shape == "Round":
            base_vocab = {
                "openers": ["íë¦„ì„ ëŠê»´ë¼.", "ë§ˆë ¥ì´ ìš”ë™ì¹œë‹¤.", "ì‹¬ì—°ì˜ ëì—ì„œ,", "ìš´ëª…ì˜ ìˆ˜ë ˆë°”í€´ê°€,"],
                "connectors": ["ìˆœí™˜í•˜ë©°", "ê¹Šì–´ì§€ê³ ", "ê³µëª…í•˜ì—¬"],
                "closers": ["í•˜ë‚˜ê°€ ëœë‹¤.", "ì§„ì‹¤ì„ ë¹„ì¶˜ë‹¤.", "ì–´ë‘ ì„ ì‚¼í‚¨ë‹¤."]
            }
        elif shape == "Block":
            base_vocab = {
                "openers": ["[ì‹œìŠ¤í…œ] ë¶„ì„ ì™„ë£Œ.", "[ì •ë³´] ì¡°ê±´ ì¶©ì¡±.", "í€˜ìŠ¤íŠ¸ ê°±ì‹ :", "ë°ì´í„° ë¡œë“œ:"],
                "connectors": ["->", "í™•ì¸:", "ê²°ê³¼:"],
                "closers": ["ì ìš©ë¨.", "ë³´ìƒ íšë“.", "í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ."]
            }
        else: # Balance
            base_vocab = {
                "openers": ["ë³¸ì§ˆì ìœ¼ë¡œ,", "ì–´ì©Œë©´,", "í•µì‹¬ì€,", "ëŒì´ì¼œë³´ë©´,"],
                "connectors": ["í—ˆë‚˜", "ê·¸ëŸ¼ì—ë„", "ê²°êµ­"],
                "closers": ["ë‹µì„ ì°¾ì„ ê²ƒì´ë‹¤.", "ê·¸ê²ƒì´ ì§„ì‹¤ì´ë‹¤.", "ê· í˜•ì´ í•„ìš”í•˜ë‹¤."]
            }
            
        # Inject Learned Vocab
        learned_words = self.genome.get("rhetoric", {}).get("vocabulary_bank", {}).get(shape, [])
        if learned_words:
            # Distribute learned words into verbs/closers randomly or heuristically
            # For now, just add to 'verbs' or 'connectors' to ensure usage
            target_key = "verbs" if "verbs" in base_vocab else "connectors"
            base_vocab[target_key].extend(learned_words)
            
        return base_vocab

    def _scan_for_sensory_anchor(self, context: List[str]) -> Optional[str]:
        """
        Scans retrieved memories for sensory descriptions.
        """
        if not context:
            return None
            
        # We look for phrases injected by InternalUniverse or SensoryCortex
        # "scent of", "taste of", "feeling of Green High Pitch", etc.
        
        for memory in context:
            # Check for specific sensory markers we generated in Phase 31/32
            if "scent of" in memory:
                return self._extract_fragment(memory, "scent of")
            if "taste" in memory:
                return self._extract_fragment(memory, "taste")
            if "sounded like" in memory:
                return self._extract_fragment(memory, "sounded like")
            if "feeling of" in memory:
                # e.g., "A feeling of Green High Pitch" -> "ê·¸ ì´ˆë¡ë¹› ê³ ìŒì˜ ê°ê°" (Transcreated)
                return "ê·¸ ê°•ë ¬í•œ ê°ê°" # Simplifying for naturalness, or extract detail
                
        return None

    def _extract_fragment(self, text: str, keyword: str) -> str:
        """Extracts the relevant sensory phrase."""
        try:
            # Simple extraction: take the keyword and the next 5 words
            parts = text.split(keyword)
            if len(parts) > 1:
                fragment = keyword + parts[1].split('.')[0]
                return fragment.strip()
        except:
            pass
        return text[:20]

    def _determine_axis(self, content: str, wave: Optional[WaveTensor] = None) -> str:
        """Determines if the thought is Logical, Emotional, or Ethical."""
        # Wave-based override
        if wave:
            # High Entropy/Dissonance -> Emotion/Chaos
            # Low Entropy/Harmonic -> Logic/Order
            if wave.total_energy > 4.0: return "Will" # High Energy
            
        text = content.lower()
        if any(w in text for w in ["feel", "sad", "joy", "pain", "love", "ê°ì •", "ë§ˆìŒ", "ìŠ¬í””"]):
            return "Emotion"
        elif any(w in text for w in ["logic", "reason", "because", "structure", "ë…¼ë¦¬", "ì´ìœ ", "êµ¬ì¡°"]):
            return "Logic"
        elif any(w in text for w in ["should", "must", "right", "wrong", "ê°€ì¹˜", "ì˜³ì€", "ë„ë•"]):
            return "Value"
        return "Balance"

    def _mine_metaphor(self, axis: str, content: str, wave: Optional[WaveTensor] = None) -> str:
        """
        Consults the Internal Universe to find a resonator (Fallback).
        Uses Wave Frequency to select metaphor register if available.
        """
        # Wave Frequency Mapping
        register = "Balance"
        if wave and wave.active_frequencies:
            dom_freq = wave.active_frequencies[0]
            if dom_freq < 200: register = "Earth" # Low/Deep
            elif dom_freq < 500: register = "Water" # Mid/Warm
            elif dom_freq < 800: register = "Air" # High/Clear
            else: register = "Fire" # Very High/Intense
        
        metaphors = {
            "Emotion": [
                "ë§ˆì¹˜ ê²¨ìš¸ ë°”ë‹¤ì˜ íŒŒë„ì²˜ëŸ¼,", 
                "ì‹¬ì¥ ê¹Šì€ ê³³ì—ì„œ ìš¸ë¦¬ëŠ” ì¢…ì†Œë¦¬ì²˜ëŸ¼,",
                "ë¹„ ì˜¨ ë’¤ì˜ ì –ì€ í™ë‚´ìŒì²˜ëŸ¼,"
            ],
            # ... (Existing lists) ...
            "Earth": ["ëŒ€ì§€ì— ë¿Œë¦¬ ë‚´ë¦° ê³ ëª©ì²˜ëŸ¼,", "ê¹Šì€ ë™êµ´ì˜ ìš¸ë¦¼ì²˜ëŸ¼,", "ë‹¨ë‹¨í•œ ë°”ìœ„ì²˜ëŸ¼,"],
            "Water": ["ìœ ìœ íˆ íë¥´ëŠ” ê°•ë¬¼ì²˜ëŸ¼,", "ê¹Šì€ í˜¸ìˆ˜ì˜ ì¹¨ë¬µì²˜ëŸ¼,", "ìƒˆë²½ ì´ìŠ¬ì²˜ëŸ¼,"],
            "Air": ["ë°”ëŒì— ì‹¤ë ¤ê°€ëŠ” êµ¬ë¦„ì²˜ëŸ¼,", "ë§‘ì€ í•˜ëŠ˜ì˜ ìƒˆì²˜ëŸ¼,", "íˆ¬ëª…í•œ ìœ ë¦¬ì²˜ëŸ¼,"],
            "Fire": ["íƒ€ì˜¤ë¥´ëŠ” í˜œì„±ì²˜ëŸ¼,", "ë²ˆê°œì²˜ëŸ¼ ê°•ë ¬í•˜ê²Œ,", "íƒœì–‘ì˜ ì—´ê¸°ì²˜ëŸ¼,"],
            
            "Logic": [
                "ì •êµí•˜ê²Œ ë§ë¬¼ë¦° ì‹œê³„íƒœì—½ì²˜ëŸ¼,", 
                "ì°¨ê°€ìš´ ëŒ€ë¦¬ì„ ì¡°ê°ì²˜ëŸ¼,",
                "ë³„ë“¤ì˜ ê¶¤ë„ì²˜ëŸ¼ ëª…í™•í•˜ê²Œ,"
            ],
            "Value": [
                "ì˜¤ë˜ëœ ë‚˜ë¬´ì˜ ë¿Œë¦¬ì²˜ëŸ¼,",
                "ìƒˆë²½ì˜ ì²« ë¹›ì²˜ëŸ¼,",
                "ë³€í•˜ì§€ ì•ŠëŠ” ë¶ê·¹ì„±ì²˜ëŸ¼,"
            ],
            "Will": [
                "íƒ€ì˜¤ë¥´ëŠ” ë¶ˆê½ƒì²˜ëŸ¼,",
                "ë°”ìœ„ë¥¼ ëš«ëŠ” ë¬¼ë°©ìš¸ì²˜ëŸ¼,",
                "í­í’ ì†ì˜ ë“±ëŒ€ì²˜ëŸ¼,"
            ],
            "Balance": [
                "íë¥´ëŠ” ê°•ë¬¼ì²˜ëŸ¼,",
                "ê³ ìš”í•œ í˜¸ìˆ˜ì²˜ëŸ¼,",
                "ë°”ëŒì— í”ë“¤ë¦¬ëŠ” ê°ˆëŒ€ì²˜ëŸ¼,"
            ]
        }
        
        # Priority: Register (Physics) > Axis (Semantic)
        choices = metaphors.get(register, metaphors.get(axis, metaphors["Balance"]))
        chosen = random.choice(choices)
        return f"{chosen}"

    def _construct_dialectic(self, desire: str, raw_thought: str, axis: str) -> dict:
        """
        Splits the raw thought into a structured argument.
        """
        # Extract keywords from raw thought
        # Example raw_thought: "'Love' is painful but necessary."
        
        # Thesis: The initial assertion
        thesis_start = random.choice(self.transition_matrix["thesis"])
        thesis = f"{thesis_start} {raw_thought}"
        
        # Antithesis: The deeper nuance or contradiction (Paradox)
        antithesis_start = random.choice(self.transition_matrix["antithesis"])
        
        if axis == "Emotion":
            antithesis_content = "ê·¸ ê°ì •ì˜ ë¬´ê²Œê°€ ë•Œë¡œëŠ” ì €ë¥¼ ì§“ëˆ„ë¥´ê¸°ë„ í•©ë‹ˆë‹¤."
        elif axis == "Logic":
            antithesis_content = "í—ˆë‚˜ ë…¼ë¦¬ë§Œìœ¼ë¡œëŠ” ì„¤ëª…ë˜ì§€ ì•ŠëŠ” ì˜ì—­ì´ ì¡´ì¬í•©ë‹ˆë‹¤."
        elif axis == "Value":
            antithesis_content = "í•˜ì§€ë§Œ ì ˆëŒ€ì ì¸ ì •ë‹µì€ ì—†ì„ì§€ë„ ëª¨ë¦…ë‹ˆë‹¤."
        else:
            antithesis_content = "ë³´ì´ëŠ” ê²ƒì´ ì „ë¶€ëŠ” ì•„ë‹ ê²ƒì…ë‹ˆë‹¤."
            
        antithesis = f"{antithesis_start} {antithesis_content}"
        
        # Synthesis: The resolution
        synthesis_start = random.choice(self.transition_matrix["synthesis"])
        synthesis = f"{synthesis_start} ì €ëŠ” ê·¸ ì†ì—ì„œ ì˜ë¯¸ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤."
        
        return {
            "thesis": thesis,
            "antithesis": antithesis,
            "synthesis": synthesis
        }
    
    def reason_with_axiom(self, concept: str, domain: str = "Ethics") -> str:
        """
        Generate a principled explanation using Universal Axioms.
        
        The Axiom system projects universal principles onto specific domains,
        then uses causal_bonds to explain relationships.
        
        Args:
            concept: The concept to explain (e.g., "Love", "Fear")
            domain: The domain lens to apply (e.g., "Geometry", "Language", "Physics", "Ethics")
            
        Returns:
            A rhetorically structured, causally grounded explanation.
        """
        # 1. Get causal explanation from the decomposer
        causal_explanation = self.decomposer.explain_causality(concept)
        
        # 2. Project the relevant axiom (Causality) onto the domain for context
        axiom_context = self.decomposer.project_axiom("Causality", domain)
        
        # 3. Compose the final speech using Logos patterns
        opener = random.choice(self.transition_matrix["thesis"])
        connector = random.choice(self.transition_matrix["antithesis"])
        closer = random.choice(self.transition_matrix["synthesis"])
        
        speech = f"{opener} {causal_explanation}\n"
        speech += f"{connector} ì´ê²ƒì€ '{axiom_context}'ë¼ëŠ” ë³´í¸ ì›ë¦¬ì™€ ê°™ì€ êµ¬ì¡°ì…ë‹ˆë‹¤.\n"
        speech += f"{closer}"
        
        return speech
