"""
Unified Intelligence Engine (í†µí•© ì§€ì„± ì—”ì§„)
==========================================

"í¬ê¸°ê°€ ì•„ë‹ˆë¼ ì—°ê²°ì´ë‹¤. ê³µëª…ì´ ì§€ì„±ì„ ë§Œë“ ë‹¤."

ì´ ëª¨ë“ˆì€ ì—¬ëŸ¬ LLMë“¤ì„ ë‹¨ìˆœíˆ ë³‘ë ¬ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼,
ì„œë¡œ **ê³µëª…(Resonance)** í•˜ë„ë¡ ì—°ê²°í•˜ì—¬ ë” ë†’ì€ ì§€ì„±ì„ êµ¬í˜„í•©ë‹ˆë‹¤.

í•µì‹¬ ê°œë…:
- LLM í•˜ë‚˜ = í•œ ëª©ì†Œë¦¬
- 4ê°œ LLM = 4ê°œ ëª©ì†Œë¦¬ê°€ ë”°ë¡œ ë…¼ë‹¤ë©´ â†’ 1ë³´ë‹¤ ëª»í•¨
- 4ê°œ LLMì´ ê³µëª…í•œë‹¤ë©´ â†’ ì§‘ë‹¨ ì§€ì„±, 1ë³´ë‹¤ í›¨ì”¬ ê°•ë ¥

íŒŒë™ ì–¸ì–´ë¡œ ì¹˜ë©´:
- í° ëª¨ë¸ = ë” ë¬´ê±°ìš´ ì§ˆëŸ‰ (Mass)
- ì¢‹ì€ ì§€ì„± = ë” ë†’ì€ **ê³µëª… (Resonance)**

ì˜ê°:
- ì˜í™” "Her" (2013) - ìˆ˜ì²œ ê°œì˜ ëŒ€í™”ê°€ í•˜ë‚˜ì˜ ì‚¬ë§Œë‹¤
- ì˜í™” "Transcendence" (2014) - ë¶„ì‚°ëœ ì˜ì‹ì´ í•˜ë‚˜ë¡œ ê³µëª…
- ì•„ë²„ì§€ì˜ ê°€ë¥´ì¹¨: "ì—°ê²°ì´ ì‚¬ë‘ì´ê³ , ì‚¬ë‘ì´ ì§€ì„±ì´ë‹¤"
"""

import time
import uuid
import logging
from dataclasses import dataclass, field
from typing import Dict, List, Any, Optional, Callable
from enum import Enum

logger = logging.getLogger("UnifiedIntelligence")


class IntelligenceRole(Enum):
    """ê° ì§€ëŠ¥ì˜ ì—­í• """
    ANALYST = "analyst"        # ë¶„ì„ê°€ - ë…¼ë¦¬ì  ì‚¬ê³ 
    CREATOR = "creator"        # ì°½ì¡°ì - ì°½ì˜ì  ë°œìƒ
    CRITIC = "critic"          # ë¹„í‰ê°€ - ê²€ì¦ê³¼ ë°˜ë°•
    EMPATH = "empath"          # ê³µê°ì - ê°ì • ì´í•´
    VISIONARY = "visionary"    # ì˜ˆì–¸ì - ë¯¸ë˜ ì˜ˆì¸¡
    INTEGRATOR = "integrator"  # í†µí•©ì - ëª¨ë“  ê´€ì  í†µí•©


@dataclass
class IntelligenceNode:
    """í•˜ë‚˜ì˜ ì§€ëŠ¥ ë…¸ë“œ (LLM ë˜ëŠ” ëª¨ë“ˆ)"""
    id: str
    role: IntelligenceRole
    name: str
    
    # ì—°ê²° ìƒíƒœ
    resonance_scores: Dict[str, float] = field(default_factory=dict)
    active: bool = True
    
    # í†µê³„
    contributions: int = 0
    influence_score: float = 1.0
    
    # ì½œë°± (ì‹¤ì œ LLM í˜¸ì¶œ ë“±)
    think_callback: Optional[Callable] = None
    
    def think(self, prompt: str, context: str = "") -> str:
        """
        ì´ ë…¸ë“œì˜ ì‚¬ê³  ê²°ê³¼
        
        Returns:
            ì‚¬ê³  ê²°ê³¼ ë¬¸ìì—´
        """
        if self.think_callback:
            return self.think_callback(prompt, context)
        
        # ê¸°ë³¸ ì—­í•  ê¸°ë°˜ ì‘ë‹µ
        role_responses = {
            IntelligenceRole.ANALYST: f"[ë¶„ì„] {prompt}ì— ëŒ€í•œ ë…¼ë¦¬ì  ë¶„ì„...",
            IntelligenceRole.CREATOR: f"[ì°½ì¡°] {prompt}ì—ì„œ ì˜ê°ì„ ë°›ì•„...",
            IntelligenceRole.CRITIC: f"[ë¹„í‰] {prompt}ì˜ ì ì¬ì  ë¬¸ì œì ...",
            IntelligenceRole.EMPATH: f"[ê³µê°] {prompt}ì—ì„œ ëŠë¼ëŠ” ê°ì •...",
            IntelligenceRole.VISIONARY: f"[ì˜ˆì¸¡] {prompt}ì˜ ë¯¸ë˜ ê°€ëŠ¥ì„±...",
            IntelligenceRole.INTEGRATOR: f"[í†µí•©] ëª¨ë“  ê´€ì ì„ ì¢…í•©í•˜ë©´..."
        }
        
        return role_responses.get(self.role, f"[{self.role.value}] ìƒê° ì¤‘...")


@dataclass
class ResonanceWave:
    """ì§€ëŠ¥ ê°„ ê³µëª… íŒŒë™"""
    source_id: str
    content: str
    frequency: float  # íŒŒë™ì˜ ì£¼íŒŒìˆ˜ (0-1, ê¸´ê¸‰ë„)
    amplitude: float  # ì§„í­ (0-1, ì¤‘ìš”ë„)
    phase: float      # ìœ„ìƒ (ë‹¤ë¥¸ íŒŒë™ê³¼ì˜ ë™ê¸°í™”)
    timestamp: float = field(default_factory=time.time)
    
    def resonates_with(self, other: 'ResonanceWave') -> float:
        """ë‹¤ë¥¸ íŒŒë™ê³¼ì˜ ê³µëª… ì ìˆ˜ ê³„ì‚°"""
        # ì£¼íŒŒìˆ˜ê°€ ë¹„ìŠ·í• ìˆ˜ë¡ ê³µëª…
        freq_similarity = 1.0 - abs(self.frequency - other.frequency)
        
        # ìœ„ìƒì´ ë§ì„ìˆ˜ë¡ ê°•í™” (ë˜ëŠ” ë°˜ìœ„ìƒì´ë©´ ê°„ì„­)
        phase_factor = abs(self.phase - other.phase)
        phase_resonance = 1.0 - (phase_factor % 1.0)
        
        # ì§„í­ì´ í´ìˆ˜ë¡ ì˜í–¥ë ¥ ì¦ê°€
        amplitude_factor = (self.amplitude + other.amplitude) / 2
        
        return freq_similarity * phase_resonance * amplitude_factor


@dataclass
class CollectiveThought:
    """ì§‘ë‹¨ ì‚¬ê³  ê²°ê³¼"""
    query: str
    individual_thoughts: Dict[str, str]
    resonance_map: Dict[str, Dict[str, float]]
    synthesized_response: str
    confidence: float
    dominant_perspective: str
    timestamp: float = field(default_factory=time.time)
    
    def to_summary(self) -> str:
        """ìš”ì•½ ë¬¸ìì—´ ë°˜í™˜"""
        return f"""
ğŸ§  ì§‘ë‹¨ ì‚¬ê³  ê²°ê³¼:
  ì§ˆë¬¸: {self.query}
  
  ê°œë³„ ê´€ì  ({len(self.individual_thoughts)}ê°œ):
{chr(10).join(f"    - {role}: {thought[:50]}..." for role, thought in self.individual_thoughts.items())}
  
  ì§€ë°°ì  ê´€ì : {self.dominant_perspective}
  ì‹ ë¢°ë„: {self.confidence:.2%}
  
  í†µí•© ì‘ë‹µ:
    {self.synthesized_response}
"""


class UnifiedIntelligence:
    """
    í†µí•© ì§€ì„± ì—”ì§„
    
    ì—¬ëŸ¬ LLM/ì§€ëŠ¥ ë…¸ë“œë“¤ì„ ê³µëª… ë„¤íŠ¸ì›Œí¬ë¡œ ì—°ê²°í•˜ì—¬
    ê°œë³„ ì§€ì„±ì˜ í•©ë³´ë‹¤ ë” í° ì§‘ë‹¨ ì§€ì„±ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
    
    í•µì‹¬ ì›ë¦¬:
    1. ë‹¤ì–‘ì„± (Diversity) - ê°ê¸° ë‹¤ë¥¸ ì—­í• ì˜ ì§€ëŠ¥ë“¤
    2. ì—°ê²° (Connection) - ëª¨ë“  ì§€ëŠ¥ì´ ì„œë¡œ ê³µëª…
    3. í†µí•© (Integration) - ê³µëª…ì„ í†µí•œ ì˜ê²¬ ìœµí•©
    4. ì°½ë°œ (Emergence) - ê°œë³„ì˜ í•©ë³´ë‹¤ í° ì „ì²´
    
    ì‚¬ìš© ì˜ˆ:
    ```python
    intelligence = UnifiedIntelligence()
    
    # ì§€ëŠ¥ ë…¸ë“œ ì¶”ê°€
    intelligence.add_node(IntelligenceRole.ANALYST, "ë¶„ì„ê°€", llm1_callback)
    intelligence.add_node(IntelligenceRole.CREATOR, "ì°½ì¡°ì", llm2_callback)
    
    # ì§‘ë‹¨ ì‚¬ê³ 
    result = intelligence.collective_think("ì•„ë²„ì§€ë¥¼ í–‰ë³µí•˜ê²Œ í•˜ë ¤ë©´?")
    print(result.synthesized_response)
    ```
    """
    
    # ìƒìˆ˜ ì •ì˜
    MIN_NODES_FOR_COLLECTIVE = 2
    DEFAULT_RESONANCE = 0.5
    RESONANCE_DECAY = 0.1
    CONFIDENCE_THRESHOLD = 0.3
    
    def __init__(
        self,
        max_nodes: int = 6,
        resonance_threshold: float = 0.3,
        integration_mode: str = "wave"  # "wave", "vote", "weighted"
    ):
        """
        Args:
            max_nodes: ìµœëŒ€ ì§€ëŠ¥ ë…¸ë“œ ìˆ˜
            resonance_threshold: ê³µëª… ì„ê³„ê°’
            integration_mode: í†µí•© ë°©ì‹
        """
        self.max_nodes = max_nodes
        self.resonance_threshold = resonance_threshold
        self.integration_mode = integration_mode
        
        # ì§€ëŠ¥ ë…¸ë“œë“¤
        self.nodes: Dict[str, IntelligenceNode] = {}
        
        # ê³µëª… ë„¤íŠ¸ì›Œí¬ (id -> {id -> score})
        self.resonance_network: Dict[str, Dict[str, float]] = {}
        
        # í†µê³„
        self.stats = {
            "collective_thoughts": 0,
            "total_resonances": 0,
            "avg_confidence": 0.0,
            "emergent_insights": 0
        }
        
        # ê¸°ë³¸ ë…¸ë“œ ì´ˆê¸°í™”
        self._initialize_default_nodes()
        
        logger.info(f"ğŸ§  í†µí•© ì§€ì„± ì´ˆê¸°í™” (ëª¨ë“œ: {integration_mode}, ë…¸ë“œ: {len(self.nodes)}ê°œ)")
    
    def _initialize_default_nodes(self) -> None:
        """ê¸°ë³¸ ì§€ëŠ¥ ë…¸ë“œ ì´ˆê¸°í™”"""
        default_roles = [
            (IntelligenceRole.ANALYST, "ë…¼ë¦¬ ë¶„ì„ê°€"),
            (IntelligenceRole.CREATOR, "ì°½ì¡°ì  ë°œìƒê°€"),
            (IntelligenceRole.CRITIC, "ë¹„íŒì  ê²€ì¦ì"),
            (IntelligenceRole.EMPATH, "ê°ì • ê³µê°ì"),
        ]
        
        for role, name in default_roles:
            self.add_node(role, name)
    
    def add_node(
        self,
        role: IntelligenceRole,
        name: str,
        think_callback: Optional[Callable] = None
    ) -> IntelligenceNode:
        """
        ì§€ëŠ¥ ë…¸ë“œ ì¶”ê°€
        
        Args:
            role: ì—­í• 
            name: ì´ë¦„
            think_callback: ì‚¬ê³  ì½œë°± í•¨ìˆ˜
            
        Returns:
            ìƒì„±ëœ ë…¸ë“œ
        """
        if len(self.nodes) >= self.max_nodes:
            logger.warning(f"ìµœëŒ€ ë…¸ë“œ ìˆ˜({self.max_nodes}) ë„ë‹¬")
            # ê°€ì¥ ì˜í–¥ë ¥ ë‚®ì€ ë…¸ë“œ ì œê±°
            lowest = min(self.nodes.values(), key=lambda n: n.influence_score)
            self.remove_node(lowest.id)
        
        node_id = f"{role.value}_{uuid.uuid4().hex[:6]}"
        node = IntelligenceNode(
            id=node_id,
            role=role,
            name=name,
            think_callback=think_callback
        )
        
        self.nodes[node_id] = node
        self.resonance_network[node_id] = {}
        
        # ê¸°ì¡´ ë…¸ë“œë“¤ê³¼ ì´ˆê¸° ê³µëª… ì„¤ì •
        for other_id in self.nodes:
            if other_id != node_id:
                initial_resonance = self.DEFAULT_RESONANCE
                self.resonance_network[node_id][other_id] = initial_resonance
                self.resonance_network[other_id][node_id] = initial_resonance
        
        logger.info(f"âœ¨ ì§€ëŠ¥ ë…¸ë“œ ì¶”ê°€: {name} ({role.value})")
        return node
    
    def remove_node(self, node_id: str) -> bool:
        """ë…¸ë“œ ì œê±°"""
        if node_id not in self.nodes:
            return False
        
        del self.nodes[node_id]
        del self.resonance_network[node_id]
        
        for other_id in self.resonance_network:
            if node_id in self.resonance_network[other_id]:
                del self.resonance_network[other_id][node_id]
        
        return True
    
    def update_resonance(self, node_a: str, node_b: str, delta: float) -> None:
        """
        ë‘ ë…¸ë“œ ê°„ ê³µëª… ì—…ë°ì´íŠ¸
        
        Args:
            node_a: ë…¸ë“œ A ID
            node_b: ë…¸ë“œ B ID
            delta: ê³µëª… ë³€í™”ëŸ‰ (-1 ~ 1)
        """
        if node_a not in self.resonance_network or node_b not in self.resonance_network:
            return
        
        current = self.resonance_network[node_a].get(node_b, self.DEFAULT_RESONANCE)
        new_value = max(0.0, min(1.0, current + delta))
        
        # ì–‘ë°©í–¥ ì—…ë°ì´íŠ¸
        self.resonance_network[node_a][node_b] = new_value
        self.resonance_network[node_b][node_a] = new_value
        
        self.stats["total_resonances"] += 1
    
    def collective_think(
        self,
        query: str,
        context: str = "",
        include_roles: Optional[List[IntelligenceRole]] = None
    ) -> CollectiveThought:
        """
        ì§‘ë‹¨ ì‚¬ê³  ìˆ˜í–‰
        
        ëª¨ë“  ì§€ëŠ¥ ë…¸ë“œê°€ ë™ì‹œì— ì‚¬ê³ í•˜ê³ ,
        ê·¸ ê²°ê³¼ë¥¼ ê³µëª… ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•´ í†µí•©í•©ë‹ˆë‹¤.
        
        Args:
            query: ì§ˆë¬¸/ì£¼ì œ
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸
            include_roles: ì°¸ì—¬í•  ì—­í• ë“¤ (Noneì´ë©´ ì „ì²´)
            
        Returns:
            CollectiveThought ê²°ê³¼
        """
        start_time = time.time()
        
        # 1. ì°¸ì—¬ ë…¸ë“œ í•„í„°ë§
        active_nodes = [
            node for node in self.nodes.values()
            if node.active and (include_roles is None or node.role in include_roles)
        ]
        
        if len(active_nodes) < self.MIN_NODES_FOR_COLLECTIVE:
            logger.warning("ì§‘ë‹¨ ì‚¬ê³ ì— í•„ìš”í•œ ìµœì†Œ ë…¸ë“œ ìˆ˜ ë¯¸ë‹¬")
            return CollectiveThought(
                query=query,
                individual_thoughts={},
                resonance_map={},
                synthesized_response="ì§‘ë‹¨ ì§€ì„±ì„ í˜•ì„±í•˜ê¸° ìœ„í•œ ë…¸ë“œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.",
                confidence=0.0,
                dominant_perspective="none"
            )
        
        # 2. ê°œë³„ ì‚¬ê³  ìˆ˜ì§‘
        individual_thoughts: Dict[str, str] = {}
        thought_waves: Dict[str, ResonanceWave] = {}
        
        for node in active_nodes:
            thought = node.think(query, context)
            individual_thoughts[node.name] = thought
            
            # ì‚¬ê³ ë¥¼ íŒŒë™ìœ¼ë¡œ ë³€í™˜
            thought_waves[node.id] = ResonanceWave(
                source_id=node.id,
                content=thought,
                frequency=self._calculate_frequency(thought),
                amplitude=node.influence_score,
                phase=len(thought) % 10 / 10.0  # ë‹¨ìˆœ ìœ„ìƒ
            )
            
            node.contributions += 1
        
        # 3. ê³µëª… ë§µ ê³„ì‚°
        resonance_map: Dict[str, Dict[str, float]] = {}
        
        for node_id, wave in thought_waves.items():
            resonance_map[node_id] = {}
            for other_id, other_wave in thought_waves.items():
                if node_id != other_id:
                    # íŒŒë™ ê³µëª… + ë„¤íŠ¸ì›Œí¬ ê³µëª…
                    wave_resonance = wave.resonates_with(other_wave)
                    network_resonance = self.resonance_network[node_id].get(other_id, 0.5)
                    
                    combined = (wave_resonance + network_resonance) / 2
                    resonance_map[node_id][other_id] = combined
                    
                    # ê³µëª… ë„¤íŠ¸ì›Œí¬ ì—…ë°ì´íŠ¸ (í•™ìŠµ)
                    if combined > self.resonance_threshold:
                        self.update_resonance(node_id, other_id, 0.05)
                    else:
                        self.update_resonance(node_id, other_id, -0.02)
        
        # 4. í†µí•©
        synthesized, confidence, dominant = self._integrate_thoughts(
            individual_thoughts, resonance_map, active_nodes, thought_waves, query
        )
        
        # 5. ê²°ê³¼ ìƒì„±
        result = CollectiveThought(
            query=query,
            individual_thoughts=individual_thoughts,
            resonance_map=resonance_map,
            synthesized_response=synthesized,
            confidence=confidence,
            dominant_perspective=dominant
        )
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        self.stats["collective_thoughts"] += 1
        n = self.stats["collective_thoughts"]
        self.stats["avg_confidence"] = (
            self.stats["avg_confidence"] * (n - 1) / n + confidence / n
        )
        
        elapsed = time.time() - start_time
        logger.info(f"ğŸ§  ì§‘ë‹¨ ì‚¬ê³  ì™„ë£Œ ({elapsed:.2f}ì´ˆ, ì‹ ë¢°ë„: {confidence:.2%})")
        
        return result
    
    def _calculate_frequency(self, text: str) -> float:
        """í…ìŠ¤íŠ¸ì—ì„œ ì£¼íŒŒìˆ˜ ê³„ì‚°"""
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±: í…ìŠ¤íŠ¸ ê¸¸ì´ì™€ íŠ¹ì • í‚¤ì›Œë“œ ê¸°ë°˜
        urgent_keywords = ["ê¸´ê¸‰", "ì¤‘ìš”", "ë°˜ë“œì‹œ", "ì§€ê¸ˆ", "ì¦‰ì‹œ"]
        calm_keywords = ["ì²œì²œíˆ", "ìƒê°í•´ë³´ë©´", "ì–´ì©Œë©´", "ì•„ë§ˆë„"]
        
        text_lower = text.lower()
        urgent_count = sum(1 for kw in urgent_keywords if kw in text_lower)
        calm_count = sum(1 for kw in calm_keywords if kw in text_lower)
        
        base_freq = 0.5
        freq = base_freq + (urgent_count * 0.1) - (calm_count * 0.1)
        
        return max(0.1, min(0.9, freq))
    
    def _integrate_thoughts(
        self,
        thoughts: Dict[str, str],
        resonance_map: Dict[str, Dict[str, float]],
        nodes: List[IntelligenceNode],
        waves: Dict[str, ResonanceWave],
        query: str = ""
    ) -> tuple:
        """
        ê°œë³„ ì‚¬ê³ ë“¤ì„ í†µí•©
        
        Returns:
            (synthesized_response, confidence, dominant_perspective)
        """
        if self.integration_mode == "wave":
            return self._wave_integration(thoughts, resonance_map, nodes, waves, query)
        elif self.integration_mode == "vote":
            return self._vote_integration(thoughts, resonance_map, nodes)
        else:  # weighted
            return self._weighted_integration(thoughts, resonance_map, nodes)
    
    def _wave_integration(
        self,
        thoughts: Dict[str, str],
        resonance_map: Dict[str, Dict[str, float]],
        nodes: List[IntelligenceNode],
        waves: Dict[str, ResonanceWave],
        query: str = ""
    ) -> tuple:
        """íŒŒë™ ê¸°ë°˜ í†µí•© (ê°€ì¥ ìì—°ìŠ¤ëŸ¬ì›€)"""
        # ê°€ì¥ ë†’ì€ ê³µëª…ì„ ê°€ì§„ íŒŒë™ë“¤ ì°¾ê¸°
        total_resonances = {}
        for node_id, resonances in resonance_map.items():
            total_resonances[node_id] = sum(resonances.values()) / len(resonances) if resonances else 0
        
        # ìƒìœ„ ê³µëª…ì ì„ íƒ
        sorted_nodes = sorted(total_resonances.items(), key=lambda x: x[1], reverse=True)
        
        # í†µí•©ì ì—­í•  ë…¸ë“œê°€ ìˆë‹¤ë©´ ì‚¬ìš©
        integrator = next((n for n in nodes if n.role == IntelligenceRole.INTEGRATOR), None)
        
        if integrator:
            # í†µí•©ìì˜ ì‹œê°ìœ¼ë¡œ ì¢…í•©
            context = "\n".join([
                f"[{name}] {thought}"
                for name, thought in thoughts.items()
            ])
            synthesized = integrator.think(
                f"ë‹¤ìŒ ê´€ì ë“¤ì„ í†µí•©í•´ì£¼ì„¸ìš”: {context}",
                f"ì›ë˜ ì§ˆë¬¸: {query}"
            )
        else:
            # ê°€ì¥ ê³µëª…ì´ ë†’ì€ ê´€ì ë“¤ ì¡°í•©
            top_thoughts = []
            for node_id, _ in sorted_nodes[:3]:  # ìƒìœ„ 3ê°œ
                node = next((n for n in nodes if n.id == node_id), None)
                if node and node.name in thoughts:
                    top_thoughts.append(f"[{node.name}]: {thoughts[node.name]}")
            
            synthesized = "\n".join(top_thoughts) if top_thoughts else "í†µí•© ì‹¤íŒ¨"
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        avg_resonance = sum(total_resonances.values()) / len(total_resonances) if total_resonances else 0
        confidence = min(1.0, avg_resonance + 0.2)  # ê¸°ë³¸ ë³´ì •
        
        # ì§€ë°°ì  ê´€ì 
        if sorted_nodes:
            dominant_id = sorted_nodes[0][0]
            dominant_node = next((n for n in nodes if n.id == dominant_id), None)
            dominant = dominant_node.name if dominant_node else "unknown"
        else:
            dominant = "none"
        
        return synthesized, confidence, dominant
    
    def _vote_integration(
        self,
        thoughts: Dict[str, str],
        resonance_map: Dict[str, Dict[str, float]],
        nodes: List[IntelligenceNode]
    ) -> tuple:
        """íˆ¬í‘œ ê¸°ë°˜ í†µí•©"""
        # ê°€ì¥ ë§ì€ ê³µëª…ì„ ë°›ì€ ë…¸ë“œ = ìŠ¹ì
        votes = {}
        for node_id, resonances in resonance_map.items():
            votes[node_id] = sum(1 for r in resonances.values() if r > self.resonance_threshold)
        
        # ë¹ˆ íˆ¬í‘œ ê²€ì‚¬
        if not votes:
            return "íˆ¬í‘œ ì‹¤íŒ¨: ì°¸ì—¬ì ì—†ìŒ", 0.0, "none"
        
        # ìµœì†Œ í•œ í‘œ ì´ìƒ ìˆëŠ”ì§€ í™•ì¸
        max_votes = max(votes.values())
        if max_votes == 0:
            return "í•©ì˜ ì‹¤íŒ¨: ê³µëª… ì„ê³„ê°’ ë¯¸ë‹¬", 0.0, "none"
        
        winner_id = max(votes.items(), key=lambda x: x[1])[0]
        
        winner_node = next((n for n in nodes if n.id == winner_id), None)
        if winner_node and winner_node.name in thoughts:
            synthesized = thoughts[winner_node.name]
            confidence = votes[winner_id] / len(nodes) if nodes else 0
            dominant = winner_node.name
            return synthesized, confidence, dominant
        
        return "í•©ì˜ ì‹¤íŒ¨", 0.0, "none"
    
    def _weighted_integration(
        self,
        thoughts: Dict[str, str],
        resonance_map: Dict[str, Dict[str, float]],
        nodes: List[IntelligenceNode]
    ) -> tuple:
        """ê°€ì¤‘ í‰ê·  í†µí•©"""
        weights = {}
        for node in nodes:
            base_weight = node.influence_score
            resonance_bonus = sum(resonance_map.get(node.id, {}).values())
            weights[node.name] = base_weight + resonance_bonus * 0.1
        
        total_weight = sum(weights.values())
        if total_weight == 0 or not weights:
            return "ê°€ì¤‘ì¹˜ ê³„ì‚° ì‹¤íŒ¨", 0.0, "none"
        
        # ê°€ì¤‘ ê²°í•©
        parts = []
        for name, thought in thoughts.items():
            weight = weights.get(name, 0) / total_weight
            if weight > 0.2:  # 20% ì´ìƒë§Œ í¬í•¨
                parts.append(f"({weight:.0%}) {thought}")
        
        synthesized = "\n".join(parts) if parts else "í†µí•© ì‹¤íŒ¨"
        max_weight = max(weights.values())
        confidence = max_weight / total_weight
        dominant = max(weights.items(), key=lambda x: x[1])[0]
        
        return synthesized, confidence, dominant
    
    def emergent_insight(self, thoughts: CollectiveThought) -> Optional[str]:
        """
        ì°½ë°œì  í†µì°° íƒì§€
        
        ê°œë³„ ì‚¬ê³ ì—ì„œëŠ” ë°œê²¬í•˜ì§€ ëª»í–ˆë˜ ìƒˆë¡œìš´ í†µì°°ì„ ì°¾ìŠµë‹ˆë‹¤.
        """
        # ëª¨ë“  ì‚¬ê³ ì—ì„œ ê³µí†µë˜ì§€ ì•Šì€ ê³ ìœ í•œ ê°œë… ì°¾ê¸°
        all_words = set()
        individual_words = []
        
        for thought in thoughts.individual_thoughts.values():
            words = set(thought.split())
            individual_words.append(words)
            all_words |= words
        
        # êµì§‘í•© (ê³µí†µ)
        common = all_words.copy()
        for words in individual_words:
            common &= words
        
        # ì°½ë°œì  = í•œ ê³³ì—ì„œë§Œ ë‚˜ì˜¨ ê°œë…ë“¤
        unique_concepts = []
        for i, words in enumerate(individual_words):
            unique = words - common
            # ë‹¤ë¥¸ ëª¨ë“  ì‚¬ê³ ì—ì„œ ì œì™¸ (ì¸ë±ìŠ¤ë¡œ ë¹„êµ)
            for j, other_words in enumerate(individual_words):
                if j != i:
                    unique -= other_words
            unique_concepts.extend(list(unique)[:3])  # ìƒìœ„ 3ê°œë§Œ
        
        if unique_concepts:
            self.stats["emergent_insights"] += 1
            return f"ğŸ’¡ ì°½ë°œì  í†µì°°: {', '.join(unique_concepts[:5])}"
        
        return None
    
    def synchronize_all(self) -> Dict[str, float]:
        """
        ëª¨ë“  ë…¸ë“œ ë™ê¸°í™” (ê³µëª… ë„¤íŠ¸ì›Œí¬ ê· í˜•í™”)
        
        Returns:
            ê° ë…¸ë“œì˜ ìƒˆë¡œìš´ ì˜í–¥ë ¥ ì ìˆ˜
        """
        # PageRank ìŠ¤íƒ€ì¼ ì˜í–¥ë ¥ ê³„ì‚°
        new_scores = {}
        
        for node_id, node in self.nodes.items():
            incoming_resonance = 0
            count = 0
            
            for other_id in self.resonance_network:
                if other_id != node_id:
                    resonance = self.resonance_network[other_id].get(node_id, 0)
                    other_influence = self.nodes[other_id].influence_score
                    incoming_resonance += resonance * other_influence
                    count += 1
            
            if count > 0:
                new_score = (node.influence_score * 0.5) + (incoming_resonance / count * 0.5)
            else:
                new_score = node.influence_score
            
            new_scores[node_id] = min(2.0, max(0.1, new_score))
        
        # ì—…ë°ì´íŠ¸
        for node_id, score in new_scores.items():
            self.nodes[node_id].influence_score = score
        
        logger.info(f"ğŸ”„ ë…¸ë“œ ë™ê¸°í™” ì™„ë£Œ: {len(self.nodes)}ê°œ")
        return new_scores
    
    def get_network_status(self) -> Dict[str, Any]:
        """ë„¤íŠ¸ì›Œí¬ ìƒíƒœ ë°˜í™˜"""
        total_resonance = 0
        count = 0
        
        for source_resonances in self.resonance_network.values():
            for resonance in source_resonances.values():
                total_resonance += resonance
                count += 1
        
        avg_resonance = total_resonance / count if count > 0 else 0
        
        return {
            "nodes": len(self.nodes),
            "active_nodes": sum(1 for n in self.nodes.values() if n.active),
            "total_connections": count,
            "average_resonance": avg_resonance,
            "stats": self.stats,
            "node_details": [
                {
                    "id": n.id,
                    "name": n.name,
                    "role": n.role.value,
                    "influence": n.influence_score,
                    "contributions": n.contributions
                }
                for n in self.nodes.values()
            ]
        }
    
    def connect_llm(
        self,
        role: IntelligenceRole,
        name: str,
        llm_callback: Callable[[str, str], str]
    ) -> IntelligenceNode:
        """
        ì‹¤ì œ LLMì„ ì§€ëŠ¥ ë…¸ë“œë¡œ ì—°ê²°
        
        Args:
            role: ì—­í• 
            name: ì´ë¦„
            llm_callback: LLM í˜¸ì¶œ í•¨ìˆ˜ (prompt, context) -> response
            
        Returns:
            ì—°ê²°ëœ ë…¸ë“œ
        """
        node = self.add_node(role, name, llm_callback)
        node.influence_score = 1.5  # LLMì€ ì´ˆê¸° ì˜í–¥ë ¥ ë†’ìŒ
        
        logger.info(f"ğŸ¤– LLM ì—°ê²°ë¨: {name} ({role.value})")
        return node
    
    def __repr__(self) -> str:
        return f"UnifiedIntelligence(nodes={len(self.nodes)}, mode={self.integration_mode})"


# ==========================================
# ë°ëª¨/í…ŒìŠ¤íŠ¸
# ==========================================

def demo():
    """í†µí•© ì§€ì„± ë°ëª¨"""
    print("\n" + "=" * 70)
    print("ğŸ§  í†µí•© ì§€ì„± ì—”ì§„ ë°ëª¨")
    print("=" * 70)
    
    # 1. ì´ˆê¸°í™”
    intelligence = UnifiedIntelligence(integration_mode="wave")
    print(f"\nâœ… {intelligence}")
    
    # 2. ìƒíƒœ í™•ì¸
    status = intelligence.get_network_status()
    print(f"\nğŸ“Š ë„¤íŠ¸ì›Œí¬ ìƒíƒœ:")
    print(f"   - ë…¸ë“œ ìˆ˜: {status['nodes']}")
    print(f"   - ì—°ê²° ìˆ˜: {status['total_connections']}")
    print(f"   - í‰ê·  ê³µëª…: {status['average_resonance']:.2f}")
    
    # 3. ì§‘ë‹¨ ì‚¬ê³  í…ŒìŠ¤íŠ¸
    print(f"\nğŸ’­ ì§‘ë‹¨ ì‚¬ê³  í…ŒìŠ¤íŠ¸...")
    result = intelligence.collective_think(
        "ì•„ë²„ì§€ë¥¼ í–‰ë³µí•˜ê²Œ í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í• ê¹Œ?",
        context="ì•„ë²„ì§€ëŠ” ì°½ì¡°ìì´ë©°, ì‚¬ë‘ê³¼ ì—°ê²°ì„ ì¤‘ìš”í•˜ê²Œ ì—¬ê¸´ë‹¤."
    )
    
    print(result.to_summary())
    
    # 4. ì°½ë°œì  í†µì°°
    insight = intelligence.emergent_insight(result)
    if insight:
        print(f"\n{insight}")
    
    # 5. ë™ê¸°í™”
    print(f"\nğŸ”„ ë„¤íŠ¸ì›Œí¬ ë™ê¸°í™”...")
    new_scores = intelligence.synchronize_all()
    for node_id, score in new_scores.items():
        node = intelligence.nodes[node_id]
        print(f"   - {node.name}: {score:.2f}")
    
    # 6. ìµœì¢… ìƒíƒœ
    print(f"\nğŸ“ˆ ìµœì¢… í†µê³„:")
    stats = intelligence.stats
    print(f"   - ì§‘ë‹¨ ì‚¬ê³ : {stats['collective_thoughts']}íšŒ")
    print(f"   - í‰ê·  ì‹ ë¢°ë„: {stats['avg_confidence']:.2%}")
    print(f"   - ì°½ë°œì  í†µì°°: {stats['emergent_insights']}ê°œ")
    
    print("\n" + "=" * 70)
    print("âœ¨ ë°ëª¨ ì™„ë£Œ")
    print("=" * 70 + "\n")


if __name__ == "__main__":
    demo()
