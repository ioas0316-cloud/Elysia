"""
Resonance Vision - íŒŒë™ ê¸°ë°˜ ì‹œê° ì‹œìŠ¤í…œ
=====================================

"ë‚˜ëŠ” ë¹›ì˜ íŒŒë™ì„ ëŠë‚€ë‹¤."

OpenCV/Pytesseract ì—†ì´ë„ í™”ë©´ì„ 'ê³µëª…'ìœ¼ë¡œ ì¸ì‹í•˜ëŠ” ì‹œìŠ¤í…œ.

ì›ë¦¬:
1. í™”ë©´ í”½ì…€ â†’ ìƒ‰ìƒ íŒŒë™ìœ¼ë¡œ ë³€í™˜
2. ë°ê¸°/ìƒ‰ìƒ íŒ¨í„´ â†’ HyperQubit ê³µëª…ìœ¼ë¡œ í•´ì„
3. í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€ â†’ íŒŒë™ ë°€ë„ ë¶„ì„
4. ê°ì²´ ì¸ì‹ â†’ ê³µëª… íŒ¨í„´ ë§¤ì¹­

"OCRì€ ê¸°ê³„ì ì´ë‹¤. ê³µëª…ì€ ì˜ì‹ì´ë‹¤."
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

import numpy as np
import logging
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass
from PIL import Image

from Core.Mind.hyper_qubit import HyperQubit, QubitState
from Core.Mind.perception import FractalPerception

logger = logging.getLogger("ResonanceVision")


@dataclass
class VisualResonance:
    """ì‹œê° ê³µëª… ìƒíƒœ"""
    dominant_color: Tuple[int, int, int]  # RGB
    color_harmony: float  # ìƒ‰ìƒ ì¡°í™”ë„ (0-1)
    brightness: float  # ë°ê¸° (0-1)
    contrast: float  # ëŒ€ë¹„ (0-1)
    complexity: float  # ë³µì¡ë„ (0-1)
    text_density: float  # í…ìŠ¤íŠ¸ ë°€ë„ ì¶”ì • (0-1)
    emotional_tone: str  # "warm", "cool", "neutral", "energetic"
    qubit_state: HyperQubit  # ì „ì²´ í™”ë©´ì˜ ì–‘ì ìƒíƒœ
    

class ResonanceVision:
    """
    íŒŒë™ ê¸°ë°˜ ì‹œê° ì‹œìŠ¤í…œ
    
    í™”ë©´ì„ í”½ì…€ì´ ì•„ë‹Œ 'ê³µëª…'ìœ¼ë¡œ ì¸ì‹í•œë‹¤.
    """
    
    def __init__(self):
        """Initialize resonance vision system"""
        self.perception = FractalPerception(vocabulary={})
        
        # ìƒ‰ìƒ ê³µëª… ë§µ (ìƒ‰ìƒ â†’ ê°ì • íŒŒë™)
        self.color_resonance = {
            "red": {"energy": 0.9, "warmth": 0.8, "danger": 0.7},
            "blue": {"calm": 0.8, "cold": 0.6, "trust": 0.7},
            "green": {"life": 0.9, "growth": 0.7, "calm": 0.6},
            "yellow": {"joy": 0.8, "energy": 0.7, "warmth": 0.6},
            "purple": {"mystery": 0.8, "creativity": 0.7, "luxury": 0.6},
            "orange": {"enthusiasm": 0.8, "warmth": 0.7, "energy": 0.6},
            "white": {"purity": 0.9, "light": 0.8, "clarity": 0.7},
            "black": {"mystery": 0.7, "power": 0.6, "void": 0.8},
        }
        
        logger.info("ğŸŒŠ Resonance Vision initialized (íŒŒë™ ê¸°ë°˜ ì‹œê°)")
    
    def perceive_image(self, image_path: str) -> VisualResonance:
        """
        ì´ë¯¸ì§€ë¥¼ íŒŒë™ìœ¼ë¡œ ì¸ì‹
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        
        Returns:
            VisualResonance: ì‹œê° ê³µëª… ìƒíƒœ
        """
        try:
            img = Image.open(image_path)
            
            # 1. ìƒ‰ìƒ íŒŒë™ ë¶„ì„
            dominant_color, color_harmony = self._analyze_color_waves(img)
            
            # 2. ë°ê¸°/ëŒ€ë¹„ íŒŒë™
            brightness, contrast = self._analyze_luminance_waves(img)
            
            # 3. ë³µì¡ë„ (ì—”íŠ¸ë¡œí”¼)
            complexity = self._analyze_complexity(img)
            
            # 4. í…ìŠ¤íŠ¸ ë°€ë„ ì¶”ì • (ì—ì§€ ë°€ë„)
            text_density = self._estimate_text_density(img)
            
            # 5. ê°ì • í†¤
            emotional_tone = self._determine_emotional_tone(
                dominant_color, brightness, complexity
            )
            
            # 6. ì „ì²´ í™”ë©´ â†’ HyperQubit ìƒíƒœ
            qubit_state = self._image_to_qubit(
                dominant_color, brightness, color_harmony, complexity
            )
            
            resonance = VisualResonance(
                dominant_color=dominant_color,
                color_harmony=color_harmony,
                brightness=brightness,
                contrast=contrast,
                complexity=complexity,
                text_density=text_density,
                emotional_tone=emotional_tone,
                qubit_state=qubit_state
            )
            
            logger.info(f"ğŸ‘ï¸ Visual Resonance: {emotional_tone} (brightness={brightness:.2f}, text_density={text_density:.2f})")
            
            return resonance
            
        except Exception as e:
            logger.error(f"Vision resonance failed: {e}")
            return None
    
    def _analyze_color_waves(self, img: Image.Image) -> Tuple[Tuple[int, int, int], float]:
        """
        ìƒ‰ìƒ íŒŒë™ ë¶„ì„
        
        Returns:
            (dominant_color, harmony)
        """
        # Resize for speed
        img_small = img.resize((100, 100))
        pixels = np.array(img_small)
        
        # RGB í‰ê·  (ì£¼ìš” ìƒ‰ìƒ)
        if len(pixels.shape) == 3:
            avg_color = pixels.mean(axis=(0, 1))[:3]  # RGB only
            dominant_color = tuple(avg_color.astype(int))
            
            # ìƒ‰ìƒ ì¡°í™”ë„ (í‘œì¤€í¸ì°¨ê°€ ë‚®ì„ìˆ˜ë¡ ì¡°í™”ë¡œì›€)
            color_std = pixels.std(axis=(0, 1))[:3].mean()
            harmony = 1.0 / (1.0 + color_std / 100.0)
        else:
            # Grayscale
            dominant_color = (128, 128, 128)
            harmony = 0.8
        
        return dominant_color, harmony
    
    def _analyze_luminance_waves(self, img: Image.Image) -> Tuple[float, float]:
        """
        ë°ê¸°/ëŒ€ë¹„ íŒŒë™ ë¶„ì„
        
        Returns:
            (brightness, contrast)
        """
        # Convert to grayscale
        gray = img.convert('L')
        pixels = np.array(gray.resize((100, 100)))
        
        # ë°ê¸° (0-1)
        brightness = pixels.mean() / 255.0
        
        # ëŒ€ë¹„ (í‘œì¤€í¸ì°¨)
        contrast = pixels.std() / 127.0
        
        return brightness, contrast
    
    def _analyze_complexity(self, img: Image.Image) -> float:
        """
        ë³µì¡ë„ ë¶„ì„ (ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜)
        
        Returns:
            complexity (0-1)
        """
        gray = img.convert('L')
        pixels = np.array(gray.resize((50, 50)))
        
        # ê°„ë‹¨í•œ ì—ì§€ ê°ì§€ (ì°¨ë¶„)
        edges_h = np.abs(np.diff(pixels, axis=0)).sum()
        edges_v = np.abs(np.diff(pixels, axis=1)).sum()
        
        total_edges = edges_h + edges_v
        max_possible = 50 * 50 * 255 * 2
        
        complexity = min(1.0, total_edges / max_possible * 10)
        
        return complexity
    
    def _estimate_text_density(self, img: Image.Image) -> float:
        """
        í…ìŠ¤íŠ¸ ë°€ë„ ì¶”ì • (ì—ì§€ íŒ¨í„´ ê¸°ë°˜)
        
        í…ìŠ¤íŠ¸ëŠ” ì¼ë°˜ì ìœ¼ë¡œ:
        - ì¤‘ê°„ ì •ë„ì˜ ë³µì¡ë„
        - ì¼ì •í•œ ê°„ê²©ì˜ ì—ì§€
        - ì¤‘ê°„~ë†’ì€ ëŒ€ë¹„
        
        Returns:
            text_density (0-1)
        """
        gray = img.convert('L')
        pixels = np.array(gray.resize((100, 100)))
        
        # ìˆ˜í‰ ì—ì§€ (í…ìŠ¤íŠ¸ ë¼ì¸)
        edges_h = np.abs(np.diff(pixels, axis=0))
        h_density = (edges_h > 30).sum() / edges_h.size
        
        # ìˆ˜ì§ ì—ì§€ (ê¸€ì ê°„ê²©)
        edges_v = np.abs(np.diff(pixels, axis=1))
        v_density = (edges_v > 30).sum() / edges_v.size
        
        # í…ìŠ¤íŠ¸ëŠ” ìˆ˜í‰ ì—ì§€ê°€ ë” ê°•í•¨
        text_likelihood = h_density * 1.5 + v_density * 0.5
        
        return min(1.0, text_likelihood * 3)
    
    def _determine_emotional_tone(
        self,
        color: Tuple[int, int, int],
        brightness: float,
        complexity: float
    ) -> str:
        """
        ê°ì • í†¤ ê²°ì •
        
        Args:
            color: RGB ìƒ‰ìƒ
            brightness: ë°ê¸°
            complexity: ë³µì¡ë„
        
        Returns:
            emotional_tone
        """
        r, g, b = color
        
        # ë”°ëœ»í•¨ (ë¹¨ê°•/ë…¸ë‘ ì„±ë¶„)
        warmth = (r + g * 0.5) / 255.0
        
        # ì°¨ê°€ì›€ (íŒŒë‘ ì„±ë¶„)
        coolness = b / 255.0
        
        # ì—ë„ˆì§€ (ë³µì¡ë„ + ë°ê¸°)
        energy = (complexity + brightness) / 2.0
        
        if warmth > 0.6 and energy > 0.5:
            return "energetic"
        elif coolness > 0.6 and brightness < 0.5:
            return "cool"
        elif warmth > 0.5:
            return "warm"
        else:
            return "neutral"
    
    def _image_to_qubit(
        self,
        color: Tuple[int, int, int],
        brightness: float,
        harmony: float,
        complexity: float
    ) -> HyperQubit:
        """
        ì´ë¯¸ì§€ â†’ HyperQubit ìƒíƒœ ë³€í™˜
        
        íŒŒë™ì˜ ë³¸ì§ˆì„ ì–‘ì ìƒíƒœë¡œ í¬ì°©í•œë‹¤.
        
        Args:
            color: RGB ìƒ‰ìƒ
            brightness: ë°ê¸°
            harmony: ì¡°í™”ë„
            complexity: ë³µì¡ë„
        
        Returns:
            HyperQubit ìƒíƒœ
        """
        r, g, b = [c / 255.0 for c in color]
        
        # Alpha: ë°ê¸° (Real) + ì¡°í™” (Imaginary)
        alpha = complex(brightness, harmony * 0.5)
        
        # Beta: ìƒ‰ìƒ (R+G ì„±ë¶„)
        beta = complex((r + g) / 2.0, 0.0)
        
        # Gamma: ìƒ‰ìƒ (B ì„±ë¶„) + ë³µì¡ë„
        gamma = complex(b, complexity * 0.5)
        
        # Delta: ì „ì²´ ì—ë„ˆì§€
        delta = complex((brightness + complexity) / 2.0, 0.0)
        
        state = QubitState(
            alpha=alpha,
            beta=beta,
            gamma=gamma,
            delta=delta
        )
        
        # HyperQubit ìƒì„± í›„ ìƒíƒœ ì„¤ì •
        qubit = HyperQubit(concept_or_value="VisualResonance", name="ScreenResonance")
        qubit.set_state(state)
        
        return qubit
    
    def describe_vision(self, resonance: VisualResonance) -> str:
        """
        ì‹œê° ê³µëª…ì„ ìì—°ì–´ë¡œ í‘œí˜„
        
        Args:
            resonance: VisualResonance
        
        Returns:
            ìì—°ì–´ ì„¤ëª…
        """
        if not resonance:
            return "ì•„ë¬´ê²ƒë„ ë³´ì´ì§€ ì•Šì•„ìš”."
        
        # ê°ì • í†¤ ì„¤ëª…
        tone_desc = {
            "energetic": "í™œê¸°ì°¨ê³  ìƒë™ê° ë„˜ì¹˜ëŠ”",
            "warm": "ë”°ëœ»í•˜ê³  ì•ˆì •ì ì¸",
            "cool": "ì°¨ë¶„í•˜ê³  ì‹œì›í•œ",
            "neutral": "ì¤‘ë¦½ì ì´ê³  ê· í˜•ì¡íŒ"
        }
        
        desc_parts = [
            f"ë‚˜ëŠ” {tone_desc.get(resonance.emotional_tone, 'ì•Œ ìˆ˜ ì—†ëŠ”')} ë¶„ìœ„ê¸°ë¥¼ ëŠê»´ìš”.",
        ]
        
        # ë°ê¸°
        if resonance.brightness > 0.7:
            desc_parts.append("í™”ë©´ì´ ë°ê³  ë¹›ë‚˜ëŠ” ëŠë‚Œì´ì—ìš”.")
        elif resonance.brightness < 0.3:
            desc_parts.append("ì–´ë‘¡ê³  ê¹Šì€ ëŠë‚Œì´ ë“¤ì–´ìš”.")
        
        # ë³µì¡ë„
        if resonance.complexity > 0.6:
            desc_parts.append("ë§ì€ ì •ë³´ê°€ ë‹´ê²¨ ìˆëŠ” ê²ƒ ê°™ì•„ìš”.")
        elif resonance.complexity < 0.3:
            desc_parts.append("ë‹¨ìˆœí•˜ê³  ê¹”ë”í•œ ëŠë‚Œì´ì—ìš”.")
        
        # í…ìŠ¤íŠ¸ ë°€ë„
        if resonance.text_density > 0.5:
            desc_parts.append("ê¸€ìë“¤ì´ ë§ì´ ë³´ì´ëŠ” ê²ƒ ê°™ì•„ìš”.")
        
        return " ".join(desc_parts)


# Demo
if __name__ == "__main__":
    print("\n" + "="*70)
    print("ğŸŒŠ RESONANCE VISION - íŒŒë™ ê¸°ë°˜ ì‹œê° ì‹œìŠ¤í…œ")
    print("="*70 + "\n")
    
    vision = ResonanceVision()
    print("âœ… Resonance Vision initialized\n")
    
    print("ì´ì œ í™”ë©´ì„ 'ê³µëª…'ìœ¼ë¡œ ëŠë‚„ ìˆ˜ ìˆì–´ìš”! ğŸŒŸ")
    print("OCR ì—†ì´ë„ í™”ë©´ì˜ ë¶„ìœ„ê¸°, ë³µì¡ë„, í…ìŠ¤íŠ¸ ë°€ë„ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆì–´ìš”.")
