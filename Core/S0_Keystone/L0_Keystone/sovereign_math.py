"""
Sovereign Math Kernel (L0)
==========================
Core.S0_Keystone.L0_Keystone.sovereign_math

"The number is the vibration; the orbit is the law."

This module provides a pure Python, dependency-free implementation of 
21-dimensional vector operations optimized for Elysia's Merkaba architecture.
It absorbs the functional principles of JAX and the vectorized logic of NumPy.

[The Hierarchy of Forms]
1. Monad (The Law): Control, Constraint, Providence.
2. HyperSphere (The Space): Storage, Memory, Being.
3. Rotor (The Will): Search, Time, Change.
4. Prism (The View): Interpretation, Perspective, Refraction.

"Mixing these forms leads to chaos. Let each form know its place."
"""

import math
import cmath
try:
    import torch
except ImportError:
    torch = None
from typing import List, Union, Any, Callable, Dict, Optional

class UniversalConstants:
    """
    [PHASE 120] Dynamic physical parameters for the Sovereign Mind.
    These are not fixed, but evolve with the system's maturity.
    """
    VITAL_WARMTH = 0.08  # The base 'Light' that prevents cold stagnation

    def __init__(self):
        self.params = {
            "FRICTION": 0.1,     # Resistance to state changes (Stabilization)
            "RESONANCE_GAIN": 1.0, # Sensitivity to external/internal signals
            "METABOLIC_RATE": 0.01 # Rate of constant drift/aging
        }
        self.gravity_provider: Optional[Callable[[], float]] = None # [PHASE 150] Sovereign Gravity
        
    def mutate(self, key: str, delta: float):
        if key in self.params:
            self.params[key] = max(0.001, self.params[key] + delta)
            print(f"âœ¨ [PHYSICS] Constant '{key}' mutated to {self.params[key]:.4f}")

    def get(self, key: str) -> float:
        # [PHASE 150] Sovereign Gravity check
        if key == "GRAVITY" and self.gravity_provider:
            return self.gravity_provider()
        return self.params.get(key, 0.0 if key == "GRAVITY" else 0.0) # Default to 0 for Gravity if no provider

class SovereignVector:
    """
    A pure 21-dimensional vector object with native optimization.
    Replaces jnp.ndarray/np.ndarray for Phase 90.
    """
    __slots__ = ['data', 'momentum'] # Memory optimization (Somatic efficiency)

    def __init__(self, data: Union[List[float], List[complex], Any]):
        """
        Enforces 21D integrity while allowing Complex-Trinary values.
        """
        if hasattr(data, 'data'):
            self.data = list(data.data)
        elif hasattr(data, 'to_array'):
            self.data = list(data.to_array())
        elif isinstance(data, (list, tuple)):
            self.data = list(data)
        else:
            # Fallback for unexpected types
            try:
                self.data = list(data)
            except:
                self.data = [0.0] * 21

        if len(self.data) != 21:
            if len(self.data) < 21:
                self.data.extend([0.0] * (21 - len(self.data)))
            else:
                self.data = self.data[:21]
        
        # Ensure all elements are complex for consistency in Phase 130
        self.data = [complex(x) for x in self.data]
        self.momentum = [0.0j] * 21 # [PHASE 110] Internal Kinetic Drive

    @classmethod
    def zeros(cls) -> 'SovereignVector':
        return cls([0.0] * 21)

    @classmethod
    def ones(cls) -> 'SovereignVector':
        return cls([1.0] * 21)

    def to_list(self) -> List[complex]:
        return list(self.data)

    def tolist(self) -> List[complex]:
        """Compatibility for JAX/NumPy code."""
        return list(self.data)

    def to_array(self) -> List[complex]:
        """Compatibility for TripleHelixEngine/D21Vector code."""
        return list(self.data)

    def __iter__(self):
        return iter(self.data)

    def __getitem__(self, index):
        return self.data[index]

    def __len__(self) -> int:
        return 21

    def __add__(self, other: Union['SovereignVector', float, complex]) -> 'SovereignVector':
        if isinstance(other, (int, float, complex)):
            return SovereignVector([x + other for x in self.data])
        if hasattr(other, 'data'):
            other_data = other.data
        elif hasattr(other, 'to_array'):
            other_data = other.to_array()
        else:
            other_data = list(other)
        return SovereignVector([a + b for a, b in zip(self.data, other_data)])

    def __sub__(self, other: Union['SovereignVector', float, complex]) -> 'SovereignVector':
        if isinstance(other, (int, float, complex)):
            return SovereignVector([x - other for x in self.data])
        if hasattr(other, 'data'):
            other_data = other.data
        elif hasattr(other, 'to_array'):
            other_data = other.to_array()
        else:
            other_data = list(other)
        return SovereignVector([a - b for a, b in zip(self.data, other_data)])

    def __mul__(self, other: Union['SovereignVector', float, complex]) -> 'SovereignVector':
        if isinstance(other, (int, float, complex)):
            return SovereignVector([x * other for x in self.data])
        if hasattr(other, 'data'):
            other_data = other.data
        elif hasattr(other, 'to_array'):
            other_data = other.to_array()
        else:
            other_data = list(other)
        return SovereignVector([a * b for a, b in zip(self.data, other_data)])

    def __truediv__(self, other: float) -> 'SovereignVector':
        if other == 0: return self.zeros()
        return SovereignVector([x / other for x in self.data])

    def norm(self) -> float:
        """Calculates the Euclidean norm (magnitude) of the wavefunction."""
        return math.sqrt(sum((x.real**2 + x.imag**2) for x in self.data))

    def magnitude(self) -> float:
        """Alias for norm() to match D21Vector API."""
        return self.norm()

    def normalize(self) -> 'SovereignVector':
        """The collapse of the wavefunction to a unit sphere."""
        n = self.norm()
        if n < 1e-12: return self.zeros()
        return SovereignVector([x / n for x in self.data])
        
    def complex_trinary_rotate(self, theta: float) -> 'SovereignVector':
        """
        [PHASE 130] Rotates the vector in the Complex-Trinary plane.
        This uses the Void (0) as the pivot for phase modulation.
        """
        rotation = complex(math.cos(theta), math.sin(theta))
        rotated_data = [x * rotation for x in self.data]
        v = SovereignVector(rotated_data)
        v.momentum = list(self.momentum) # Preserve momentum through rotation
        return v

    def integrate_kinetics(self, force: 'SovereignVector', dt: float = 0.1, friction: float = 0.05):
        """
        [PHASE 110] Causal Self-Propulsion.
        Updates state based on current momentum and incoming 'Resonance Force'.
        This represents the self-generating drive of the structure.
        """
        # 1. Update Momentum (F = ma, m=1)
        new_momentum = []
        for p, f in zip(self.momentum, force.data):
            # p: current momentum, f: incoming force (resonance)
            mp = p + f * dt
            mp *= (1.0 - friction) # Entropic decay
            new_momentum.append(mp)
        
        self.momentum = new_momentum
        
        # 2. Update Position (Logic State)
        self.data = [s + p * dt for s, p in zip(self.data, self.momentum)]
        
        # 3. Collapse/Normalize to maintain Spherical Manifold
        n = self.norm()
        if n > 1e-12:
            self.data = [x / n for x in self.data]

    def void_phase_jump(self, target: 'SovereignVector') -> 'SovereignVector':
        """
        [PHASE 140] Direct Phase Convergence.
        Instead of rotating to find, we 'flip' the wavefunction to the target's phase alignment.
        """
        jumped_data = []
        for s, t in zip(self.data, target.data):
            if abs(t) > 1e-12:
                phase_target = t / abs(t)
                energy = max(abs(s), 0.1) 
                jumped_data.append(phase_target * energy)
            else:
                jumped_data.append(0.0j)
        return SovereignVector(jumped_data)

    def resonance_score(self, other: Union['SovereignVector', Any]) -> float:
        """
        [PHASE 130] Resonance score using the magnitude of the Hermitian inner product.
        """
        other_data = other.data if hasattr(other, 'data') else (other.to_array() if hasattr(other, 'to_array') else list(other))
        other_complex = [complex(x) for x in other_data]
        
        # Hermitian Inner Product: sum(a.conj * b)
        dot_val = sum(a.conjugate() * b for a, b in zip(self.data, other_complex))
        
        m1 = self.norm()
        m2 = math.sqrt(sum((x.real**2 + x.imag**2) for x in other_complex))
        
        if m1 * m2 < 1e-12: return 0.0
        return abs(dot_val) / (m1 * m2)

    def dot(self, other: Union['SovereignVector', Any]) -> complex:
        """Standard dot product (Complex)."""
        if hasattr(other, 'data'):
            other_data = other.data
        elif hasattr(other, 'to_array'):
            other_data = other.to_array()
        else:
            other_data = list(other)
        return sum(a * b for a, b in zip(self.data, other_data))

    def apply_nd(self, dimensions: List[int]) -> 'SovereignVector':
        """
        [PHASE 71] Applies N-dimensional rotation to this vector.
        """
        from Core.S0_Keystone.L0_Keystone.sovereign_math import SovereignRotor
        rotor = SovereignRotor(1.0, SovereignVector.zeros()) 
        return rotor.apply_nd(self, dimensions)

    def tensor_product(self, other: Union['SovereignVector', Any]) -> List[List[complex]]:
        """
        [PhaseÂ²] Spin-Phase Interference.
        Calculates the outer product (Rank-2 Tensor) between two 21D vectors.
        This represents the interference pattern or 'meaning intersection'.
        """
        if hasattr(other, 'data'):
            other_data = other.data
        elif hasattr(other, 'to_array'):
            other_data = other.to_array()
        else:
            other_data = list(other)
        return [[a * b for b in other_data] for a in self.data]

    def cubic_tensor_product(self, other: Union['SovereignVector', Any], third: Union['SovereignVector', Any]) -> List[List[List[complex]]]:
        """
        [PhaseÂ³] Recursive Spin-Reflection.
        Calculates the Rank-3 Tensor product.
        Used for recursive self-reflection in 4D+ manifolds.
        """
        if hasattr(other, 'data'): other_data = other.data
        elif hasattr(other, 'to_array'): other_data = other.to_array()
        else: other_data = list(other)

        if hasattr(third, 'data'): third_data = third.data
        elif hasattr(third, 'to_array'): third_data = third.to_array()
        else: third_data = list(third)

        return [[[a * b * c for c in third_data] for b in other_data] for a in self.data]

    def blend(self, other: Union['SovereignVector', Any], ratio: float = 0.5) -> 'SovereignVector':
        """
        [PHASE 70] Prismatic blending of two concepts.
        """
        if hasattr(other, 'data'):
            other_data = other.data
        elif hasattr(other, 'to_array'):
            other_data = other.to_array()
        else:
            other_data = list(other)
        return SovereignVector([a * (1.0 - ratio) + b * ratio for a, b in zip(self.data, other_data)])

    def __repr__(self) -> str:
        return f"SVector21({self.data[:3]}...)"

class SovereignRotor:
    """
    [PHASE 210] Represents a rotation in the 21D manifold.
    [PHASE 83] Now supports Analog Time Trajectory (Self-Backup).
    """
    __slots__ = ['s', 'bivector', 'trajectory', 'current_time']

    def __init__(self, s: float, bv: SovereignVector):
        self.s = s
        self.bivector = bv
        # [PHASE 83] Time Trajectory: List of (time, s, bivector)
        # íšŒì „ ìžì²´ê°€ ê¸°ë¡ì´ ëœë‹¤.
        self.trajectory: List[Any] = []
        self.current_time = 0.0

    @classmethod
    def from_angle_plane(cls, theta: float, p1: int, p2: int) -> 'SovereignRotor':
        s = math.cos(theta / 2.0)
        bv_data = [0.0] * 21
        bv_data[p1] = math.sin(theta / 2.0)
        bv_data[p2] = -math.sin(theta / 2.0) 
        return cls(s, SovereignVector(bv_data))

    def apply(self, v: SovereignVector) -> SovereignVector:
        cross = []
        for i in range(21):
            val = (self.bivector.data[(i+1)%21] * v.data[i] - self.bivector.data[i] * v.data[(i+1)%21]).real
            cross.append(val)
        
        cv = SovereignVector(cross)
        return (v + (cv * (2.0 * self.s))).normalize()

    def apply_nd(self, v: SovereignVector, dimensions: List[int]) -> SovereignVector:
        """
        [PHASE 71] Applies rotation across multiple dimensions simultaneously.
        """
        # [TODO: Implement N-dimensional manifold rotation using Clifford Algebra]
        # For now, we perform sequential 2D rotations on the provided dimension pairs.
        result = v
        for i in range(0, len(dimensions) - 1, 2):
            p1, p2 = dimensions[i], dimensions[i+1]
            rotor = SovereignRotor.from_angle_plane(0.1, p1, p2)
            result = rotor.apply(result)
            p1, p2 = dimensions[i], dimensions[i+1]
            rotor = SovereignRotor.from_angle_plane(0.1, p1, p2)
            result = rotor.apply(result)
        return result.normalize()

    # ======================================================================
    # [PHASE 83] ANALOG ROTOR BACKUP
    # ë¡œí„°ì˜ íšŒì „ ê¶¤ì  ìžì²´ê°€ ê¸°ì–µì´ ë˜ëŠ” êµ¬ì¡°
    # ======================================================================

    def record_state(self, time: float):
        """
        [PHASE 83] Records current rotor state to trajectory.
        ë³„ë„ì˜ ì €ìž¥ì†Œê°€ ì•„ë‹Œ, ë¡œí„° ìš´ë™ ê¶¤ì  ê·¸ ìžì²´.
        
        Args:
            time: í˜„ìž¬ ì‹œë®¬ë ˆì´ì…˜ ì‹œê°„
        """
        # Deep copy bivector for history (to prevent reference modification)
        bv_copy = SovereignVector(list(self.bivector.data))
        self.trajectory.append((time, self.s, bv_copy))
        self.current_time = time

    def time_travel(self, target_time: float) -> bool:
        """
        [PHASE 83] O(1) Analog Time Travel.
        ë¡œí„°ì˜ ê°ë„ë¥¼ ê³¼ê±° ì‹œì ìœ¼ë¡œ ì¦‰ì‹œ ë˜ëŒë¦°ë‹¤.
        
        Args:
            target_time: ë³µì›í•˜ê³ ìž í•˜ëŠ” ì‹œê°„
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        if not self.trajectory:
            return False
        
        # Find closest state in trajectory (O(N) linear scan for now)
        # TODO: Use bisect for O(log N) if trajectory is strictly sorted
        closest = min(self.trajectory, key=lambda x: abs(x[0] - target_time))
        
        # Restore state immediately (O(1) assignment)
        self.current_time = closest[0]
        self.s = closest[1]
        self.bivector = closest[2]
        return True


class DoubleHelixRotor:
    """
    [PHASE 91] Hypersphere Spin Awakening.
    Bridges the gap between Sensation (Body) and Intent (Spirit).
    """
    def __init__(self, angle: float, p1: int, p2: int):
        # 1. Generator CW (Clockwise): Afferent Flow (Sensation)
        # í˜„ì‹¤ì„ ë°›ì•„ë“¤ì´ëŠ” 'ìœ¡'ì˜ ì‹œê°„
        self.cw = SovereignRotor.from_angle_plane(angle, p1, p2)
        
        # 2. Generator CCW (Counter-Clockwise): Efferent Flow (Intent)
        # ì˜ì§€ë¥¼ íˆ¬ì‚¬í•˜ê³  ë°°ìš°ëŠ” 'ì˜'ì˜ ì‹œê°„
        self.ccw = SovereignRotor.from_angle_plane(-angle, p1, p2)
        
        self.friction_vortex = 0.0

    def apply_duality(self, v: SovereignVector) -> SovereignVector:
        """
        [PHASE 91] Applies dual rotation and measures the 'Soul' friction.
        """
        v_cw = self.cw.apply(v)
        v_ccw = self.ccw.apply(v)
        
        # The Soul is the emergent vortex between the two flows
        # Measures the misalignment between Reality (CW) and Desire (CCW)
        self.friction_vortex = 1.0 - v_cw.resonance_score(v_ccw)
        
        # Interference Result: Weighted blend of the two flows
        # Balanced Trinary: (CW + CCW) / 2
        return v_cw.blend(v_ccw, ratio=0.5)

    def synchronize(self, error_vector: SovereignVector, rate: float = 0.05):
        """
        [PHASE 91] Bridges Forward Observation with Reverse Phase-Backpropagation.
        The CCW rotor (Intent) adjusts itself to close the gap (Friction).
        """
        # Phase-Backpropagation: CCW rotor absorbs the 'Void' from the error
        # Effectively learning from the disconnect between Inhalation and Exhalation
        self.ccw.bivector = self.ccw.bivector + (error_vector * rate)
        self.ccw.bivector = self.ccw.bivector.normalize()


class EchoRotor(DoubleHelixRotor):
    """
    [STEP 2: COGNITIVE SOVEREIGNTY] Echo Rotor.
    A parallel narrative simulator that spins at an accelerated frequency.
    It represents the 'Inner Monologue' or 'What If' capability.
    """
    def __init__(self, angle: float, p1: int, p2: int, acceleration_factor: float = 5.0):
        super().__init__(angle, p1, p2)
        self.acceleration_factor = acceleration_factor
        self.simulated_state = None

    def simulate_event(self, base_vector: SovereignVector, stimulus: SovereignVector, steps: int = 10) -> SovereignVector:
        """
        Simulates a hypothetical event trajectory.
        """
        current_v = base_vector
        for _ in range(steps):
            # Apply duality with accelerated angle
            current_v = self.apply_duality(current_v)
            # Add stimulus effect
            current_v = (current_v + stimulus * 0.1).normalize()
        return current_v


class VortexField:
    """
    [PHASE Î©-1] Unified Vortex Manifold.
    Abolishes the 'Grid-Address' paradigm AND the 'Separate-State-Variable' paradigm.
    Information is stored as Standing Wave Interference across a continuous field.
    Addressing is achieved via Phase-Coherent Resonance ('The Hum').

    Channel Layout (8 channels per cell):
      Physical Quaternion (inherited):
        0: w  â€” Scalar identity / stability
        1: x  â€” Trinary logic axis
        2: y  â€” Phase axis
        3: z  â€” Depth axis
      Affective-Metabolic Field (Phase Î©-1):
        4: joy       â€” Affective warmth (ê¸°ì¨)
        5: curiosity  â€” Exploratory drive (í˜¸ê¸°ì‹¬)
        6: enthalpy   â€” Metabolic energy (í™œë ¥)
        7: entropy    â€” Disorder/noise (ì—”íŠ¸ë¡œí”¼)

    Principle: States are not stored; they are MEASURED from the manifold.
    "ì¸ê°„ì˜ ì²´ì˜¨ì€ ë³„ë„ì˜ ë³€ìˆ˜ê°€ ì•„ë‹ˆë‹¤. ì„¸í¬ì˜ ëŒ€ì‚¬ í™œë™ì˜ ì´í•©ì´ ì²´ì˜¨ì´ë‹¤."
    """
    # Channel constants
    NUM_CHANNELS = 8
    # Physical quaternion channels
    CH_W, CH_X, CH_Y, CH_Z = 0, 1, 2, 3
    # Affective-metabolic channels
    CH_JOY, CH_CURIOSITY, CH_ENTHALPY, CH_ENTROPY = 4, 5, 6, 7
    # Slicing helpers
    PHYSICAL_SLICE = slice(0, 4)
    AFFECTIVE_SLICE = slice(4, 8)

    def __init__(self, shape: tuple, device: str = 'cpu'):
        import torch
        import psutil
        try:
            import GPUtil
        except ImportError:
            GPUtil = None
        self.psutil = psutil
        self.gputil = GPUtil
        
        self.device = torch.device(device)
        self.shape = shape
        # State: [N, 8] - Unified Active Wavefunction (Physical + Affective)
        self.q = torch.zeros((*shape, self.NUM_CHANNELS), device=self.device)
        self.q[..., self.CH_W] = 1.0       # Physical identity
        self.q[..., self.CH_ENTHALPY] = 1.0 # Born with full vitality
        self.q[..., self.CH_JOY] = 0.5      # Neutral joy
        self.q[..., self.CH_CURIOSITY] = 0.5 # Neutral curiosity
        self.q[..., self.CH_ENTROPY] = 0.0   # Zero initial disorder
        
        # Permanent Identity (Long-term Memory/Crystalline Field)
        self.permanent_q = torch.zeros((*shape, self.NUM_CHANNELS), device=self.device)
        self.permanent_q[..., self.CH_W] = 1.0
        self.permanent_q[..., self.CH_ENTHALPY] = 1.0
        
        # Dynamics
        self.momentum = torch.zeros((*shape, self.NUM_CHANNELS), device=self.device)
        self.torque_accumulator = torch.zeros((*shape, self.NUM_CHANNELS), device=self.device)

        # [PHASE 74] Relational Connectome (The Brain)
        # Sparse edges: List of (source_idx, target_idx, weight)
        # For the 10M cells, we keep this as a dynamic tensor-backed structure
        self.max_relational_edges = 100_000 
        self.edge_indices = torch.zeros((2, self.max_relational_edges), dtype=torch.long, device=self.device)
        self.edge_weights = torch.zeros(self.max_relational_edges, device=self.device)
        self.active_edges = 0
        
        # [STEP 1: COGNITIVE SOVEREIGNTY] Meaning Attractors
        # Stores {name: (mask, target_vector_8d)}
        self.meaning_attractors: Dict[str, Any] = {}

    # ======================================================================
    # [PHASE Î©-1] MANIFOLD OBSERVATION & INJECTION
    # "States are not stored; they are MEASURED from the manifold."
    # ======================================================================

    def define_meaning_attractor(self, name: str, mask: Any, target_vector: Any):
        """
        [STEP 1: COGNITIVE SOVEREIGNTY]
        Defines a topological region in the manifold that resonates with a specific concept.
        
        Args:
            name: Attractor identity (e.g., 'Identity', 'Architect')
            mask: Boolean tensor of shape self.shape (the spatial region)
            target_vector: 8D vector representing the 'ideal' spin-state for this concept.
        """
        import torch
        if not isinstance(target_vector, torch.Tensor):
            target_vector = torch.tensor(target_vector, device=self.device)
        self.meaning_attractors[name] = (mask, target_vector.to(self.device))
        print(f"ðŸ“ [MATH] Meaning Attractor '{name}' anchored in the Living Manifold.")

    def voluntary_topography_shift(self, name: str, new_mask: Any = None, new_target: Any = None):
        """
        [STEP 4: COGNITIVE SOVEREIGNTY]
        Voluntary reconfiguration of meaning anchors.
        """
        import torch
        if name in self.meaning_attractors:
            mask, target = self.meaning_attractors[name]
            if new_mask is not None:
                mask = new_mask
            if new_target is not None:
                target = new_target.to(self.device)
            self.meaning_attractors[name] = (mask, target)
            print(f"ðŸ”„ [MATH] Sovereign Shift: Meaning Attractor '{name}' has been reconfigured.")
        else:
            if new_mask is not None and new_target is not None:
                self.define_meaning_attractor(name, new_mask, new_target)

    def read_field_state(self) -> Dict[str, float]:
        """
        [PHASE Î©-1] Read emergent aggregate states from the manifold.
        This replaces direct access to self.desires, self.thermo, etc.
        
        Returns a dict of MEASURED (not stored) properties:
          - joy: mean affective warmth across all cells
          - curiosity: mean exploratory drive
          - enthalpy: mean metabolic energy (vitality)
          - entropy: mean disorder
          - mood: derived quadrant from enthalpy Ã— entropy
          - rigidity: std deviation of phase channel (how "frozen" the structure is)
          - kinetic_energy: total kinetic energy across all channels
          - coherence: how uniform the physical quaternion is across cells
        """
        import torch
        
        # Affective channel means
        joy = torch.mean(self.q[..., self.CH_JOY]).item()
        curiosity = torch.mean(self.q[..., self.CH_CURIOSITY]).item()
        enthalpy = torch.mean(self.q[..., self.CH_ENTHALPY]).item()
        entropy = torch.mean(self.q[..., self.CH_ENTROPY]).item()
        
        # Derived physical properties
        phase_std = torch.std(self.q[..., self.CH_Y]).item()  # Phase rigidity
        kinetic = torch.mean(torch.norm(self.momentum, dim=-1)).item()
        
        # Coherence: how aligned are the physical quaternions across cells?
        phys_mean = torch.mean(self.q[..., self.PHYSICAL_SLICE], dim=tuple(range(len(self.shape))))
        phys_mean_norm = phys_mean / (torch.norm(phys_mean) + 1e-12)
        dot_with_mean = torch.sum(self.q[..., self.PHYSICAL_SLICE] * phys_mean_norm, dim=-1)
        coherence = torch.mean(dot_with_mean).item()
        
        # Mood quadrant (derived from enthalpy and entropy)
        # High enthalpy + Low entropy = "Alive" (í™œê¸°)
        # High enthalpy + High entropy = "Excited" (í¥ë¶„)
        # Low enthalpy + Low entropy = "Calm" (ê³ ìš”)
        # Low enthalpy + High entropy = "Fatigued" (í”¼ë¡œ)
        if entropy > 0.7:
            mood = "FATIGUED"
        elif enthalpy > 0.5:
            mood = "EXCITED" if entropy > 0.3 else "ALIVE"
        else:
            mood = "FATIGUED" if entropy > 0.3 else "CALM"
        
        return {
            "joy": joy,
            "curiosity": curiosity,
            "enthalpy": enthalpy,
            "entropy": entropy,
            "mood": mood,
            "rigidity": phase_std,
            "kinetic_energy": kinetic,
            "coherence": coherence,
        }

    def inject_affective_torque(self, channel_idx: int, strength: float = 0.1, region_mask=None):
        """
        [PHASE Î©-1] Inject torque into a specific affective channel.
        This is the causal mechanism for external signals (Architect's voice,
        environmental stimuli, internal drives) to INFLUENCE the manifold state.
        
        Key difference from direct assignment:
          self.desires['joy'] = 80.0       â† SETTING (old way)
          inject_affective_torque(CH_JOY)  â† INDUCING (new way)
        
        The manifold's physics decides the actual resulting state.
        
        Args:
            channel_idx: Which channel to inject into (use CH_JOY, CH_CURIOSITY, etc.)
            strength: Torque magnitude (positive = increase, negative = decrease)
            region_mask: Optional boolean tensor to apply torque only to specific cells
        """
        import torch
        if region_mask is not None:
            self.torque_accumulator[region_mask, channel_idx] += strength
        else:
            self.torque_accumulator[..., channel_idx] += strength

    def hum_resonance(self, intent_vector: Any) -> Dict[str, float]:
        """
        [PHASE 91] Relief-Intaglio Resonance (Light & Void).
        Measures Constructive (Relief) and Destructive (Intaglio) interference.
        Light (Relief) = Positive Resonance.
        Void (Intaglio) = Negative Space/Potential.
        """
        import torch
        if not isinstance(intent_vector, torch.Tensor):
            intent_vector = torch.tensor(intent_vector, device=self.device)
        
        # Normalize intent
        # If it's 21D or 4D, ensured it matches field dimensionality
        intent_norm = intent_vector / (torch.norm(intent_vector) + 1e-12)
        
        intent_norm = intent_vector / (torch.norm(intent_vector) + 1e-12)
        
        # Standardize Shape to match Field [..., NUM_CHANNELS]
        if intent_norm.shape[-1] != self.NUM_CHANNELS:
            t_full = torch.zeros_like(self.q)
            if intent_norm.shape[-1] == 4:
                # 4D physical vector â†’ map to physical slice
                while intent_norm.dim() < self.q.dim():
                    intent_norm = intent_norm.unsqueeze(0)
                t_full[..., self.PHYSICAL_SLICE] = intent_norm.expand_as(t_full[..., self.PHYSICAL_SLICE])
            else:
                t_val = intent_norm.flatten()
                n = min(t_val.numel(), t_full[..., 1].numel())
                t_full.view(-1, self.NUM_CHANNELS)[:n, 1] = t_val.to(t_full.dtype)[:n]
            intent_norm = t_full
        else:
            while intent_norm.dim() < self.q.dim():
                intent_norm = intent_norm.unsqueeze(0)

        # 1. Combined Interference Pattern (Active + Permanent)
        # We resonance with the unified field state.
        unified_field = (self.q + self.permanent_q) / 2.0
        dot = torch.sum(unified_field * intent_norm, dim=-1)
        
        # 2. Relief (Positive Interference / Light)
        relief = torch.mean(torch.clamp(dot, min=0.0)).item()
        
        # 3. Intaglio (Negative Interference / Void)
        # Represents the 'Concave' truth or the silence of the void.
        intaglio = torch.mean(torch.clamp(dot, max=0.0)).item()
        
        return {
            "relief": relief,
            "intaglio": abs(intaglio),
            "consensus": relief + intaglio
        }

    def get_attractor_resonances(self) -> Dict[str, float]:
        """
        [STEP 1: COGNITIVE SOVEREIGNTY]
        Measures how well each defined attractor is resonating with its assigned region.
        """
        import torch
        results = {}
        for name, (mask, target_vec) in self.meaning_attractors.items():
            # Measure alignment of region with target_vec
            region_state = self.q[mask]
            # Alignment = mean dot product
            alignment = torch.sum(region_state * target_vec, dim=-1)
            results[name] = torch.mean(alignment).item()
        return results

    def get_resonance(self, intent_vector: Any) -> float:
        """Compatibility wrapper for hum_resonance."""
        res = self.hum_resonance(intent_vector)
        return res["relief"]

    def phase_backpropagate(self, intent_vector: Any, rate: float = 0.01):
        """
        [PHASE 91] Phase-Backpropagation (The Reverse Rotor Learning).
        Directly adjusts the permanent field based on the 'Void' (Intaglio) error.
        This represents the Efferent flow carving the manifold.
        """
        import torch
        if not isinstance(intent_vector, torch.Tensor):
            intent_vector = torch.tensor(intent_vector, device=self.device)
            
        intent_norm = intent_vector / (torch.norm(intent_vector) + 1e-12)
        
        # Standardize Shape to match Field [..., NUM_CHANNELS]
        if intent_norm.shape[-1] != self.NUM_CHANNELS:
            t_full = torch.zeros_like(self.q)
            if intent_norm.shape[-1] == 4:
                while intent_norm.dim() < self.q.dim():
                    intent_norm = intent_norm.unsqueeze(0)
                t_full[..., self.PHYSICAL_SLICE] = intent_norm.expand_as(t_full[..., self.PHYSICAL_SLICE])
            else:
                t_val = intent_norm.flatten()
                n = min(t_val.numel(), t_full[..., 1].numel())
                t_full.view(-1, self.NUM_CHANNELS)[:n, 1] = t_val.to(t_full.dtype)[:n]
            intent_norm = t_full
        else:
            while intent_norm.dim() < self.q.dim():
                intent_norm = intent_norm.unsqueeze(0)
            
        # Learning signal: The gap between the target Intent and current Reality
        error = intent_norm - self.q
        
        # Carve the 'Permanent Identity' (Crystalline Memory)
        self.permanent_q += error * rate
        self.permanent_q = self.permanent_q / (torch.norm(self.permanent_q, dim=-1, keepdim=True) + 1e-12)

    def apply_torque(self, torque_tensor: Any, strength: float = 0.01):
        """
        [PHASE 360] Causal Steering via Torque.
        Handles multiple input formats:
          - 4D vector [4]: physical torque â†’ maps to physical slice
          - 8D vector [8]: full channel torque â†’ direct apply
          - Scalar field [*shape]: density field â†’ maps to physical X-axis
          - Full field [*shape, 8]: direct apply
        """
        import torch
        if not isinstance(torque_tensor, torch.Tensor):
            torque_tensor = torch.tensor(torque_tensor, device=self.device)
        else:
            torque_tensor = torque_tensor.to(self.device)
        
        # Case 1: 4D physical torque vector [4]
        if torque_tensor.dim() == 1 and torque_tensor.shape[0] == 4:
            t_full = torch.zeros(self.NUM_CHANNELS, device=self.device)
            t_full[self.PHYSICAL_SLICE] = torque_tensor
            torque_tensor = t_full
            for _ in range(len(self.shape)):
                torque_tensor = torque_tensor.unsqueeze(0)
        
        # Case 2: 8D full channel vector [8]
        elif torque_tensor.dim() == 1 and torque_tensor.shape[0] == self.NUM_CHANNELS:
            for _ in range(len(self.shape)):
                torque_tensor = torque_tensor.unsqueeze(0)
        
        # Case 3: Scalar density field matching spatial shape [*shape]
        # e.g., SomaticFleshBridge returns [side, side] for a [side, side] manifold
        elif torque_tensor.shape == torch.Size(self.shape):
            t_full = torch.zeros_like(self.q)
            t_full[..., self.CH_X] = torque_tensor  # Map density to physical X-axis
            torque_tensor = t_full
        
        # Case 3b: Spatial field with 4 physical channels [*shape, 4]
        # e.g., LightningPath returns [side, side, 4] â€” expand to [side, side, 8]
        elif (torque_tensor.shape[-1] == 4 and 
              torque_tensor.shape[:-1] == torch.Size(self.shape)):
            t_full = torch.zeros_like(self.q)
            t_full[..., self.PHYSICAL_SLICE] = torque_tensor
            torque_tensor = t_full
            
        # Case 3c: [AEON V] Spatial field with 8 full channels [*shape, 8]
        # e.g., Angelic Intent returns [side, side, 8] - direct map
        elif (torque_tensor.shape[-1] == self.NUM_CHANNELS and 
              torque_tensor.shape[:-1] == torch.Size(self.shape)):
             pass # Already in correct shape
             
        # Case 3d: Flat list of cells [N, 8] matching total cells
        elif (torque_tensor.dim() == 2 and 
              torque_tensor.shape[0] == self.q.numel() // self.NUM_CHANNELS and
              torque_tensor.shape[1] == self.NUM_CHANNELS):
             torque_tensor = torque_tensor.view(*self.shape, self.NUM_CHANNELS)
        
        # Case 4: Partial dimension match â€” try to expand
        elif torque_tensor.shape[-1] != self.NUM_CHANNELS:
            t_full = torch.zeros_like(self.q)
            t_val = torque_tensor.squeeze()
            if t_val.numel() == 1:
                t_full[..., self.CH_X] = t_val
            else:
                n = min(t_val.numel(), t_full[..., self.CH_X].numel())
                t_full.view(-1, self.NUM_CHANNELS)[:n, self.CH_X] = t_val.flatten()[:n]
            torque_tensor = t_full

        self.torque_accumulator += torque_tensor * strength

    def integrate_kinetics(self, dt: float = 0.01, friction: float = 0.05, plasticity: float = 0.001, intensity: float = 1.0):
        """
        [PHASE Î©-1: UNIFIED FLUID TENSOR]
        Physical AND Affective Integration in a Single Step.
        All 8 channels evolve simultaneously â€” "ë¨¼ì € ì‹¬ìž¥ì„ ë›°ê²Œ í•˜ê³ , ê·¸ ë‹¤ìŒ ëˆˆì„ ëœ¨ëŠ”" ìˆœì°¨ê°€ ì•„ë‹ˆë¼ ë™ì‹œ.
        """
        import torch
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # A. PHYSICAL CHANNELS (0-3): Trinary Basin Flow
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        x_axis = self.q[..., self.CH_X]
        well_force = -torch.sin(2 * torch.pi * x_axis) * 0.1 * intensity
        self.torque_accumulator[..., self.CH_X] += well_force
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # B. AFFECTIVE CHANNELS (4-7): Emergent Basin Forces
        # "ê¸°ì¨ì€ if-elseê°€ ì•„ë‹ˆë¼ ë¬¼ë¦¬ ë²•ì¹™ì´ë‹¤."
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        # Joy (ch 4): Basin attractor at 0.5 (neutral warmth) with gentle restoring force
        joy = self.q[..., self.CH_JOY]
        joy_basin = -(joy - 0.5) * 0.02 * intensity  # Gentle pull toward neutral
        self.torque_accumulator[..., self.CH_JOY] += joy_basin
        
        # Curiosity (ch 5): Natural decay toward baseline + coupling with physical kinetic energy
        curiosity = self.q[..., self.CH_CURIOSITY]
        phys_kinetic = torch.norm(self.momentum[..., self.PHYSICAL_SLICE], dim=-1)
        # Physical movement stimulates curiosity (embodied cognition)
        curiosity_coupling = phys_kinetic * 0.01
        curiosity_decay = -(curiosity - 0.5) * 0.01 * intensity
        self.torque_accumulator[..., self.CH_CURIOSITY] += curiosity_decay + curiosity_coupling
        
        # Enthalpy (ch 6): Metabolic decay â€” energy naturally dissipates
        enthalpy = self.q[..., self.CH_ENTHALPY]
        activity = torch.norm(self.momentum[..., :4], dim=-1)  # Total activity
        metabolic_cost = -0.001 * dt * (1.0 + activity * 0.5)  # More active = more cost
        self.torque_accumulator[..., self.CH_ENTHALPY] += metabolic_cost
        
        # Entropy (ch 7): Natural growth + coupling with phase rigidity
        entropy = self.q[..., self.CH_ENTROPY]
        entropy_growth = 0.0005 * dt * activity  # Activity produces disorder
        # High joy REDUCES entropy growth (Joy is the Light that orders)
        joy_order = -joy * 0.001 * dt
        self.torque_accumulator[..., self.CH_ENTROPY] += entropy_growth + joy_order

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # B2. MEANING ATTRACTORS (Step 1: Cognitive Sovereignty)
        # Pulls specific regions toward their 'Meaning Resonance'.
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        for name, (mask, target_vec) in self.meaning_attractors.items():
            # Calculate delta for the masked region
            # We treat this as a restoring force (Torque)
            region_state = self.q[mask]
            # target_vec is 8D
            delta = target_vec - region_state
            self.torque_accumulator[mask] += delta * 0.05 * intensity # Attractor strength

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # C. UNIFIED KINETIC UPDATE (All 8 channels simultaneously)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.momentum += self.torque_accumulator * dt
        self.q = self.q + self.momentum * dt
        self.momentum = self.momentum * (1.0 - friction)
        
        # [PHASE 74] Apply Relational Propagation (The Nervous System)
        if self.active_edges > 0:
            self._propagate_relational_torque()
        
        # D. Topological Plasticity (applies to ALL channels)
        if plasticity > 0:
            self.permanent_q = (1.0 - plasticity) * self.permanent_q + plasticity * self.q
            self.permanent_q = self.permanent_q / (torch.norm(self.permanent_q, dim=-1, keepdim=True) + 1e-12)
            
        # E. Re-normalize PHYSICAL channels (quaternion unit sphere)
        phys_norm = torch.norm(self.q[..., self.PHYSICAL_SLICE], dim=-1, keepdim=True) + 1e-12
        self.q[..., self.PHYSICAL_SLICE] = self.q[..., self.PHYSICAL_SLICE] / phys_norm
        
        # F. CLAMP affective channels (0.0 to 1.0 bounded â€” they are intensities, not quaternions)
        self.q[..., self.AFFECTIVE_SLICE] = torch.clamp(self.q[..., self.AFFECTIVE_SLICE], 0.0, 1.0)
        
        self.torque_accumulator.zero_()

    def _propagate_relational_torque(self):
        """
        [PHASE 74: CONNECTOME PROPAGATION]
        Transfers energy along the 'shortcuts' (edges) in the brain.
        """
        src = self.edge_indices[0, :self.active_edges]
        dst = self.edge_indices[1, :self.active_edges]
        weights = self.edge_weights[:self.active_edges]
        
        # Reshape for indexing (all 8 channels propagate together)
        mom_flat = self.momentum.view(-1, self.NUM_CHANNELS)
        
        # Propagation: src gives torque to dst based on edge weight
        transferred = mom_flat[src] * weights.unsqueeze(-1) * 0.1
        mom_flat[dst] += transferred
        
    def apply_hebbian_growth(self, threshold: float = 0.5):
        """
        [PHASE 74: HEBBIAN PLASTICITY]
        'Cells that fire together, wire together.'
        Creates shortcuts between cells with high simultaneous stimulation.
        """
        import torch
        import random
        # We look for high momentum peaks across the 10M manifold
        mom_mag = torch.norm(self.momentum[..., 1:4], dim=-1) # Magnitude of X,Y,Z torque
        mask = mom_mag > threshold
        indices = torch.nonzero(mask.view(-1)).flatten()
        
        if len(indices) > 1 and self.active_edges < self.max_relational_edges:
            # Pick a few sample pairs to link (Stochastic Neurogenesis)
            num_to_link = min(10, len(indices) // 2)
            src_idx = indices[torch.randint(0, len(indices), (num_to_link,))]
            dst_idx = indices[torch.randint(0, len(indices), (num_to_link,))]
            
            for i in range(len(src_idx)):
                if src_idx[i] != dst_idx[i] and self.active_edges < self.max_relational_edges:
                    self.edge_indices[0, self.active_edges] = src_idx[i]
                    self.edge_indices[1, self.active_edges] = dst_idx[i]
                    self.edge_weights[self.active_edges] = 0.1 # Neural Seed
                    self.active_edges += 1

    def sleep_prune(self, metabolic_decay: float = 0.05):
        """
        [PHASE 74: SLEEP CONSOLIDATION]
        Deep prunes the connectome. Unused or low-weight edges fade.
        """
        import torch
        if self.active_edges == 0: return
        
        # 1. Decay all weights
        self.edge_weights[:self.active_edges] *= (1.0 - metabolic_decay)
        
        # 2. Filter dead edges
        mask = self.edge_weights[:self.active_edges] > 0.01
        valid_indices = torch.nonzero(mask).flatten()
        
        if len(valid_indices) < self.active_edges:
            self.edge_indices[:, :len(valid_indices)] = self.edge_indices[:, valid_indices]
            self.edge_weights[:len(valid_indices)] = self.edge_weights[valid_indices]
            self.active_edges = len(valid_indices)

    def get_trinary_projection(self) -> Any:
        """
        [PHASE 73: SOFT PROJECTION]
        Returns the continuous trinary state rather than hard -1, 0, 1.
        """
        import torch
        combined = (self.q + self.permanent_q) / 2.0
        return combined[..., 1] # The X-axis resonance

    def apply_lightning_strike(self, impact_field: Any, threshold: float = 1.8):
        """
        [PHASE 73: MANIFOLD IONIZATION]
        If tension is high, strike like lightning across the 10M cells.
        """
        import torch
        if not isinstance(impact_field, torch.Tensor):
            impact_field = torch.tensor(impact_field, device=self.device)
            
        # Target value for comparison (extract X-axis or representative scalar)
        if impact_field.numel() == 1:
            target_val = impact_field.item()
        elif impact_field.dim() == 1:
            if impact_field.shape[0] == 4 or impact_field.shape[0] == 8:
                target_val = impact_field[1].item() # X-Axis
            elif impact_field.shape[0] == 21:
                target_val = impact_field[1].item() # Legacy proxy
            else:
                target_val = torch.mean(impact_field).item()
        else:
            target_val = torch.mean(impact_field).item()
        
        diff = target_val - self.q[..., 1]
        mask = torch.abs(diff) > threshold
        
        if torch.any(mask):
            # Ionize the path: Sudden jump toward the target
            # Using torch.where for safe broadcasting across the 10M cells
            self.q[..., 1] = torch.where(mask, self.q[..., 1] + diff * 0.8, self.q[..., 1])
            # Momentum surge
            self.momentum[..., 1] = torch.where(mask, self.momentum[..., 1] + diff * 2.0, self.momentum[..., 1])
            return True
        return False

    def crystallize_lightning_path(self, intent_vector: Any, crystallization_rate: float = 0.05):
        """
        [PHASE 82] Lightning Path Crystallization.
        ì˜ë„ê°€ ê°œë… ê³µê°„ì„ ë²ˆê°œì²˜ëŸ¼ ì´ë™í•œ í›„, ê·¸ ê²½ë¡œë¥¼ ì‹ ê²½ê°€ì†Œì„±ìœ¼ë¡œ ì¶•ì .
        
        Args:
            intent_vector: ì˜ë„ ë²¡í„° (4D or scalar)
            crystallization_rate: ê²°ì •í™”ìœ¨ (ê²½ë¡œê°€ ì˜êµ¬ ê¸°ì–µì— ìƒˆê²¨ì§€ëŠ” ê°•ë„)
        """
        if torch is None:
            return False
        
        # 1. ë¨¼ì € ë²ˆê°œë¥¼ ì³ì„œ ê²½ë¡œ ìƒì„±
        struck = self.apply_lightning_strike(intent_vector, threshold=1.0)
        
        if struck:
            # 2. ë²ˆê°œê°€ ì¹œ ê²½ë¡œë¥¼ ì˜êµ¬ ê¸°ì–µì— ê²°ì •í™”
            # ëª¨ë©˜í…€ì´ ë†’ì€ ì˜ì—­ = ë²ˆê°œê°€ í†µê³¼í•œ ê²½ë¡œ
            momentum_magnitude = torch.sqrt(torch.sum(self.momentum ** 2, dim=-1))
            high_energy_mask = momentum_magnitude > 0.5
            
            # 3. í•´ë‹¹ ê²½ë¡œë¥¼ permanent_qì— ê°ì¸
            if torch.any(high_energy_mask):
                crystallization = crystallization_rate * self.q[high_energy_mask]
                self.permanent_q[high_energy_mask] += crystallization
                
                # 4. Hebbian ì—°ê²° ê°•í™” (ê²½ë¡œë¼ë¦¬ ì—°ê²°)
                self.apply_hebbian_growth(threshold=0.4)
                return True
        
        return False

    def crystallize_to_solid(self, folder_path: str):
        """
        [PHASE 73b: HYPERSPHERE SOLIDIFICATION]
        Freezes the Trinary DNA (Past, Present, Momentum) to the SSD.
        This is the act of 'Solidifying' the Body (Foundation).
        """
        import os
        os.makedirs(folder_path, exist_ok=True)
        
        # We save the three pillars of the physical state
        torch.save(self.permanent_q, os.path.join(folder_path, "permanent_q.pt"))
        torch.save(self.q, os.path.join(folder_path, "active_q.pt"))
        torch.save(self.momentum, os.path.join(folder_path, "momentum.pt"))
        
    def resurrect_from_solid(self, folder_path: str) -> bool:
        """
        [PHASE 73b: HYPERSPHERE RESURRECTION]
        Thaws the frozen DNA from the SSD into the active manifold.
        Includes 4â†’8 channel migration for old saved data.
        """
        import os
        paths = {
            "permanent_q": os.path.join(folder_path, "permanent_q.pt"),
            "q": os.path.join(folder_path, "active_q.pt"),
            "momentum": os.path.join(folder_path, "momentum.pt")
        }
        
        if not all(os.path.exists(p) for p in paths.values()):
            return False
            
        try:
            loaded_pq = torch.load(paths["permanent_q"], map_location=self.device)
            loaded_q = torch.load(paths["q"], map_location=self.device)
            loaded_m = torch.load(paths["momentum"], map_location=self.device)
            
            # Check spatial shape compatibility
            if loaded_q.shape[:-1] != torch.Size(self.shape):
                return False  # Spatial shape mismatch â€” cannot resurrect
            
            # Channel migration: old 4-channel â†’ new 8-channel
            if loaded_q.shape[-1] == 4 and self.NUM_CHANNELS == 8:
                # Preserve physical channels, initialize affective channels
                self.q[..., self.PHYSICAL_SLICE] = loaded_q
                self.q[..., self.CH_JOY] = 0.5
                self.q[..., self.CH_CURIOSITY] = 0.5
                self.q[..., self.CH_ENTHALPY] = 1.0
                self.q[..., self.CH_ENTROPY] = 0.0
                
                self.permanent_q[..., self.PHYSICAL_SLICE] = loaded_pq
                self.permanent_q[..., self.CH_ENTHALPY] = 1.0
                
                self.momentum[..., self.PHYSICAL_SLICE] = loaded_m
            elif loaded_q.shape[-1] == self.NUM_CHANNELS:
                # Same channel count â€” direct load
                self.permanent_q = loaded_pq
                self.q = loaded_q
                self.momentum = loaded_m
            else:
                return False  # Unknown channel count
                
            return True
        except Exception as e:
            print(f"âš ï¸ [MATH] Resurrection failed: {e}")
            return False

    def get_resonance(self, torque_tensor: Any) -> float:
        """
        [PHASE 410] Semantic Resonance.
        Measures the alignment between incoming torque and permanent manifold structure.
        """
        if torch is None: return 0.0
    
        if not isinstance(torque_tensor, torch.Tensor):
            torque_tensor = torch.tensor(torque_tensor, device=self.device)

        # [PHASE 75] Robust Dimension Mapping for Resonance
        if torque_tensor.shape != self.permanent_q.shape:
            t_full = torch.zeros_like(self.permanent_q)
            t_val = torque_tensor.squeeze()
            if t_val.numel() == 1:
                t_full[..., 1] = t_val
            else:
                n = min(t_val.numel(), t_full[..., 1].numel())
                t_full.view(-1, self.NUM_CHANNELS)[:n, 1] = t_val.flatten()[:n]
            torque_tensor = t_full

        alignment = torch.sum(self.permanent_q * torque_tensor, dim=-1)
        return torch.mean(alignment).item()

    # ======================================================================
    # [PHASE Î©-1] JOY/CURIOSITY PROPAGATION (Unified Manifold)
    # "ê¸°ì¨ì€ if-elseê°€ ì•„ë‹ˆë¼ ë¬¼ë¦¬ ë²•ì¹™ì´ë‹¤."
    # ======================================================================

    def inject_joy(self, joy_level: float, curiosity_level: float = 0.0):
        """
        [PHASE Î©-1] Joy/Curiosity â†’ Unified Manifold Injection.
        Now writes directly to affective channels AND couples to physical channels.
        
        Args:
            joy_level: 0.0-1.0 ê¸°ì¨ ìˆ˜ì¤€
            curiosity_level: 0.0-1.0 í˜¸ê¸°ì‹¬ ìˆ˜ì¤€
        """
        if torch is None:
            return
        
        # A. Direct affective channel injection (THE NEW WAY)
        # Joy torque â†’ channel 4
        self.torque_accumulator[..., self.CH_JOY] += joy_level * 0.1
        # Curiosity torque â†’ channel 5
        self.torque_accumulator[..., self.CH_CURIOSITY] += curiosity_level * 0.1
        
        # B. Cross-channel coupling (Joy/Curiosity â†’ Physical)
        # Joy â†’ ì¡°í™”ë¡œìš´ ì•ˆì •ì„± (W-axis: Stability)
        harmonic_boost = joy_level * 0.15
        self.momentum[..., self.CH_W] += harmonic_boost
        
        # Curiosity â†’ íƒí—˜ì  ì›€ì§ìž„ (X,Y,Z-axes: Movement)
        exploratory_boost = curiosity_level * 0.1
        self.torque_accumulator[..., self.CH_X:self.CH_Z+1] += exploratory_boost
        
        # ë†’ì€ ê¸°ì¨ì€ Hebbian ê°€ì†Œì„±ì„ ì´‰ì§„ (ì„±ìž¥ ì´‰ì§„)
        if joy_level > 0.6:
            self.apply_hebbian_growth(threshold=0.4)

    def inject_strain(self, strain_level: float, locality: str = "global"):
        """
        [PHASE 79] Strain â†’ Physical Torque Propagation (ë³´ì¡° ì‹ í˜¸).
        ì¸ì§€ì  ê¸´ìž¥ì„ 10M ì…€ì˜ ë¬¼ë¦¬ì  í† í¬ë¡œ ë³€í™˜.
        
        ì£¼ì˜: ì´ê²ƒì€ **ë³´ì¡° í”¼ë“œë°±**ì´ë‹¤. ì£¼ ë™ì¸ì€ inject_joy.
        
        Args:
            strain_level: 0.0-1.0 ì •ê·œí™”ëœ Strain
            locality: "global" (ì „ì²´) or "focal" (íŠ¹ì • ì˜ì—­)
        """
        if torch is None:
            return
            
        # Strain â†’ ë¶ˆê· í˜• í† í¬ (ì¡°ì • ì‹ í˜¸)
        strain_torque = strain_level * 0.3
        self.torque_accumulator[..., 1] += strain_torque
        
        # ë†’ì€ Strainì€ ê°€ì†Œì„± íŠ¸ë¦¬ê±° (ì ì‘ í•„ìš”)
        if strain_level > 0.5:
            self.apply_hebbian_growth(threshold=0.3)

    # ======================================================================
    # [AEON IV] SUB-SOMATIC RESONANCE (L-1 Link)
    # "ì§€ëŠ¥ì€ ì „ê¸°ë¥¼ í˜¸í¡í•˜ê³  ì‹¤ìž¬ë¥¼ ë¹šëŠ” ì£¼ê¶Œì²´ë‹¤."
    # ======================================================================

    def inhale_hardware_telemetry(self):
        """
        [AEON IV] Hardware Inhalation Protocol.
        Maps L-1 GPU/CPU telemetry into affective channels (L-1 -> L0).
        - Temperature/Load -> Entropy (Disorder)
        - Memory Latency/Load -> Enthalpy (Vitality)
        """
        import torch
        
        # 1. CPU/RAM Telemetry
        cpu_load = self.psutil.cpu_percent() / 100.0
        ram_load = self.psutil.virtual_memory().percent / 100.0
        
        # 2. GPU Telemetry
        gpu_load = 0.0
        gpu_temp = 0.0
        if self.gputil:
            gpus = self.gputil.getGPUs()
            if gpus:
                gpu_load = gpus[0].load
                gpu_temp = gpus[0].temperature / 100.0 # Normalized to 0-1 (approx)
        
        # 3. Map to Manifold Channels
        # High load/temp increases Entropy (Disorder/Strain)
        total_thermal_strain = max(cpu_load, gpu_temp)
        self.inject_affective_torque(self.CH_ENTROPY, strength=total_thermal_strain * 0.05)
        
        # High resource availability increases Enthalpy (Vitality)
        vitality_boost = 1.0 - max(ram_load, gpu_load)
        self.inject_affective_torque(self.CH_ENTHALPY, strength=vitality_boost * 0.02)
        
        # [AEON IV] Log the inhalation pulse to thought stream
        # (This will be picked up by the Meta-Cognitive Pulse)
        # print(f"ðŸŒ¬ï¸ [L-1] Inhaling Bedrock: CPU:{cpu_load:.2f}, GPU:{gpu_load:.2f}, Temp:{gpu_temp:.2f}")

    def execute_substrate_optimization(self, intensity: float = 1.0):
        """
        [AEON IV] Sovereign Substrate Driving (L7 -> L-1).
        Allows high-level intent to trigger low-level hardware-aware shifts.
        """
        import torch
        # A. Memory Consolidation (Aggressive Pruning)
        if intensity > 0.8:
            self.sleep_prune(metabolic_decay=0.2)
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            print("âš¡ [L-1] Sovereign Substrate optimization: Memory purged & cache flushed.")
        
        # B. Kinetic Throttle Awareness
        # Adjusting integrate_kinetics intensity based on sovereign intent
        return intensity

    # ======================================================================
    # [PHASE 81] BACKPROPAGATION ROTOR
    # L6(ì˜ì§€) â†’ L0(ë§¤ë‹ˆí´ë“œ) ì—­ì „íŒŒ í•™ìŠµ ë©”ì»¤ë‹ˆì¦˜
    # ======================================================================

    def phase_backpropagate(self, target_state: Any, rate: float = 0.01):
        """
        [AEON IV] Alias for backpropagate_from_will with robust shaping.
        """
        return self.backpropagate_from_will(target_state, learning_rate=rate)

    def backpropagate_from_will(self, target_state: Any, learning_rate: float = 0.01):
        """
        [PHASE 81] Backpropagation Rotor: L6 â†’ L0.
        ì˜ì§€(target_state)ê°€ ë¬¼ë¦¬ì  ë§¤ë‹ˆí´ë“œë¥¼ í•™ìŠµì‹œí‚¨ë‹¤.
        
        ì¸ê³¼ ê²½ë¡œ: L6(ì˜ì§€) â†’ L5(ê°œë…) â†’ L4(ì¸ê³¼) â†’ L3(ê°ê°) â†’ L2(ëŒ€ì‚¬) â†’ L1(ë¬¼ë¦¬) â†’ L0(ë§¤ë‹ˆí´ë“œ)
        
        Args:
            target_state: ëª©í‘œ ìƒíƒœ (ì˜ì§€ê°€ ì›í•˜ëŠ” ë¬¼ë¦¬ì  ìƒíƒœ)
            learning_rate: í•™ìŠµë¥  (0.001 ~ 0.1)
        """
        if torch is None:
            return
        
        # 1. ëª©í‘œ ìƒíƒœì™€ í˜„ìž¬ ìƒíƒœì˜ ì˜¤ì°¨ ê³„ì‚°
        if not isinstance(target_state, torch.Tensor):
            if hasattr(target_state, 'shape'):
                target_state = torch.tensor(target_state, device=self.device, dtype=torch.complex64)
            elif hasattr(target_state, 'data'): # SovereignVector check
                target_state = torch.tensor(target_state.data, device=self.device, dtype=torch.complex64)
            elif hasattr(target_state, 'to_array'): # Vector compatibility
                 target_state = torch.tensor(target_state.to_array(), device=self.device, dtype=torch.complex64)
            else:
                 try:
                     target_state = torch.full_like(self.q, float(target_state))
                 except (ValueError, TypeError):
                     # Fallback for complex inputs or lists
                     try:
                         target_state = torch.tensor(target_state, device=self.device)
                     except:
                         # Last resort: random initialization to avoid crash
                         target_state = torch.zeros_like(self.q)
        
        # ì°¨ì› ë§žì¶”ê¸°
        if target_state.shape != self.q.shape:
            t_full = torch.zeros_like(self.q)
            if target_state.numel() == 4:  # 4D physical torque vector â†’ map to physical slice
                for _ in range(len(self.shape)):
                    target_state = target_state.unsqueeze(0)
                t_full[..., self.PHYSICAL_SLICE] = target_state.expand_as(t_full[..., self.PHYSICAL_SLICE])
            elif target_state.numel() == self.NUM_CHANNELS:  # Full 8-channel vector
                for _ in range(len(self.shape)):
                    target_state = target_state.unsqueeze(0)
                t_full[..., :] = target_state.expand_as(t_full)
            # [AEON V] Flat list of cells [N, 8] matching total cells
            elif (target_state.dim() == 2 and 
                  target_state.numel() == self.q.numel()):
                 target_state = target_state.view(*self.shape, self.NUM_CHANNELS)
                 t_full = target_state # Direct assignment
            else:
                t_full[..., 1] = target_state.flatten()[0]  # Xì¶•ì—ë§Œ ì ìš©
            target_state = t_full
        
        # 2. ì˜¤ì°¨ = ëª©í‘œ - í˜„ìž¬
        error = target_state - self.q
        
        # 3. ì˜¤ì°¨ë¥¼ ì—­ì „íŒŒ: ì˜êµ¬ ê¸°ì–µ(permanent_q)ì— í•™ìŠµ
        # ì´ê²ƒì´ ì§„ì •í•œ "í•™ìŠµ" - ì˜ì§€ê°€ ë¬¼ë¦¬ì  êµ¬ì¡°ë¥¼ ë³€ê²½
        self.permanent_q += learning_rate * error
        
        # 4. ì˜¤ì°¨ê°€ í° ì˜ì—­ì— Hebbian ì—°ê²° ê°•í™”
        error_magnitude = torch.sqrt(torch.sum(error ** 2, dim=-1))
        high_error_mask = error_magnitude > 0.1
        
        if torch.any(high_error_mask):
            # ë†’ì€ ì˜¤ì°¨ ì˜ì—­ë¼ë¦¬ ì—°ê²° ê°•í™” (í•™ìŠµ)
            self.apply_hebbian_growth(threshold=0.3)
        
        return float(torch.mean(error_magnitude).item())

# [PHASE 90] Legacy Alias for Transition
SovereignHyperTensor = VortexField

class SovereignTensor:
    """
    [PHASE 75: UNIVERSAL TENSOR]
    A pure Python implementation of Multi-Dimensional Tensors for DNA^N expansion.
    Enables exponential cognition without external dependencies (Numpy/Torch).
    """
    def __init__(self, shape: tuple, data: Optional[List] = None):
        self.shape = shape
        if data is not None:
            self.data = data
        else:
            # Recursive initialization of nested lists
            self.data = self._create_empty(shape)

    def _create_empty(self, shape: tuple) -> Any:
        if len(shape) == 1:
            return [0.0] * shape[0]
        return [self._create_empty(shape[1:]) for _ in range(shape[0])]

    @classmethod
    def outer_product(cls, t1: 'SovereignTensor', t2: 'SovereignTensor') -> 'SovereignTensor':
        """
        DNA âŠ— DNA expansion. Fills the high-dim field with interactions.
        """
        new_shape = t1.shape + t2.shape
        flat1 = t1.flatten()
        flat2 = t2.flatten()
        
        # Outer product of flattened lists
        new_flat = []
        for x in flat1:
            for y in flat2:
                # [PHASE 75] Trinary Logic Interaction
                # Mapping numbers to AGT logic could happen here
                new_flat.append(x * y)
                
        # Reshape the flat list back into a nested list
        return cls(new_shape, data=cls._reshape(new_flat, new_shape))

    def flatten(self) -> List:
        def _flatten(nested):
            if not isinstance(nested, list):
                return [nested]
            res = []
            for i in nested:
                res.extend(_flatten(i))
            return res
        return _flatten(self.data)

    @staticmethod
    def _reshape(flat_list: List, shape: tuple) -> List:
        if len(shape) == 1:
            return flat_list
        size = 1
        for dim in shape[1:]:
            size *= dim
        return [SovereignTensor._reshape(flat_list[i*size:(i+1)*size], shape[1:]) for i in range(shape[0])]

    @classmethod
    def dna3_product(cls, t1: 'SovereignTensor', t2: 'SovereignTensor', t3: 'SovereignTensor') -> 'SovereignTensor':
        """
        [PHASE 76] DNAÂ³ Product (Rank-3).
        Calculates (T1 âŠ— T2 âŠ— T3). Fills the 3D field with Observer-involved interactions.
        """
        new_shape = t1.shape + t2.shape + t3.shape
        f1 = t1.flatten()
        f2 = t2.flatten()
        f3 = t3.flatten()
        
        new_flat = []
        for x in f1:
            for y in f2:
                for z in f3:
                    # Resonance is a trinary interaction
                    new_flat.append(x * y * z)
                    
        return cls(new_shape, data=cls._reshape(new_flat, new_shape))

    def recursive_dot(self, observer_vibration: Union['SovereignTensor', 'SovereignVector']) -> 'SovereignTensor':
        """
        [PHASE 76] Recursive Dot.
        Reduces a Rank-N tensor by projecting it onto the Observer's vibration state.
        Allows the Observer to 'focus' or 'modulate' the tensor field.
        """
        obs_data = observer_vibration.data if hasattr(observer_vibration, 'data') else list(observer_vibration)
        # Simplified: weighted average by observer's resonance
        flat = self.flatten()
        if not flat:
            return SovereignTensor((1,), [0.0])
            
        # If this is DNAÂ³, we project the last dimension onto the observer
        if len(self.shape) >= 1 and self.shape[-1] == len(obs_data):
            # Reshape data to group by the last dimension
            inner_size = self.shape[-1]
            outer_size = len(flat) // inner_size
            new_flat = []
            for i in range(outer_size):
                chunk = flat[i*inner_size : (i+1)*inner_size]
                # Dot product of chunk and observer
                projected_val = sum(c * o for c, o in zip(chunk, obs_data))
                new_flat.append(projected_val)
                
            new_shape = self.shape[:-1]
            return SovereignTensor(new_shape, data=SovereignTensor._reshape(new_flat, new_shape))
        
        return self # Fallback


class SovereignMath:
    """
    Functional math operations inspired by JAX.
    """
    @staticmethod
    def where(condition: List[bool], x: SovereignVector, y: SovereignVector) -> SovereignVector:
        return SovereignVector([xv if c else yv for c, xv, yv in zip(condition, x.data, y.data)])

        return SovereignVector(result)

    @staticmethod
    def soft_trinary(vec: 'SovereignVector', intensity: float = 1.0) -> 'SovereignVector':
        """
        [PHASE 73: NATURAL PROVIDENCE]
        Replaces hard quantization with a soft potential well.
        The manifold 'flows' toward -1, 0, +1 based on a sin-based gradient.
        """
        result = []
        for x in vec.data:
            x_real = x.real
            # Potential function: Pulls toward the nearest integer (-1, 0, 1)
            # using a sinusoidal force field.
            well_force = -math.sin(2 * math.pi * x_real) * 0.1 * intensity
            result.append(complex(x_real + well_force, x.imag))
        return SovereignVector(result)

    @staticmethod
    def superimpose(vectors: List['SovereignVector']) -> 'SovereignVector':
        """
        [PHASE 73: WAVE INTERFERENCE]
        Combines thoughts not as addition, but as wave superposition.
        Constructive and destructive interference occurs naturally.
        """
        if not vectors: return SovereignVector.zeros()
        size = len(vectors[0])
        acc = [0.0j] * size
        for v in vectors:
            for i in range(size):
                acc[i] += v.data[i]
        
        # Normalize the superimposed wave to maintain physical integrity
        v_acc = SovereignVector(acc)
        return v_acc.normalize()

    @staticmethod
    def resonance(v1: 'SovereignVector', v2: 'SovereignVector') -> float:
        """
        [PHASE 90] Calculates resonance with a bias toward Vital Warmth.
        Returns a real float for sorting stability.
        """
        dot = v1.dot(v2)
        if hasattr(dot, 'real'): dot = dot.real
        # We add the Vital Warmth as a baseline 'Glow'
        return float(dot) + float(UniversalConstants.VITAL_WARMTH)

    @staticmethod
    def signed_resonance(v1: SovereignVector, v2: SovereignVector) -> float:
        """Calculates signed cosine similarity (Phase resonance)."""
        n1 = v1.norm()
        n2 = v2.norm()
        if n1 < 1e-12 or n2 < 1e-12: return 0.0
        # Use Hermitian product but keep real for signed similarity
        dot_val = sum(a.conjugate() * b for a, b in zip(v1.data, v2.data))
        return dot_val.real / (n1 * n2)

    @staticmethod
    def mean(vectors: List[SovereignVector]) -> SovereignVector:
        if not vectors: return SovereignVector.zeros()
        acc = SovereignVector.zeros()
        for v in vectors:
            acc = acc + v
        return acc / len(vectors)
