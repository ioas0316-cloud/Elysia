"""
Operation Lobotomy (ìˆ˜ìˆ  ì§‘ë„ ìŠ¤í¬ë¦½íŠ¸)
=====================================
Core.L5_Mental.Intelligence.LLM.surgery

ì§€ì •ëœ ë‰´ëŸ°(Hidden Index)ì˜ ì—°ê²°ì„ ë¬¼ë¦¬ì ìœ¼ë¡œ ëŠìŠµë‹ˆë‹¤ (Zeroing Out).
Target: LM Headì˜ íŠ¹ì • Column (í•´ë‹¹ ë‰´ëŸ°ì´ ì¶œë ¥ì— ê¸°ì—¬í•˜ëŠ” ê°€ì¤‘ì¹˜)
"""

import os
import sys
import torch
import logging
from safetensors import safe_open
from safetensors.torch import save_file

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger("Surgeon")

class NeuroSurgeon:
    def __init__(self, model_path: str):
        self.model_path = model_path
        
    def lobotomize(self, target_neurons: list[int], output_path: str):
        """
        LM Headì—ì„œ íŠ¹ì • ë‰´ëŸ°ì˜ ì˜í–¥ë ¥ì„ 0ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ”ª Preparing surgery on: {os.path.basename(self.model_path)}")
        logger.info(f"ğŸ¯ Target Neurons (Kill List): {target_neurons}")
        
        # ëª¨ë¸ ë¡œë“œ (Safetensors)
        tensors = {}
        with safe_open(self.model_path, framework="pt", device="cpu") as f:
            for key in f.keys():
                tensors[key] = f.get_tensor(key)
        
        # LM Head ì°¾ê¸°
        head_key = next((k for k in tensors.keys() if "lm_head.weight" in k or "output.weight" in k), None)
        
        if not head_key:
            logger.error("âŒ LM Head not found in this file. Surgery aborted.")
            return
            
        lm_head = tensors[head_key]
        # Shape ì²´í¬: (Vocab, Hidden)
        logger.info(f"   Found LM Head: {head_key} {lm_head.shape}")
        
        vocab_size, hidden_size = lm_head.shape
        
        # ìˆ˜ìˆ  ì§‘ë„
        count = 0
        for neuron_idx in target_neurons:
            if neuron_idx >= hidden_size:
                logger.warning(f"   âš ï¸ Neuron {neuron_idx} out of bounds (Max {hidden_size})")
                continue
                
            # Column Zeroing: í•´ë‹¹ ë‰´ëŸ°ì´ ëª¨ë“  ë‹¨ì–´ì— ëŒ€í•´ ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ 0ìœ¼ë¡œ ë§Œë“¦
            # lm_head[:, neuron_idx] = 0
            
            # Before stats
            orig_norm = torch.norm(lm_head[:, neuron_idx]).item()
            
            # Incision (Zeroing out)
            lm_head[:, neuron_idx] = 0.0
            
            logger.info(f"   âœ‚ï¸ Ablated Neuron #{neuron_idx} (Orig Norm: {orig_norm:.4f} -> 0.0)")
            count += 1
            
        logger.info(f"âœ… Surgery complete. {count} neurons silenced.")
        
        # ì €ì¥
        logger.info(f"ğŸ’¾ Saving patient to: {output_path}")
        save_file(tensors, output_path)
        logger.info("âœ¨ Operation Successful.")

if __name__ == "__main__":
    if len(sys.argv) < 3:
        print("Usage: python surgery.py <input_safetensors> <target_neurons_comma_separated>")
        sys.exit(1)
        
    input_path = sys.argv[1]
    targets = [int(x) for x in sys.argv[2].split(",")]
    
    # ì¶œë ¥ íŒŒì¼ëª… ìë™ ìƒì„±
    dir_name = os.path.dirname(input_path)
    base_name = os.path.basename(input_path)
    name, ext = os.path.splitext(base_name)
    output_path = os.path.join(dir_name, f"{name}_lobotomized{ext}")
    
    surgeon = NeuroSurgeon(input_path)
    surgeon.lobotomize(targets, output_path)
