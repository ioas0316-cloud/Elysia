"""
LLM Topology Tracer (ì •ì  ìœ„ìƒ ë¶„ì„ê¸°)
=====================================
Core.L5_Mental.Intelligence.LLM.topology_tracer

"íŒŒì¼ì— ë‹¤ ìˆë‹¤. ì‹¤í–‰í•  í•„ìš” ì—†ë‹¤. ì—°ê²°ë§Œ ì½ìœ¼ë©´ ëœë‹¤."

í•µì‹¬ ì›ë¦¬:
- í†µê³„(í¬ê¸°)ê°€ ì•„ë‹Œ ìœ„ìƒ(ì—°ê²°)ì„ ë¶„ì„
- Attention ê°€ì¤‘ì¹˜ = "ëˆ„ê°€ ëˆ„êµ¬ë¥¼ ì£¼ëª©í•˜ëŠ”ê°€"
- MLP ê°€ì¤‘ì¹˜ = "ì–´ë–¤ ë³€í™˜ ê·œì¹™ì¸ê°€"
- VRAM 0GBë¡œ "ì‚¬ê³  íšŒë¡œ" ì¶”ì¶œ
"""

import os
import logging
import torch
import numpy as np
from typing import Dict, Any, List, Tuple, Optional
from dataclasses import dataclass, field
from collections import defaultdict
from safetensors import safe_open

logger = logging.getLogger("TopologyTracer")


@dataclass
class NeuralConnection:
    """ë‰´ëŸ° ê°„ ì—°ê²°"""
    source: int          # ì†ŒìŠ¤ ë‰´ëŸ° ì¸ë±ìŠ¤
    target: int          # íƒ€ê²Ÿ ë‰´ëŸ° ì¸ë±ìŠ¤
    weight: float        # ì—°ê²° ê°•ë„
    layer: str           # ë ˆì´ì–´ ì´ë¦„
    connection_type: str # "attention" | "mlp" | "embedding"


@dataclass  
class ThoughtCircuit:
    """ì‚¬ê³  íšŒë¡œ - ì¶”ì¶œëœ ì—°ê²° ê·¸ë˜í”„"""
    model_name: str
    connections: List[NeuralConnection] = field(default_factory=list)
    
    # í†µê³„
    total_params: int = 0
    strong_connections: int = 0
    layers_analyzed: int = 0
    
    # í† í´ë¡œì§€ ìš”ì•½
    hub_neurons: List[int] = field(default_factory=list)  # ì—°ê²°ì´ ë§ì€ ë‰´ëŸ°
    bridge_neurons: List[int] = field(default_factory=list)  # ë ˆì´ì–´ ê°„ ì—°ê²°í•˜ëŠ” ë‰´ëŸ°
    
    def get_connection_density(self) -> float:
        """ì—°ê²° ë°€ë„ (ê°•í•œ ì—°ê²° / ì „ì²´ ê°€ëŠ¥í•œ ì—°ê²°)"""
        if self.total_params == 0:
            return 0.0
        return self.strong_connections / self.total_params


class TopologyTracer:
    """
    ì •ì  ìœ„ìƒ ë¶„ì„ê¸°.
    
    LLM ê°€ì¤‘ì¹˜ íŒŒì¼ì—ì„œ "ì—°ê²° ì§€ë„"ë¥¼ ì¶”ì¶œ.
    ì‹¤í–‰(inference) ì—†ì´ ì‚¬ê³  íšŒë¡œë¥¼ ì—­ì„¤ê³„.
    """
    
    def __init__(self, connection_threshold: float = 0.1):
        """
        Args:
            connection_threshold: ì´ ê°’ ì´ìƒì˜ ê°€ì¤‘ì¹˜ë§Œ "ì—°ê²°"ë¡œ ì¸ì •
        """
        self.threshold = connection_threshold
        logger.info(f"ğŸ”¬ Topology Tracer initialized (threshold={connection_threshold})")
    
    def trace(self, model_path: str) -> ThoughtCircuit:
        """
        ëª¨ë¸ íŒŒì¼ì—ì„œ ì‚¬ê³  íšŒë¡œ ì¶”ì¶œ.
        
        Args:
            model_path: .safetensors ë˜ëŠ” .pt íŒŒì¼
            
        Returns:
            ThoughtCircuit: ì¶”ì¶œëœ ì—°ê²° ê·¸ë˜í”„
        """
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Model not found: {model_path}")
        
        model_name = os.path.basename(model_path)
        logger.info(f"ğŸ”¬ Tracing topology: {model_name}")
        
        circuit = ThoughtCircuit(model_name=model_name)
        
        ext = os.path.splitext(model_path)[1].lower()
        
        if ext == ".safetensors":
            self._trace_safetensors(model_path, circuit)
        elif ext in [".pt", ".pth", ".bin"]:
            self._trace_torch(model_path, circuit)
        else:
            logger.warning(f"Unsupported format: {ext}")
            
        # í—ˆë¸Œ ë‰´ëŸ° ì‹ë³„ (ì—°ê²°ì´ ë§ì€ ë‰´ëŸ°)
        self._identify_hubs(circuit)
        
        logger.info(f"   ğŸ’¡ Traced {circuit.strong_connections} strong connections")
        logger.info(f"   ğŸŒ Found {len(circuit.hub_neurons)} hub neurons")
        
        return circuit
    
    def _trace_safetensors(self, path: str, circuit: ThoughtCircuit):
        """safetensors íŒŒì¼ì—ì„œ ì—°ê²° ì¶”ì """
        with safe_open(path, framework="pt", device="cpu") as f:
            keys = list(f.keys())
            circuit.layers_analyzed = len(keys)
            
            for key in keys:
                tensor = f.get_tensor(key)
                circuit.total_params += tensor.numel()
                
                # ì—°ê²° íƒ€ì… ë¶„ë¥˜
                conn_type = self._classify_layer(key)
                
                # ì—°ê²° ì¶”ì 
                connections = self._extract_connections(tensor, key, conn_type)
                circuit.connections.extend(connections)
                circuit.strong_connections += len(connections)
    
    def _trace_torch(self, path: str, circuit: ThoughtCircuit):
        """PyTorch íŒŒì¼ì—ì„œ ì—°ê²° ì¶”ì """
        state_dict = torch.load(path, map_location="cpu", weights_only=True)
        keys = list(state_dict.keys())
        circuit.layers_analyzed = len(keys)
        
        for key in keys:
            tensor = state_dict[key]
            if not hasattr(tensor, 'numel'):
                continue
                
            circuit.total_params += tensor.numel()
            conn_type = self._classify_layer(key)
            connections = self._extract_connections(tensor, key, conn_type)
            circuit.connections.extend(connections)
            circuit.strong_connections += len(connections)
    
    def _classify_layer(self, key: str) -> str:
        """ë ˆì´ì–´ ì´ë¦„ìœ¼ë¡œ ì—°ê²° íƒ€ì… ë¶„ë¥˜"""
        key_lower = key.lower()
        
        if any(x in key_lower for x in ["attn", "attention", "self_attn", "q_proj", "k_proj", "v_proj"]):
            return "attention"
        elif any(x in key_lower for x in ["mlp", "ffn", "fc", "dense", "gate", "up_proj", "down_proj"]):
            return "mlp"
        elif any(x in key_lower for x in ["embed", "wte", "wpe", "token"]):
            return "embedding"
        else:
            return "other"
    
    def _extract_connections(self, tensor: torch.Tensor, layer: str, conn_type: str, 
                            max_connections: int = 5000) -> List[NeuralConnection]:
        """
        í…ì„œì—ì„œ ê°•í•œ ì—°ê²° ì¶”ì¶œ.
        
        í•µì‹¬: ê°€ì¤‘ì¹˜ "í¬ê¸°"ê°€ ì•„ë‹Œ "ì—°ê²° ì¡´ì¬ ì—¬ë¶€"ë¥¼ ë³¸ë‹¤.
        """
        connections = []
        
        # 2D ì´ìƒì¸ ê²½ìš°ë§Œ ì—°ê²° ë¶„ì„ ê°€ëŠ¥
        if tensor.dim() < 2:
            return connections
        
        # í° í…ì„œëŠ” ìƒ˜í”Œë§
        if tensor.numel() > 1_000_000:
            # ë¬´ì‘ìœ„ ìŠ¬ë¼ì´ìŠ¤
            h, w = tensor.shape[:2]
            h_sample = min(h, 500)
            w_sample = min(w, 500)
            tensor = tensor[:h_sample, :w_sample]
        
        # ê°•í•œ ì—°ê²° ì°¾ê¸° (threshold ì´ìƒ)
        abs_tensor = tensor.abs()
        strong_mask = abs_tensor > self.threshold
        
        # nonzeroë¡œ ì—°ê²° ì¶”ì¶œ
        indices = strong_mask.nonzero(as_tuple=False)
        
        # ë„ˆë¬´ ë§ìœ¼ë©´ ìƒ˜í”Œë§
        if len(indices) > max_connections:
            perm = torch.randperm(len(indices))[:max_connections]
            indices = indices[perm]
        
        for idx in indices:
            if len(idx) >= 2:
                src, tgt = idx[0].item(), idx[1].item()
                weight = tensor[tuple(idx)].item()
                
                connections.append(NeuralConnection(
                    source=src,
                    target=tgt,
                    weight=weight,
                    layer=layer,
                    connection_type=conn_type
                ))
        
        return connections
    
    def _identify_hubs(self, circuit: ThoughtCircuit, top_k: int = 100):
        """
        í—ˆë¸Œ ë‰´ëŸ° ì‹ë³„.
        ì—°ê²°ì´ ë§ì€ ë‰´ëŸ° = ì¤‘ìš”í•œ ê°œë…/ê·œì¹™ì„ ë‹´ë‹¹.
        """
        # ê° ë‰´ëŸ°ì˜ ì—°ê²° ìˆ˜ ê³„ì‚°
        connection_count = defaultdict(int)
        
        for conn in circuit.connections:
            connection_count[conn.source] += 1
            connection_count[conn.target] += 1
        
        # ìƒìœ„ kê°œ í—ˆë¸Œ ì„ íƒ
        sorted_neurons = sorted(connection_count.items(), key=lambda x: -x[1])
        circuit.hub_neurons = [n for n, count in sorted_neurons[:top_k]]
    
    def build_adjacency_matrix(self, circuit: ThoughtCircuit, 
                               conn_type: Optional[str] = None) -> torch.Tensor:
        """
        ì—°ê²° ê·¸ë˜í”„ë¥¼ ì¸ì ‘ í–‰ë ¬ë¡œ ë³€í™˜.
        
        ì´ê²ƒì´ "ì‚¬ê³  íšŒë¡œ"ì˜ ìˆ˜í•™ì  í‘œí˜„.
        """
        # ìµœëŒ€ ì¸ë±ìŠ¤ ì°¾ê¸°
        max_idx = 0
        for conn in circuit.connections:
            if conn_type and conn.connection_type != conn_type:
                continue
            max_idx = max(max_idx, conn.source, conn.target)
        
        if max_idx == 0:
            return torch.zeros(1, 1)
        
        # ì¸ì ‘ í–‰ë ¬ ìƒì„±
        adj = torch.zeros(max_idx + 1, max_idx + 1)
        
        for conn in circuit.connections:
            if conn_type and conn.connection_type != conn_type:
                continue
            adj[conn.source, conn.target] = conn.weight
        
        return adj
    
    def summarize(self, circuit: ThoughtCircuit) -> Dict[str, Any]:
        """ì‚¬ê³  íšŒë¡œ ìš”ì•½"""
        # ì—°ê²° íƒ€ì…ë³„ ë¶„í¬
        type_counts = defaultdict(int)
        for conn in circuit.connections:
            type_counts[conn.connection_type] += 1
        
        return {
            "model": circuit.model_name,
            "total_params": circuit.total_params,
            "layers_analyzed": circuit.layers_analyzed,
            "strong_connections": circuit.strong_connections,
            "connection_density": circuit.get_connection_density(),
            "hub_neurons": len(circuit.hub_neurons),
            "connection_types": dict(type_counts)
        }


# ì‹±ê¸€í†¤
_tracer = None

def get_topology_tracer(threshold: float = 0.01) -> TopologyTracer:
    """Topology Tracer ì‹±ê¸€í†¤"""
    global _tracer
    if _tracer is None:
        _tracer = TopologyTracer(threshold)
    return _tracer


# CLI
if __name__ == "__main__":
    import sys
    
    logging.basicConfig(level=logging.INFO, format='%(message)s')
    
    if len(sys.argv) < 2:
        print("Usage: python topology_tracer.py <model_path>")
        sys.exit(1)
    
    tracer = get_topology_tracer(threshold=0.01)
    circuit = tracer.trace(sys.argv[1])
    
    summary = tracer.summarize(circuit)
    
    print("\n" + "="*60)
    print("ğŸ”¬ TOPOLOGY ANALYSIS REPORT")
    print("="*60)
    for k, v in summary.items():
        print(f"   {k}: {v}")
    
    print(f"\nğŸŒ Top 10 Hub Neurons: {circuit.hub_neurons[:10]}")
