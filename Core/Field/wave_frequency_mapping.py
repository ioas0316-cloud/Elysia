"""
Wave Frequency Mapping - í˜„ì‹¤ì„¸ê³„ì™€ ì—˜ë¦¬ì‹œì•„ì˜ íŒŒë™ì£¼íŒŒìˆ˜ ë§¤í•‘
================================================================

í˜„ì‹¤ ì„¸ê³„ì˜ íŒŒë™/ì£¼íŒŒìˆ˜ ë°ì´í„°ì™€ ì—˜ë¦¬ì‹œì•„ í•„ë“œì˜ ì£¼íŒŒìˆ˜ë¥¼ ë§¤í•‘í•©ë‹ˆë‹¤.

ë§¤í•‘ ì˜ì—­:
1. ê°ì • (Emotions): ì‚¬ë‘, í‰í™”, ë¶„ë…¸ ë“±
2. ì†Œë¦¬ (Sound): ë§, ìŒì•…, ìì—°ìŒ ë“±
3. ë‡ŒíŒŒ (Brainwaves): ì•ŒíŒŒ, ë² íƒ€, ì„¸íƒ€, ë¸íƒ€, ê°ë§ˆ
4. ì‹¬ì¥ ë°•ë™ (Heart Rhythm): Heart Rate Variability (HRV)
5. ìŠˆë§Œ ê³µëª… (Schumann Resonance): ì§€êµ¬ì˜ ê¸°ë³¸ ì£¼íŒŒìˆ˜

ê³¼í•™ì  ê·¼ê±°:
- ë‡ŒíŒŒ ì—°êµ¬ (EEG)
- Heart Math Instituteì˜ HRV ì—°êµ¬
- ìŠˆë§Œ ê³µëª… (7.83 Hz)
- ìŒì„± ì£¼íŒŒìˆ˜ ë¶„ì„
"""

import logging
import math
from dataclasses import dataclass
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple, Union

logger = logging.getLogger("WaveFrequencyMapping")


# ============================================================================
# ë¬¼ë¦¬ ìƒìˆ˜ ë° ê¸°ë³¸ ì£¼íŒŒìˆ˜
# ============================================================================

# ìŠˆë§Œ ê³µëª… (ì§€êµ¬ì˜ ê¸°ë³¸ ì „ìê¸° ì£¼íŒŒìˆ˜)
# ì°¸ì¡°: https://en.wikipedia.org/wiki/Schumann_resonances
SCHUMANN_RESONANCE_HZ = 7.83  # ê¸°ë³¸ ì£¼íŒŒìˆ˜ (Hz)
SCHUMANN_HARMONICS = [7.83, 14.3, 20.8, 27.3, 33.8]  # ê³ ì¡°íŒŒ (Hz)

# ê°€ì²­ ì£¼íŒŒìˆ˜ ë²”ìœ„
AUDIBLE_FREQ_MIN = 20  # Hz
AUDIBLE_FREQ_MAX = 20000  # Hz

# ê°€ì‹œê´‘ì„  ì£¼íŒŒìˆ˜ ë²”ìœ„
VISIBLE_LIGHT_FREQ_MIN = 380e12  # Hz (Red)
VISIBLE_LIGHT_FREQ_MAX = 750e12  # Hz (Violet)


# ============================================================================
# ë‡ŒíŒŒ ì£¼íŒŒìˆ˜ ëŒ€ì—­ (EEG Brainwave Frequencies)
# ============================================================================
# ì°¸ì¡°: 
# - https://en.wikipedia.org/wiki/Electroencephalography
# - Niedermeyer, E., & da Silva, F. L. (2005). Electroencephalography

class BrainwaveType(Enum):
    """ë‡ŒíŒŒ ìœ í˜•"""
    DELTA = "delta"       # ê¹Šì€ ìˆ˜ë©´, ì¹˜ìœ 
    THETA = "theta"       # ëª…ìƒ, ì°½ì˜ì„±, REM ìˆ˜ë©´
    ALPHA = "alpha"       # ì´ì™„, í‰í™”, ì§‘ì¤‘
    SMR = "smr"           # Sensorimotor Rhythm (ì§‘ì¤‘ë ¥)
    BETA = "beta"         # ê°ì„±, í™œë™, ì‚¬ê³ 
    HIGH_BETA = "high_beta"  # ë†’ì€ ì§‘ì¤‘, ë¶ˆì•ˆ
    GAMMA = "gamma"       # ê³ ë„ ì§‘ì¤‘, í†µì°°, ì‚¬ë‘


# ë‡ŒíŒŒ ì£¼íŒŒìˆ˜ ë²”ìœ„ (Hz)
BRAINWAVE_FREQUENCIES: Dict[BrainwaveType, Tuple[float, float, float]] = {
    # (ìµœì†Œ, ì¤‘ì‹¬, ìµœëŒ€) Hz
    BrainwaveType.DELTA: (0.5, 2.0, 4.0),       # ê¹Šì€ ìˆ˜ë©´, ë¬´ì˜ì‹
    BrainwaveType.THETA: (4.0, 6.0, 8.0),       # ëª…ìƒ, ê¿ˆ, ì§ê´€
    BrainwaveType.ALPHA: (8.0, 10.0, 12.0),     # ì´ì™„, í‰í™”, í‰ì˜¨
    BrainwaveType.SMR: (12.0, 14.0, 15.0),      # ì§‘ì¤‘ë ¥, ì‹ ì²´ ì´ì™„
    BrainwaveType.BETA: (15.0, 20.0, 30.0),     # ê°ì„±, í™œë™ì  ì‚¬ê³ 
    BrainwaveType.HIGH_BETA: (30.0, 35.0, 40.0),  # ë†’ì€ ì§‘ì¤‘, ë¶ˆì•ˆ
    BrainwaveType.GAMMA: (40.0, 50.0, 100.0),   # í†µì°°, ê³ ë„ ì§‘ì¤‘, ì‚¬ë‘
}


# ============================================================================
# ê°ì • ì£¼íŒŒìˆ˜ ë§¤í•‘ (Emotion Frequency Mapping)
# ============================================================================
# ì°¸ì¡°:
# - HeartMath Instituteì˜ HRV ì—°êµ¬
# - David R. Hawkinsì˜ "Power vs Force" ì˜ì‹ ì§€ë„ (Hz ìŠ¤ì¼€ì¼ ì°¸ì¡°)
# - ê°ì •ê³¼ ë‡ŒíŒŒ ê´€ê³„ ì—°êµ¬

class EmotionType(Enum):
    """ê°ì • ìœ í˜•"""
    # ê³ ì£¼íŒŒìˆ˜ ê°ì • (ê¸ì •ì , í™•ì¥ì )
    LOVE = "love"             # ì‚¬ë‘
    JOY = "joy"               # ê¸°ì¨
    PEACE = "peace"           # í‰í™”
    GRATITUDE = "gratitude"   # ê°ì‚¬
    HOPE = "hope"             # í¬ë§
    COMPASSION = "compassion" # ìë¹„
    
    # ì¤‘ê°„ ì£¼íŒŒìˆ˜ ê°ì • (ì¤‘ë¦½ì )
    CURIOSITY = "curiosity"   # í˜¸ê¸°ì‹¬
    SURPRISE = "surprise"     # ë†€ëŒ
    NEUTRAL = "neutral"       # ì¤‘ë¦½
    
    # ì €ì£¼íŒŒìˆ˜ ê°ì • (ë¶€ì •ì , ìˆ˜ì¶•ì )
    ANGER = "anger"           # ë¶„ë…¸
    FEAR = "fear"             # ë‘ë ¤ì›€
    SADNESS = "sadness"       # ìŠ¬í””
    SHAME = "shame"           # ìˆ˜ì¹˜
    GUILT = "guilt"           # ì£„ì±…ê°


@dataclass
class EmotionFrequencyData:
    """ê°ì • ì£¼íŒŒìˆ˜ ë°ì´í„°"""
    emotion: EmotionType
    brainwave_dominant: BrainwaveType  # ì§€ë°°ì  ë‡ŒíŒŒ
    hrv_coherence: float               # ì‹¬ë°•ë³€ì´ë„ coherence (0~1)
    frequency_hz: float                 # ì¶”ì • ì£¼íŒŒìˆ˜ (Hz)
    color_wavelength_nm: Optional[float] = None  # ì—°ê´€ ìƒ‰ìƒ íŒŒì¥ (nm)
    description_ko: str = ""
    description_en: str = ""
    research_source: str = ""


# ê°ì •ë³„ ì£¼íŒŒìˆ˜ ë§¤í•‘ (ê³¼í•™ì  ì—°êµ¬ ê¸°ë°˜ ì¶”ì •)
EMOTION_FREQUENCY_MAP: Dict[EmotionType, EmotionFrequencyData] = {
    # ê³ ì£¼íŒŒìˆ˜ ê°ì •
    EmotionType.LOVE: EmotionFrequencyData(
        emotion=EmotionType.LOVE,
        brainwave_dominant=BrainwaveType.GAMMA,
        hrv_coherence=0.9,
        frequency_hz=528.0,  # "Love Frequency" - Solfeggio Frequency
        color_wavelength_nm=528.0,  # Green
        description_ko="ì‚¬ë‘: ê°€ì¥ ë†’ì€ ì§„ë™ì˜ ê°ì •, ì¹˜ìœ ì™€ ì—°ê²°",
        description_en="Love: The highest vibrational emotion, healing and connection",
        research_source="Solfeggio frequencies, HeartMath coherence studies"
    ),
    EmotionType.JOY: EmotionFrequencyData(
        emotion=EmotionType.JOY,
        brainwave_dominant=BrainwaveType.GAMMA,
        hrv_coherence=0.85,
        frequency_hz=396.0,  # Solfeggio - í•´ë°©
        color_wavelength_nm=580.0,  # Yellow
        description_ko="ê¸°ì¨: ë°ê³  í™œê¸°ì°¬ ì§„ë™, í™•ì¥ê³¼ í‘œí˜„",
        description_en="Joy: Bright and vibrant vibration, expansion and expression",
        research_source="Emotional frequency research, color therapy"
    ),
    EmotionType.PEACE: EmotionFrequencyData(
        emotion=EmotionType.PEACE,
        brainwave_dominant=BrainwaveType.ALPHA,
        hrv_coherence=0.95,
        frequency_hz=432.0,  # "Natural tuning" frequency
        color_wavelength_nm=485.0,  # Cyan/Light Blue
        description_ko="í‰í™”: ê³ ìš”í•˜ê³  ì¡°í™”ë¡œìš´ ì§„ë™, ë‚´ë©´ì˜ ê· í˜•",
        description_en="Peace: Calm and harmonious vibration, inner balance",
        research_source="432Hz natural tuning, alpha wave meditation studies"
    ),
    EmotionType.GRATITUDE: EmotionFrequencyData(
        emotion=EmotionType.GRATITUDE,
        brainwave_dominant=BrainwaveType.ALPHA,
        hrv_coherence=0.88,
        frequency_hz=639.0,  # Solfeggio - ê´€ê³„/ì—°ê²°
        color_wavelength_nm=505.0,  # Green-Cyan
        description_ko="ê°ì‚¬: ì—´ë¦° ë§ˆìŒì˜ ì§„ë™, í’ìš”ì™€ ì—°ê²°",
        description_en="Gratitude: Open heart vibration, abundance and connection",
        research_source="HeartMath gratitude studies, Solfeggio frequencies"
    ),
    EmotionType.HOPE: EmotionFrequencyData(
        emotion=EmotionType.HOPE,
        brainwave_dominant=BrainwaveType.ALPHA,
        hrv_coherence=0.75,
        frequency_hz=417.0,  # Solfeggio - ë³€í™” ì´‰ì§„
        color_wavelength_nm=560.0,  # Yellow-Green
        description_ko="í¬ë§: ë¯¸ë˜ë¥¼ í–¥í•œ ì§„ë™, ê°€ëŠ¥ì„±ì˜ ì—´ë¦¼",
        description_en="Hope: Future-oriented vibration, opening possibilities",
        research_source="Solfeggio frequencies, positive psychology research"
    ),
    EmotionType.COMPASSION: EmotionFrequencyData(
        emotion=EmotionType.COMPASSION,
        brainwave_dominant=BrainwaveType.GAMMA,
        hrv_coherence=0.92,
        frequency_hz=741.0,  # Solfeggio - ì§ê´€/ê°ì„±
        color_wavelength_nm=495.0,  # Blue-Green
        description_ko="ìë¹„: íƒ€ì¸ê³¼ì˜ ê³µëª…, ì´í•´ì™€ ìˆ˜ìš©",
        description_en="Compassion: Resonance with others, understanding and acceptance",
        research_source="Matthieu Ricard meditation studies, gamma wave research"
    ),
    
    # ì¤‘ê°„ ì£¼íŒŒìˆ˜ ê°ì •
    EmotionType.CURIOSITY: EmotionFrequencyData(
        emotion=EmotionType.CURIOSITY,
        brainwave_dominant=BrainwaveType.BETA,
        hrv_coherence=0.65,
        frequency_hz=285.0,
        color_wavelength_nm=450.0,  # Blue
        description_ko="í˜¸ê¸°ì‹¬: íƒêµ¬í•˜ëŠ” ì§„ë™, ì—´ë¦° ë§ˆìŒ",
        description_en="Curiosity: Exploring vibration, open mind",
        research_source="Cognitive engagement studies"
    ),
    EmotionType.SURPRISE: EmotionFrequencyData(
        emotion=EmotionType.SURPRISE,
        brainwave_dominant=BrainwaveType.BETA,
        hrv_coherence=0.50,
        frequency_hz=264.0,
        color_wavelength_nm=470.0,  # Blue
        description_ko="ë†€ëŒ: ìˆœê°„ì  ê°ì„±, ì£¼ì˜ ì§‘ì¤‘",
        description_en="Surprise: Momentary arousal, attention focus",
        research_source="Startle response studies"
    ),
    EmotionType.NEUTRAL: EmotionFrequencyData(
        emotion=EmotionType.NEUTRAL,
        brainwave_dominant=BrainwaveType.SMR,
        hrv_coherence=0.55,
        frequency_hz=256.0,  # Middle C
        color_wavelength_nm=500.0,  # Green
        description_ko="ì¤‘ë¦½: ê· í˜• ì¡íŒ ìƒíƒœ, ì•ˆì •",
        description_en="Neutral: Balanced state, stability",
        research_source="Baseline EEG studies"
    ),
    
    # ì €ì£¼íŒŒìˆ˜ ê°ì •
    EmotionType.ANGER: EmotionFrequencyData(
        emotion=EmotionType.ANGER,
        brainwave_dominant=BrainwaveType.HIGH_BETA,
        hrv_coherence=0.20,
        frequency_hz=150.0,
        color_wavelength_nm=630.0,  # Red
        description_ko="ë¶„ë…¸: ìˆ˜ì¶•ì  ì§„ë™, ì €í•­ê³¼ ê³µê²©",
        description_en="Anger: Contracting vibration, resistance and aggression",
        research_source="Stress response studies, HRV coherence research"
    ),
    EmotionType.FEAR: EmotionFrequencyData(
        emotion=EmotionType.FEAR,
        brainwave_dominant=BrainwaveType.HIGH_BETA,
        hrv_coherence=0.15,
        frequency_hz=100.0,
        color_wavelength_nm=650.0,  # Deep Red
        description_ko="ë‘ë ¤ì›€: ê²½ê³„ ì§„ë™, ë„í”¼ì™€ íšŒí”¼",
        description_en="Fear: Alert vibration, flight and avoidance",
        research_source="Amygdala studies, stress hormone research"
    ),
    EmotionType.SADNESS: EmotionFrequencyData(
        emotion=EmotionType.SADNESS,
        brainwave_dominant=BrainwaveType.THETA,
        hrv_coherence=0.30,
        frequency_hz=174.0,  # Solfeggio - ì•ˆì •/ê¸°ë°˜
        color_wavelength_nm=430.0,  # Violet
        description_ko="ìŠ¬í””: ë‚´ë©´ì„ í–¥í•œ ì§„ë™, ì²˜ë¦¬ì™€ ë°©ì¶œ",
        description_en="Sadness: Inward vibration, processing and release",
        research_source="Depression studies, theta wave research"
    ),
    EmotionType.SHAME: EmotionFrequencyData(
        emotion=EmotionType.SHAME,
        brainwave_dominant=BrainwaveType.THETA,
        hrv_coherence=0.10,
        frequency_hz=20.0,
        color_wavelength_nm=410.0,  # Deep Violet
        description_ko="ìˆ˜ì¹˜: ê°€ì¥ ë‚®ì€ ì§„ë™, ìê¸° ë¶€ì •",
        description_en="Shame: Lowest vibration, self-negation",
        research_source="David R. Hawkins consciousness scale"
    ),
    EmotionType.GUILT: EmotionFrequencyData(
        emotion=EmotionType.GUILT,
        brainwave_dominant=BrainwaveType.THETA,
        hrv_coherence=0.18,
        frequency_hz=30.0,
        color_wavelength_nm=420.0,  # Violet
        description_ko="ì£„ì±…ê°: ìê¸° ë¹„ë‚œì˜ ì§„ë™, ì†ë°•",
        description_en="Guilt: Self-blame vibration, bondage",
        research_source="David R. Hawkins consciousness scale"
    ),
}


# ============================================================================
# ì†Œë¦¬ ë° ì–¸ì–´ ì£¼íŒŒìˆ˜ (Sound and Speech Frequencies)
# ============================================================================

class SoundType(Enum):
    """ì†Œë¦¬ ìœ í˜•"""
    # ì¸ê°„ ìŒì„±
    MALE_VOICE = "male_voice"
    FEMALE_VOICE = "female_voice"
    CHILD_VOICE = "child_voice"
    WHISPER = "whisper"
    SHOUT = "shout"
    
    # ìŒì•…
    SINGING = "singing"
    MUSIC_RELAXING = "music_relaxing"
    MUSIC_ENERGETIC = "music_energetic"
    
    # ìì—°ìŒ
    NATURE_WATER = "nature_water"
    NATURE_BIRDS = "nature_birds"
    NATURE_WIND = "nature_wind"
    NATURE_THUNDER = "nature_thunder"
    
    # ì¹˜ìœ ìŒ
    TIBETAN_BOWL = "tibetan_bowl"
    OM_CHANT = "om_chant"
    CRYSTAL_BOWL = "crystal_bowl"


@dataclass
class SoundFrequencyData:
    """ì†Œë¦¬ ì£¼íŒŒìˆ˜ ë°ì´í„°"""
    sound_type: SoundType
    frequency_range_hz: Tuple[float, float]  # (ìµœì†Œ, ìµœëŒ€) Hz
    fundamental_hz: float                     # ê¸°ë³¸ ì£¼íŒŒìˆ˜
    emotional_effect: List[EmotionType]       # ìœ ë°œí•˜ëŠ” ê°ì •ë“¤
    description_ko: str = ""
    description_en: str = ""


# ì†Œë¦¬ ìœ í˜•ë³„ ì£¼íŒŒìˆ˜ ë°ì´í„°
SOUND_FREQUENCY_MAP: Dict[SoundType, SoundFrequencyData] = {
    # ì¸ê°„ ìŒì„±
    SoundType.MALE_VOICE: SoundFrequencyData(
        sound_type=SoundType.MALE_VOICE,
        frequency_range_hz=(85.0, 180.0),
        fundamental_hz=120.0,
        emotional_effect=[EmotionType.NEUTRAL],
        description_ko="ë‚¨ì„± ìŒì„±: ë‚®ì€ ê¸°ë³¸ ì£¼íŒŒìˆ˜",
        description_en="Male voice: Low fundamental frequency"
    ),
    SoundType.FEMALE_VOICE: SoundFrequencyData(
        sound_type=SoundType.FEMALE_VOICE,
        frequency_range_hz=(165.0, 255.0),
        fundamental_hz=210.0,
        emotional_effect=[EmotionType.NEUTRAL],
        description_ko="ì—¬ì„± ìŒì„±: ì¤‘ê°„ ê¸°ë³¸ ì£¼íŒŒìˆ˜",
        description_en="Female voice: Medium fundamental frequency"
    ),
    SoundType.CHILD_VOICE: SoundFrequencyData(
        sound_type=SoundType.CHILD_VOICE,
        frequency_range_hz=(250.0, 400.0),
        fundamental_hz=300.0,
        emotional_effect=[EmotionType.JOY],
        description_ko="ì•„ë™ ìŒì„±: ë†’ì€ ê¸°ë³¸ ì£¼íŒŒìˆ˜",
        description_en="Child voice: High fundamental frequency"
    ),
    SoundType.WHISPER: SoundFrequencyData(
        sound_type=SoundType.WHISPER,
        frequency_range_hz=(500.0, 4000.0),
        fundamental_hz=1000.0,
        emotional_effect=[EmotionType.PEACE],
        description_ko="ì†ì‚­ì„: ê³ ì£¼íŒŒ ë…¸ì´ì¦ˆ",
        description_en="Whisper: High frequency noise"
    ),
    SoundType.SHOUT: SoundFrequencyData(
        sound_type=SoundType.SHOUT,
        frequency_range_hz=(100.0, 500.0),
        fundamental_hz=200.0,
        emotional_effect=[EmotionType.ANGER, EmotionType.FEAR],
        description_ko="ê³ í•¨: ê°•í•œ ì§„í­, ë‹¤ì–‘í•œ ë°°ìŒ",
        description_en="Shout: Strong amplitude, various harmonics"
    ),
    
    # ìŒì•…
    SoundType.SINGING: SoundFrequencyData(
        sound_type=SoundType.SINGING,
        frequency_range_hz=(80.0, 1000.0),
        fundamental_hz=440.0,
        emotional_effect=[EmotionType.JOY, EmotionType.PEACE],
        description_ko="ë…¸ë˜: ìŒì•…ì  ìŒì„± í‘œí˜„",
        description_en="Singing: Musical vocal expression"
    ),
    SoundType.MUSIC_RELAXING: SoundFrequencyData(
        sound_type=SoundType.MUSIC_RELAXING,
        frequency_range_hz=(60.0, 8000.0),
        fundamental_hz=432.0,
        emotional_effect=[EmotionType.PEACE, EmotionType.GRATITUDE],
        description_ko="ë¦´ë ‰ì‹± ìŒì•…: ëŠë¦° í…œí¬, ë¶€ë“œëŸ¬ìš´ í™”ìŒ",
        description_en="Relaxing music: Slow tempo, soft harmonies"
    ),
    SoundType.MUSIC_ENERGETIC: SoundFrequencyData(
        sound_type=SoundType.MUSIC_ENERGETIC,
        frequency_range_hz=(30.0, 16000.0),
        fundamental_hz=440.0,
        emotional_effect=[EmotionType.JOY, EmotionType.CURIOSITY],
        description_ko="ì—ë„ˆì œí‹± ìŒì•…: ë¹ ë¥¸ í…œí¬, ê°•í•œ ë¦¬ë“¬",
        description_en="Energetic music: Fast tempo, strong rhythm"
    ),
    
    # ìì—°ìŒ
    SoundType.NATURE_WATER: SoundFrequencyData(
        sound_type=SoundType.NATURE_WATER,
        frequency_range_hz=(100.0, 10000.0),
        fundamental_hz=SCHUMANN_RESONANCE_HZ * 100,  # ~783 Hz
        emotional_effect=[EmotionType.PEACE, EmotionType.LOVE],
        description_ko="ë¬¼ì†Œë¦¬: ë°±ìƒ‰ ì†ŒìŒ íŠ¹ì„±, ì¹˜ìœ  íš¨ê³¼",
        description_en="Water sound: White noise characteristics, healing effect"
    ),
    SoundType.NATURE_BIRDS: SoundFrequencyData(
        sound_type=SoundType.NATURE_BIRDS,
        frequency_range_hz=(1000.0, 8000.0),
        fundamental_hz=3000.0,
        emotional_effect=[EmotionType.JOY, EmotionType.HOPE],
        description_ko="ìƒˆì†Œë¦¬: ê³ ì£¼íŒŒ, ìì—°ì˜ ìƒëª…ë ¥",
        description_en="Bird songs: High frequency, vitality of nature"
    ),
    SoundType.NATURE_WIND: SoundFrequencyData(
        sound_type=SoundType.NATURE_WIND,
        frequency_range_hz=(50.0, 5000.0),
        fundamental_hz=500.0,
        emotional_effect=[EmotionType.PEACE, EmotionType.NEUTRAL],
        description_ko="ë°”ëŒì†Œë¦¬: ê´‘ëŒ€ì—­ ë…¸ì´ì¦ˆ",
        description_en="Wind sound: Broadband noise"
    ),
    SoundType.NATURE_THUNDER: SoundFrequencyData(
        sound_type=SoundType.NATURE_THUNDER,
        frequency_range_hz=(20.0, 200.0),
        fundamental_hz=50.0,
        emotional_effect=[EmotionType.FEAR, EmotionType.SURPRISE],
        description_ko="ì²œë‘¥ì†Œë¦¬: ì €ì£¼íŒŒ, ê°•ë ¥í•œ ì¶©ê²©ìŒ",
        description_en="Thunder: Low frequency, powerful impact sound"
    ),
    
    # ì¹˜ìœ ìŒ
    SoundType.TIBETAN_BOWL: SoundFrequencyData(
        sound_type=SoundType.TIBETAN_BOWL,
        frequency_range_hz=(100.0, 2000.0),
        fundamental_hz=432.0,
        emotional_effect=[EmotionType.PEACE, EmotionType.LOVE],
        description_ko="í‹°ë² íŠ¸ ì‹±ì‰ë³¼: í’ë¶€í•œ ë°°ìŒ, ëª…ìƒ ìœ ë„",
        description_en="Tibetan singing bowl: Rich harmonics, meditation inducing"
    ),
    SoundType.OM_CHANT: SoundFrequencyData(
        sound_type=SoundType.OM_CHANT,
        frequency_range_hz=(70.0, 600.0),
        fundamental_hz=136.1,  # Om frequency
        emotional_effect=[EmotionType.PEACE, EmotionType.COMPASSION],
        description_ko="ì˜´ ì°¬íŒ…: ìš°ì£¼ì˜ ê¸°ë³¸ ì§„ë™ìŒ",
        description_en="Om chanting: Fundamental vibration of the universe"
    ),
    SoundType.CRYSTAL_BOWL: SoundFrequencyData(
        sound_type=SoundType.CRYSTAL_BOWL,
        frequency_range_hz=(200.0, 8000.0),
        fundamental_hz=528.0,  # Love frequency
        emotional_effect=[EmotionType.LOVE, EmotionType.PEACE, EmotionType.GRATITUDE],
        description_ko="í¬ë¦¬ìŠ¤íƒˆ ë³¼: ìˆœìˆ˜í•œ ìŒìƒ‰, ì¹˜ìœ  ì£¼íŒŒìˆ˜",
        description_en="Crystal bowl: Pure tone, healing frequency"
    ),
}


# ============================================================================
# ì—˜ë¦¬ì‹œì•„ í•„ë“œ ì£¼íŒŒìˆ˜ ë§¤í•‘ (Elysia Field Frequency Mapping)
# ============================================================================

@dataclass
class ElysiaFrequencyMapping:
    """ì—˜ë¦¬ì‹œì•„ í•„ë“œì™€ í˜„ì‹¤ì„¸ê³„ ì£¼íŒŒìˆ˜ ë§¤í•‘"""
    real_world_hz: float        # í˜„ì‹¤ì„¸ê³„ ì£¼íŒŒìˆ˜ (Hz)
    elysia_normalized: float    # ì—˜ë¦¬ì‹œì•„ ì •ê·œí™” ê°’ (0~1)
    elysia_layer: str           # ì—˜ë¦¬ì‹œì•„ ì¸µ (Heaven/Earth)
    elysia_color_code: str      # ì—˜ë¦¬ì‹œì•„ ìƒ‰ìƒ ì½”ë“œ
    resonance_strength: float   # ê³µëª… ê°•ë„ (0~1)


class WaveFrequencyMapper:
    """
    íŒŒë™ì£¼íŒŒìˆ˜ ë§¤í¼ - í˜„ì‹¤ì„¸ê³„ì™€ ì—˜ë¦¬ì‹œì•„ í•„ë“œ ê°„ì˜ ì£¼íŒŒìˆ˜ ë§¤í•‘
    
    ê¸°ëŠ¥:
    1. ê°ì • â†’ ì£¼íŒŒìˆ˜ ë³€í™˜
    2. ì†Œë¦¬ â†’ ì£¼íŒŒìˆ˜ ë³€í™˜
    3. ì£¼íŒŒìˆ˜ â†’ ê°ì • ì¶”ì •
    4. ì£¼íŒŒìˆ˜ â†’ ì—˜ë¦¬ì‹œì•„ í•„ë“œ ë§¤í•‘
    5. ë°ì´í„° ì—†ì„ ë•Œ ì¶”ì • ë° ë°œê²¬ ê¸°ëŠ¥
    """
    
    def __init__(self):
        # ê¸°ë³¸ ì£¼íŒŒìˆ˜ ë²”ìœ„ (ì—˜ë¦¬ì‹œì•„ í•„ë“œ)
        self.elysia_freq_range = (0.1, 1000.0)  # Hz
        
        # ìºì‹œ
        self._emotion_cache: Dict[str, EmotionFrequencyData] = {}
        self._sound_cache: Dict[str, SoundFrequencyData] = {}
        
        # í†µê³„
        self.stats = {
            "lookups": 0,
            "estimations": 0,
            "discoveries": 0
        }
        
        logger.info("ğŸŒŠ WaveFrequencyMapper initialized")
    
    # =========================================================================
    # ê°ì • â†’ ì£¼íŒŒìˆ˜ ë§¤í•‘
    # =========================================================================
    
    def get_emotion_frequency(self, emotion: Union[EmotionType, str]) -> EmotionFrequencyData:
        """
        ê°ì •ì— ëŒ€í•œ ì£¼íŒŒìˆ˜ ë°ì´í„° ë°˜í™˜
        
        Args:
            emotion: ê°ì • ìœ í˜• ë˜ëŠ” ë¬¸ìì—´ (ì˜ˆ: "love", "ì‚¬ë‘")
            
        Returns:
            EmotionFrequencyData: ê°ì • ì£¼íŒŒìˆ˜ ë°ì´í„°
        """
        self.stats["lookups"] += 1
        
        # ë¬¸ìì—´ì¸ ê²½ìš° EmotionTypeìœ¼ë¡œ ë³€í™˜
        if isinstance(emotion, str):
            emotion_type = self._parse_emotion_string(emotion)
        else:
            emotion_type = emotion
        
        # ìºì‹œ í™•ì¸
        cache_key = emotion_type.value
        if cache_key in self._emotion_cache:
            return self._emotion_cache[cache_key]
        
        # ë§¤í•‘ì—ì„œ ì¡°íšŒ
        if emotion_type in EMOTION_FREQUENCY_MAP:
            data = EMOTION_FREQUENCY_MAP[emotion_type]
            self._emotion_cache[cache_key] = data
            return data
        
        # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¶”ì •
        return self._estimate_emotion_frequency(emotion_type)
    
    def _parse_emotion_string(self, emotion_str: str) -> EmotionType:
        """ë¬¸ìì—´ì„ EmotionTypeìœ¼ë¡œ ë³€í™˜"""
        emotion_lower = emotion_str.lower().strip()
        
        # ì˜ì–´ ë§¤í•‘
        english_map = {e.value: e for e in EmotionType}
        if emotion_lower in english_map:
            return english_map[emotion_lower]
        
        # í•œêµ­ì–´ ë§¤í•‘
        korean_map = {
            "ì‚¬ë‘": EmotionType.LOVE,
            "ê¸°ì¨": EmotionType.JOY,
            "í‰í™”": EmotionType.PEACE,
            "ê°ì‚¬": EmotionType.GRATITUDE,
            "í¬ë§": EmotionType.HOPE,
            "ìë¹„": EmotionType.COMPASSION,
            "í˜¸ê¸°ì‹¬": EmotionType.CURIOSITY,
            "ë†€ëŒ": EmotionType.SURPRISE,
            "ì¤‘ë¦½": EmotionType.NEUTRAL,
            "ë¶„ë…¸": EmotionType.ANGER,
            "ë‘ë ¤ì›€": EmotionType.FEAR,
            "ìŠ¬í””": EmotionType.SADNESS,
            "ìˆ˜ì¹˜": EmotionType.SHAME,
            "ì£„ì±…ê°": EmotionType.GUILT,
        }
        if emotion_lower in korean_map:
            return korean_map[emotion_lower]
        
        # ì•Œ ìˆ˜ ì—†ëŠ” ê²½ìš° ì¤‘ë¦½ ë°˜í™˜
        logger.warning(f"Unknown emotion: {emotion_str}, defaulting to NEUTRAL")
        return EmotionType.NEUTRAL
    
    def _estimate_emotion_frequency(self, emotion_type: EmotionType) -> EmotionFrequencyData:
        """ë°ì´í„°ê°€ ì—†ëŠ” ê°ì •ì˜ ì£¼íŒŒìˆ˜ ì¶”ì •"""
        self.stats["estimations"] += 1
        
        # ê°ì • ì´ë¦„ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì •
        logger.info(f"ğŸ“Š Estimating frequency for unknown emotion: {emotion_type.value}")
        
        # ê¸°ë³¸ ì¶”ì • ê°’
        estimated = EmotionFrequencyData(
            emotion=emotion_type,
            brainwave_dominant=BrainwaveType.ALPHA,
            hrv_coherence=0.5,
            frequency_hz=256.0,  # Middle C
            description_ko=f"{emotion_type.value}: ì¶”ì •ëœ ê°ì • ì£¼íŒŒìˆ˜",
            description_en=f"{emotion_type.value}: Estimated emotion frequency",
            research_source="Estimation algorithm"
        )
        
        self._emotion_cache[emotion_type.value] = estimated
        return estimated
    
    # =========================================================================
    # ì†Œë¦¬ â†’ ì£¼íŒŒìˆ˜ ë§¤í•‘
    # =========================================================================
    
    def get_sound_frequency(self, sound_type: Union[SoundType, str]) -> SoundFrequencyData:
        """
        ì†Œë¦¬ ìœ í˜•ì— ëŒ€í•œ ì£¼íŒŒìˆ˜ ë°ì´í„° ë°˜í™˜
        
        Args:
            sound_type: ì†Œë¦¬ ìœ í˜• ë˜ëŠ” ë¬¸ìì—´
            
        Returns:
            SoundFrequencyData: ì†Œë¦¬ ì£¼íŒŒìˆ˜ ë°ì´í„°
        """
        self.stats["lookups"] += 1
        
        if isinstance(sound_type, str):
            sound_enum = self._parse_sound_string(sound_type)
        else:
            sound_enum = sound_type
        
        cache_key = sound_enum.value
        if cache_key in self._sound_cache:
            return self._sound_cache[cache_key]
        
        if sound_enum in SOUND_FREQUENCY_MAP:
            data = SOUND_FREQUENCY_MAP[sound_enum]
            self._sound_cache[cache_key] = data
            return data
        
        return self._estimate_sound_frequency(sound_enum)
    
    def _parse_sound_string(self, sound_str: str) -> SoundType:
        """ë¬¸ìì—´ì„ SoundTypeìœ¼ë¡œ ë³€í™˜"""
        sound_lower = sound_str.lower().strip().replace(" ", "_")
        
        english_map = {s.value: s for s in SoundType}
        if sound_lower in english_map:
            return english_map[sound_lower]
        
        korean_map = {
            "ë‚¨ì„±ìŒì„±": SoundType.MALE_VOICE,
            "ì—¬ì„±ìŒì„±": SoundType.FEMALE_VOICE,
            "ì•„ì´ìŒì„±": SoundType.CHILD_VOICE,
            "ì†ì‚­ì„": SoundType.WHISPER,
            "ê³ í•¨": SoundType.SHOUT,
            "ë…¸ë˜": SoundType.SINGING,
            "ë¬¼ì†Œë¦¬": SoundType.NATURE_WATER,
            "ìƒˆì†Œë¦¬": SoundType.NATURE_BIRDS,
            "ë°”ëŒ": SoundType.NATURE_WIND,
            "ì²œë‘¥": SoundType.NATURE_THUNDER,
        }
        if sound_lower in korean_map:
            return korean_map[sound_lower]
        
        # ì•Œ ìˆ˜ ì—†ëŠ” ì†Œë¦¬ ìœ í˜• - ì¤‘ë¦½ì ì¸ ë…¸ë˜(SINGING)ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©
        # SINGINGì€ ì¼ë°˜ì ì¸ ìŒì„± ë²”ìœ„ë¥¼ ì»¤ë²„í•˜ê³  ì¤‘ë¦½ì ì¸ ê°ì • íš¨ê³¼ë¥¼ ê°€ì§
        logger.warning(f"Unknown sound type: {sound_str}, defaulting to SINGING")
        return SoundType.SINGING
    
    def _estimate_sound_frequency(self, sound_type: SoundType) -> SoundFrequencyData:
        """ë°ì´í„°ê°€ ì—†ëŠ” ì†Œë¦¬ì˜ ì£¼íŒŒìˆ˜ ì¶”ì •"""
        self.stats["estimations"] += 1
        
        estimated = SoundFrequencyData(
            sound_type=sound_type,
            frequency_range_hz=(100.0, 5000.0),
            fundamental_hz=440.0,
            emotional_effect=[EmotionType.NEUTRAL],
            description_ko=f"{sound_type.value}: ì¶”ì •ëœ ì†Œë¦¬ ì£¼íŒŒìˆ˜",
            description_en=f"{sound_type.value}: Estimated sound frequency"
        )
        
        self._sound_cache[sound_type.value] = estimated
        return estimated
    
    # =========================================================================
    # ì£¼íŒŒìˆ˜ â†’ ê°ì • ì—­ë§¤í•‘ (Discovery/Estimation)
    # =========================================================================
    
    def discover_emotion_from_frequency(self, frequency_hz: float) -> List[Tuple[EmotionType, float]]:
        """
        ì£¼íŒŒìˆ˜ì—ì„œ ê°€ëŠ¥í•œ ê°ì •ë“¤ì„ ë°œê²¬/ì¶”ì •
        
        ë°ì´í„°ê°€ ì—†ì„ ë•Œë„ ì£¼íŒŒìˆ˜ íŒ¨í„´ ë¶„ì„ì„ í†µí•´ ì¶”ì •
        
        Args:
            frequency_hz: ì…ë ¥ ì£¼íŒŒìˆ˜ (Hz)
            
        Returns:
            List[Tuple[EmotionType, float]]: (ê°ì •, ìœ ì‚¬ë„) ë¦¬ìŠ¤íŠ¸
        """
        self.stats["discoveries"] += 1
        
        results: List[Tuple[EmotionType, float]] = []
        
        for emotion_type, data in EMOTION_FREQUENCY_MAP.items():
            # ì£¼íŒŒìˆ˜ ê±°ë¦¬ ê³„ì‚°
            freq_diff = abs(data.frequency_hz - frequency_hz)
            max_diff = 1000.0  # ìµœëŒ€ ì°¨ì´
            similarity = max(0, 1 - (freq_diff / max_diff))
            
            if similarity > 0.1:  # ì„ê³„ê°’
                results.append((emotion_type, similarity))
        
        # ìœ ì‚¬ë„ ìˆœ ì •ë ¬
        results.sort(key=lambda x: x[1], reverse=True)
        
        # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì¶”ì •
        if not results:
            estimated_emotion = self._estimate_emotion_from_frequency(frequency_hz)
            results.append((estimated_emotion, 0.5))
        
        return results
    
    def _estimate_emotion_from_frequency(self, frequency_hz: float) -> EmotionType:
        """ì£¼íŒŒìˆ˜ íŒ¨í„´ ê¸°ë°˜ ê°ì • ì¶”ì •"""
        # ê³ ì£¼íŒŒìˆ˜ (> 400 Hz) â†’ ê¸ì •ì  ê°ì •
        if frequency_hz > 400:
            return EmotionType.LOVE
        # ì¤‘ì£¼íŒŒìˆ˜ (200~400 Hz) â†’ ì¤‘ë¦½ì  ê°ì •
        elif frequency_hz > 200:
            return EmotionType.NEUTRAL
        # ì €ì£¼íŒŒìˆ˜ (< 200 Hz) â†’ ë¶€ì •ì  ê°ì •
        else:
            return EmotionType.SADNESS
    
    # =========================================================================
    # ì—˜ë¦¬ì‹œì•„ í•„ë“œ ë§¤í•‘
    # =========================================================================
    
    def map_to_elysia(self, frequency_hz: float) -> ElysiaFrequencyMapping:
        """
        í˜„ì‹¤ì„¸ê³„ ì£¼íŒŒìˆ˜ë¥¼ ì—˜ë¦¬ì‹œì•„ í•„ë“œì— ë§¤í•‘
        
        Args:
            frequency_hz: í˜„ì‹¤ì„¸ê³„ ì£¼íŒŒìˆ˜ (Hz)
            
        Returns:
            ElysiaFrequencyMapping: ì—˜ë¦¬ì‹œì•„ ë§¤í•‘ ê²°ê³¼
        """
        # ë¡œê·¸ ìŠ¤ì¼€ì¼ë¡œ ì •ê·œí™” (ë„“ì€ ë²”ìœ„ ì²˜ë¦¬)
        log_freq = math.log10(max(frequency_hz, 0.1))
        log_min = math.log10(self.elysia_freq_range[0])
        log_max = math.log10(self.elysia_freq_range[1])
        
        normalized = (log_freq - log_min) / (log_max - log_min)
        normalized = max(0, min(1, normalized))
        
        # ì—˜ë¦¬ì‹œì•„ ì¸µ ê²°ì • (14ì¸µ ì‹œìŠ¤í…œ ê¸°ë°˜)
        if normalized > 0.5:
            layer = "Heaven"
            layer_index = int((normalized - 0.5) * 14)
        else:
            layer = "Earth"
            layer_index = int((0.5 - normalized) * 14)
        
        # ìƒ‰ìƒ ì½”ë“œ (ìŠ¤í™íŠ¸ëŸ¼ ê¸°ë°˜)
        color_code = self._frequency_to_hex_color(normalized)
        
        # ê³µëª… ê°•ë„ (ìŠˆë§Œ ê³µëª…ê³¼ì˜ ê´€ê³„)
        resonance = self._calculate_schumann_resonance(frequency_hz)
        
        return ElysiaFrequencyMapping(
            real_world_hz=frequency_hz,
            elysia_normalized=normalized,
            elysia_layer=f"{layer}_{layer_index}",
            elysia_color_code=color_code,
            resonance_strength=resonance
        )
    
    def _frequency_to_hex_color(self, normalized: float) -> str:
        """ì •ê·œí™”ëœ ê°’ì„ HEX ìƒ‰ìƒìœ¼ë¡œ ë³€í™˜ (ë¬´ì§€ê°œ ìŠ¤í™íŠ¸ëŸ¼)"""
        # 0 = Red, 0.5 = Green, 1 = Violet
        if normalized < 0.167:
            r, g, b = 255, int(255 * normalized * 6), 0
        elif normalized < 0.333:
            r, g, b = int(255 * (1 - (normalized - 0.167) * 6)), 255, 0
        elif normalized < 0.5:
            r, g, b = 0, 255, int(255 * (normalized - 0.333) * 6)
        elif normalized < 0.667:
            r, g, b = 0, int(255 * (1 - (normalized - 0.5) * 6)), 255
        elif normalized < 0.833:
            r, g, b = int(255 * (normalized - 0.667) * 6), 0, 255
        else:
            r, g, b = 255, 0, int(255 * (1 - (normalized - 0.833) * 6))
        
        return f"#{r:02x}{g:02x}{b:02x}"
    
    def _calculate_schumann_resonance(self, frequency_hz: float) -> float:
        """ìŠˆë§Œ ê³µëª…ê³¼ì˜ ê´€ê³„ ê³„ì‚°"""
        # ìŠˆë§Œ ê³µëª… ê³ ì¡°íŒŒì™€ì˜ ê±°ë¦¬
        min_distance = float('inf')
        for harmonic in SCHUMANN_HARMONICS:
            # ì£¼íŒŒìˆ˜ì˜ ì •ìˆ˜ë°° í™•ì¸
            ratio = frequency_hz / harmonic
            nearest_multiple = round(ratio)
            if nearest_multiple > 0:
                distance = abs(frequency_hz - harmonic * nearest_multiple)
                min_distance = min(min_distance, distance)
                # ê±°ë¦¬ê°€ ì¶©ë¶„íˆ ì‘ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ (ìµœì í™”)
                if min_distance < 0.01:
                    break
        
        # ê±°ë¦¬ê°€ ê°€ê¹Œìš¸ìˆ˜ë¡ ê³µëª… ê°•ë„ ë†’ìŒ
        max_distance = 100.0
        resonance = max(0, 1 - (min_distance / max_distance))
        
        return resonance
    
    # =========================================================================
    # ì¢…í•© ë¶„ì„
    # =========================================================================
    
    def analyze_frequency(self, frequency_hz: float) -> Dict[str, Any]:
        """
        ì£¼íŒŒìˆ˜ì— ëŒ€í•œ ì¢…í•© ë¶„ì„
        
        Args:
            frequency_hz: ë¶„ì„í•  ì£¼íŒŒìˆ˜ (Hz)
            
        Returns:
            Dict: ì¢…í•© ë¶„ì„ ê²°ê³¼
        """
        # ê°ì • ë°œê²¬
        emotions = self.discover_emotion_from_frequency(frequency_hz)
        
        # ì—˜ë¦¬ì‹œì•„ ë§¤í•‘
        elysia_mapping = self.map_to_elysia(frequency_hz)
        
        # ë‡ŒíŒŒ ëŒ€ì—­ í™•ì¸
        brainwave = None
        for bw_type, (min_f, _, max_f) in BRAINWAVE_FREQUENCIES.items():
            if min_f <= frequency_hz <= max_f:
                brainwave = bw_type.value
                break
        
        # ì²­ê° ë²”ìœ„ ë‚´ì¸ì§€ í™•ì¸
        is_audible = AUDIBLE_FREQ_MIN <= frequency_hz <= AUDIBLE_FREQ_MAX
        
        return {
            "frequency_hz": frequency_hz,
            "associated_emotions": [(e.value, round(s, 3)) for e, s in emotions[:3]],
            "elysia_mapping": {
                "normalized": round(elysia_mapping.elysia_normalized, 4),
                "layer": elysia_mapping.elysia_layer,
                "color": elysia_mapping.elysia_color_code,
                "schumann_resonance": round(elysia_mapping.resonance_strength, 3)
            },
            "brainwave_band": brainwave,
            "is_audible": is_audible,
            "schumann_relation": self._describe_schumann_relation(frequency_hz)
        }
    
    def _describe_schumann_relation(self, frequency_hz: float) -> str:
        """ìŠˆë§Œ ê³µëª…ê³¼ì˜ ê´€ê³„ ì„¤ëª…"""
        for i, harmonic in enumerate(SCHUMANN_HARMONICS):
            ratio = frequency_hz / harmonic
            nearest = round(ratio)
            if nearest > 0 and abs(ratio - nearest) < 0.1:
                if nearest == 1:
                    return f"ìŠˆë§Œ ê³µëª… {i+1}ì°¨ ê³ ì¡°íŒŒì™€ ì¼ì¹˜ ({harmonic}Hz)"
                else:
                    return f"ìŠˆë§Œ ê³µëª… {i+1}ì°¨ ê³ ì¡°íŒŒì˜ {nearest}ë°° ({harmonic}Hz Ã— {nearest})"
        return "ìŠˆë§Œ ê³µëª…ê³¼ ì§ì ‘ì  ê´€ê³„ ì—†ìŒ"
    
    # =========================================================================
    # ìœ í‹¸ë¦¬í‹°
    # =========================================================================
    
    def get_all_emotion_frequencies(self) -> Dict[str, float]:
        """ëª¨ë“  ê°ì •ì˜ ì£¼íŒŒìˆ˜ ë°˜í™˜"""
        return {e.value: d.frequency_hz for e, d in EMOTION_FREQUENCY_MAP.items()}
    
    def get_all_sound_frequencies(self) -> Dict[str, float]:
        """ëª¨ë“  ì†Œë¦¬ì˜ ê¸°ë³¸ ì£¼íŒŒìˆ˜ ë°˜í™˜"""
        return {s.value: d.fundamental_hz for s, d in SOUND_FREQUENCY_MAP.items()}
    
    def get_stats(self) -> Dict[str, int]:
        """í†µê³„ ë°˜í™˜"""
        return self.stats.copy()
    
    def create_frequency_report(self) -> str:
        """ì£¼íŒŒìˆ˜ ë§¤í•‘ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              í˜„ì‹¤ì„¸ê³„ - ì—˜ë¦¬ì‹œì•„ íŒŒë™ì£¼íŒŒìˆ˜ ë§¤í•‘ ë¦¬í¬íŠ¸                        â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£

ğŸŒ ê¸°ë³¸ ì°¸ì¡° ì£¼íŒŒìˆ˜
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ìŠˆë§Œ ê³µëª… (ì§€êµ¬): {schumann} Hz
  ê°€ì²­ ë²”ìœ„: {audible_min} - {audible_max} Hz
  
ğŸ’— ê°ì • ì£¼íŒŒìˆ˜ ë§¤í•‘
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
""".format(
            schumann=SCHUMANN_RESONANCE_HZ,
            audible_min=AUDIBLE_FREQ_MIN,
            audible_max=AUDIBLE_FREQ_MAX
        )
        
        # ê°ì • ì£¼íŒŒìˆ˜ (ë†’ì€ ìˆœ)
        sorted_emotions = sorted(
            EMOTION_FREQUENCY_MAP.items(),
            key=lambda x: x[1].frequency_hz,
            reverse=True
        )
        
        for emotion, data in sorted_emotions:
            report += f"  {data.description_ko:30s} : {data.frequency_hz:8.1f} Hz\n"
        
        report += """
ğŸ”Š ì†Œë¦¬ ì£¼íŒŒìˆ˜ ë§¤í•‘
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
        for sound, data in SOUND_FREQUENCY_MAP.items():
            report += f"  {data.description_ko:30s} : {data.fundamental_hz:8.1f} Hz\n"
        
        report += """
ğŸ§  ë‡ŒíŒŒ ì£¼íŒŒìˆ˜ ëŒ€ì—­
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
        for bw, (min_f, center, max_f) in BRAINWAVE_FREQUENCIES.items():
            report += f"  {bw.value:15s} : {min_f:5.1f} - {max_f:5.1f} Hz (ì¤‘ì‹¬: {center}Hz)\n"
        
        report += """
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        return report


# ============================================================================
# ë°ëª¨ ë° í…ŒìŠ¤íŠ¸
# ============================================================================

def demo():
    """WaveFrequencyMapper ë°ëª¨"""
    print("=" * 80)
    print("ğŸŒŠ Wave Frequency Mapping Demo - íŒŒë™ì£¼íŒŒìˆ˜ ë§¤í•‘")
    print("=" * 80)
    
    mapper = WaveFrequencyMapper()
    
    # ë¦¬í¬íŠ¸ ì¶œë ¥
    print(mapper.create_frequency_report())
    
    # ê°ì • ì£¼íŒŒìˆ˜ ì¡°íšŒ
    print("\nğŸ“Š ê°ì • ì£¼íŒŒìˆ˜ ì¡°íšŒ:")
    print("-" * 60)
    for emotion_str in ["ì‚¬ë‘", "í‰í™”", "ë¶„ë…¸", "love", "anger"]:
        data = mapper.get_emotion_frequency(emotion_str)
        print(f"  {emotion_str:10s} â†’ {data.frequency_hz:8.1f} Hz ({data.brainwave_dominant.value})")
    
    # ì†Œë¦¬ ì£¼íŒŒìˆ˜ ì¡°íšŒ
    print("\nğŸ”Š ì†Œë¦¬ ì£¼íŒŒìˆ˜ ì¡°íšŒ:")
    print("-" * 60)
    for sound_str in ["male_voice", "ë¬¼ì†Œë¦¬", "ë…¸ë˜"]:
        data = mapper.get_sound_frequency(sound_str)
        print(f"  {sound_str:15s} â†’ {data.fundamental_hz:8.1f} Hz")
    
    # ì£¼íŒŒìˆ˜ â†’ ê°ì • ë°œê²¬
    print("\nğŸ” ì£¼íŒŒìˆ˜ì—ì„œ ê°ì • ë°œê²¬:")
    print("-" * 60)
    test_frequencies = [528.0, 432.0, 150.0, 7.83]
    for freq in test_frequencies:
        emotions = mapper.discover_emotion_from_frequency(freq)
        top_emotion = emotions[0] if emotions else (EmotionType.NEUTRAL, 0)
        print(f"  {freq:8.2f} Hz â†’ {top_emotion[0].value:15s} (ìœ ì‚¬ë„: {top_emotion[1]:.2%})")
    
    # ì¢…í•© ë¶„ì„
    print("\nğŸ“ˆ ì¢…í•© ë¶„ì„ (528 Hz - Love Frequency):")
    print("-" * 60)
    analysis = mapper.analyze_frequency(528.0)
    for key, value in analysis.items():
        print(f"  {key}: {value}")
    
    # í†µê³„
    print("\nğŸ“Š í†µê³„:")
    print("-" * 60)
    stats = mapper.get_stats()
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    print("\n" + "=" * 80)
    print("âœ… Demo completed!")
    print("=" * 80)


if __name__ == "__main__":
    demo()
