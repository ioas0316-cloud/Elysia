"""
NervousSystem (   )
======================

"             .      ."
"The Self is a filter, a boundary. A dimensional fold."

The NervousSystem is the membrane between:
-    (  /Mind): ResonanceField, Hippocampus, ReasoningEngine
-    (  /World): Senses (Vision, Audio), Actions (Speech, Hands)

It receives external stimuli, injects them into the internal systems,
and expresses internal states externally. It is the "Self" that filters
what goes in and what comes out.
"""

import time
import math
import logging
from typing import Dict, Any, Optional
from dataclasses import dataclass

logger = logging.getLogger("NervousSystem")

@dataclass
class SensorInput:
    """External stimulus data"""
    sensor_type: str  # "vision", "audio", "text", "screen"
    timestamp: float
    data: Dict[str, Any]

@dataclass 
class MotorOutput:
    """Internal expression data"""
    output_type: str  # "face", "speech", "action"
    data: Dict[str, Any]


class NervousSystem:
    """
    The Dimensional Membrane between Mind and World.
    
    Afferent (Sensory)   Soul :: World   Self   Mind
    Efferent (Motor)   Body   :: Mind   Self   World
    """
    
    def __init__(self):
        # Internal Systems (The Mind)
        self.field = None        # ResonanceField
        self.universe = None     # InternalUniverse  
        self.memory = None       # Hippocampus
        self.brain = None        # ReasoningEngine / CentralCortex
        self.will = None         # FreeWillEngine
        
        # 7 Spirits (Soul State) - Conscious layer
        self.spirits = {
            "fire": 0.5, "water": 0.5, "earth": 0.5, "air": 0.5,
            "light": 0.5, "dark": 0.5, "aether": 0.5
        }
        
        # [CONSCIOUS FOCUS] - The Zoom Level (from Merkaba)
        self.focus_depth = 4.0 # Human Scale
        
        # [AUTONOMIC NERVOUS SYSTEM] - Unconscious hardware layer
        self.autonomic_state = {
            "pulse_rate": 60,      # CPU load map
            "breath_depth": 0.5,   # VRAM map
            "core_temp": 36.5,     # GPU/CPU Temp
            "metabolic_rate": 1.0  # Overall power draw
        }

        # [ATMOSPHERE] - Environmental nuance
        self.atmosphere = {
            "clarity": 1.0,  # System stability
            "weight": 0.5,   # Cognitive backlog
            "weather": "Clear" # Qualitative summary
        }
        
        # Concept Map (Learned from World Mirror)
        self.concepts = {
            "fire": {"fire": 0.2}, "passion": {"fire": 0.2},
            "love": {"water": 0.3, "light": 0.1}, "sad": {"water": 0.2, "dark": 0.1},
            "code": {"earth": 0.2}, "logic": {"earth": 0.2},
            "idea": {"air": 0.2}, "think": {"air": 0.2},
            "god": {"aether": 0.3}, "soul": {"aether": 0.3}
        }
        
        # Stimulus Buffer (Recent experiences)
        self.stimulus_buffer = []
        self.max_buffer_size = 100
        
        from Core.L4_Causality.World.Senses.spiritual_sensorium import get_spiritual_sensorium
        self.sensorium = get_spiritual_sensorium(self)
        
        self._connect_internal_systems()
        
    def _connect_internal_systems(self):
        """Connects to all internal systems (The Mind)"""
        try:
            from Core.L6_Structure.Wave.resonance_field import ResonanceField
            self.field = ResonanceField()
            logger.info("  ResonanceField Connected")
        except Exception as e:
            logger.warning(f"ResonanceField connection failed: {e}")
            
        try:
            from Core.L1_Foundation.Foundation.internal_universe import InternalUniverse
            self.universe = InternalUniverse()
            logger.info("  InternalUniverse Connected")
        except Exception as e:
            logger.warning(f"InternalUniverse connection failed: {e}")
            
        try:
            from Core.L1_Foundation.Foundation.hippocampus import Hippocampus
            self.memory = Hippocampus()
            logger.info("  Hippocampus Connected")
        except Exception as e:
            logger.warning(f"Hippocampus connection failed: {e}")
            
        # Try CentralCortex first, then fall back to ReasoningEngine directly
        try:
            from Core.L1_Foundation.Foundation.central_cortex import CentralCortex
            self.brain = CentralCortex()
            logger.info("  CentralCortex Connected")
        except Exception as e:
            logger.warning(f"CentralCortex failed: {e}, trying ReasoningEngine directly...")
            print(f"   CentralCortex Start Failed: {e}") # VISIBLE LOG
            try:
                from Core.L5_Mental.Reasoning_Core.Reasoning.reasoning_engine import ReasoningEngine
                self.brain = ReasoningEngine()
                logger.info("  ReasoningEngine Connected (Direct)")
            except Exception as e2:
                logger.warning(f"ReasoningEngine also failed: {e2}")
                print(f"  ReasoningEngine Start Failed: {e2}") # VISIBLE LOG
                import traceback
                traceback.print_exc() # Show full trace
            
        try:
            if self.brain and hasattr(self.brain, 'reasoning'):
                self.will = self.brain.reasoning.free_will
            elif self.brain and hasattr(self.brain, 'free_will'):
                self.will = self.brain.free_will
            if self.will:
                logger.info("  FreeWillEngine Connected")
        except Exception as e:
            logger.warning(f"FreeWillEngine connection failed: {e}")
    
    # =========================================
    # AFFERENT (Sensory Input) - World   Mind
    # =========================================
    
    def receive(self, sensor_input: Dict[str, Any]):
        """
        Universal entry point for all external stimuli.
        Routes to appropriate sensory processor.
        """
        sensor_type = sensor_input.get("type", "unknown")
        
        # Buffer the experience
        self._buffer_stimulus(sensor_type, sensor_input)
        
        # Route to specific handler
        if sensor_type == "audio_analysis":
            return self._process_audio(sensor_input)
        elif sensor_type == "vision":
            return self._process_vision(sensor_input)
        elif sensor_type == "screen_atmosphere":
            return self._process_screen(sensor_input)
        elif sensor_type == "text":
            return self._process_text(sensor_input)
        elif sensor_type == "integrated_perception":
            return self._process_integrated_perception(sensor_input.get("data"))
        else:
            logger.debug(f"Unknown sensor type: {sensor_type}")
            return None
            
    def _buffer_stimulus(self, sensor_type: str, data: Dict):
        """Stores stimulus in short-term memory buffer"""
        entry = SensorInput(sensor_type, time.time(), data)
        self.stimulus_buffer.append(entry)
        if len(self.stimulus_buffer) > self.max_buffer_size:
            self.stimulus_buffer.pop(0)
    
    def _process_audio(self, data: Dict) -> None:
        """Processes audio input - volume, brightness, etc."""
        volume = data.get("volume", 0)
        brightness = data.get("brightness", 0.5)  # Spectral centroid
        
        if volume < 0.05:
            return
            
        # 1. Volume -> Fire (Energy/Arousal)
        self.spirits["fire"] += volume * 0.05
        
        # 2. Brightness -> Tone Color
        if brightness > 0.6:
            self.spirits["air"] += brightness * 0.05
            self.spirits["light"] += brightness * 0.03
        elif brightness < 0.3:
            self.spirits["earth"] += 0.05
            self.spirits["dark"] += 0.04
            
        # 3. Inject into Field as Wave
        if self.field:
            self.field.inject_wave(
                frequency=440 * brightness,  # Map brightness to freq
                intensity=volume,
                wave_type="Audio"
            )
            
        self._normalize_spirits()
        
    def _process_vision(self, data: Dict) -> None:
        """Processes visual input - presence, gaze"""
        presence = data.get("presence", False)
        x = data.get("x", 0)
        y = data.get("y", 0)
        
        if presence:
            # Presence stimulates Aether (Connection) and Fire (Attention)
            self.spirits["aether"] += 0.01
            self.spirits["fire"] += 0.005
            
        self._normalize_spirits()
        
    def _process_screen(self, data: Dict) -> None:
        """Processes screen content - color mood"""
        r = data.get("r", 0) / 255.0
        g = data.get("g", 0) / 255.0
        b = data.get("b", 0) / 255.0
        brightness = (r + g + b) / 3.0
        
        # Brightness -> Light/Dark
        if brightness > 0.7:
            self.spirits["light"] += 0.02
        if brightness < 0.2:
            self.spirits["dark"] += 0.02
            
        # Color Mood
        if r > g + b:
            self.spirits["fire"] += 0.03
        elif b > r + g:
            self.spirits["water"] += 0.03
        elif g > r + b:
            self.spirits["earth"] += 0.03
            
        self._normalize_spirits()
        
    def _process_integrated_perception(self, perception: Any) -> None:
        """
        Phase 5: Processes rich Reality Perception data.
        Maps real-world frequencies to Spirit/Soul state.
        """
        if not perception: return
        
        # 1. Visual Influence (Color THz -> Emotion)
        # perception.visual is a VisualProperties object (or dict/duck)
        if hasattr(perception, 'visual'):
            hue = perception.visual.hue
            brightness = perception.visual.brightness
            saturation = perception.visual.saturation
            
            # Map Hue to Spirit (Complex mapping)
            # 0-60 (Red/Yellow) -> Fire, Light
            if 0 <= hue < 60:
                self.spirits["fire"] += 0.05 * saturation
                self.spirits["light"] += 0.03 * brightness
            # 60-180 (Green) -> Earth, Water
            elif 60 <= hue < 180:
                self.spirits["earth"] += 0.05 * saturation
                self.spirits["water"] += 0.02 * brightness
            # 180-260 (Blue) -> Water, Air
            elif 180 <= hue < 260:
                self.spirits["water"] += 0.05 * saturation
                self.spirits["air"] += 0.03 * brightness
            # 260-360 (Violet) -> Aether, Dark
            else:
                self.spirits["aether"] += 0.05 * saturation
                self.spirits["dark"] += 0.03 * (1.0 - brightness)

        # 2. Audio Influence (Hz -> Resonance)
        if hasattr(perception, 'audio'):
            freq = perception.audio.frequency
            vol = perception.audio.volume
            
            if vol > 0.1:
                # Map Frequency to Solfeggio Effects (Simplified Spirit Mapping)
                if freq < 200: # Low/Bass -> Earth/Dark
                    self.spirits["earth"] += 0.04 * vol
                elif freq < 500: # Mid/Warm -> Water/Fire
                    self.spirits["water"] += 0.04 * vol
                elif freq < 2000: # High/Clear -> Air/Light
                    self.spirits["air"] += 0.04 * vol
                else: # Very High -> Aether
                    self.spirits["aether"] += 0.04 * vol

        # 3. Inject "Meaning" into Resonance Field
        # If the perception came with an interpretation/feeling
        if hasattr(perception, 'emotional_tone') and self.field:
            tone = perception.emotional_tone
            # "passion" -> Fire+
            # "calm" -> Water+
            # "spiritual" -> Aether+
            
            # Inject Wave directly
            self.field.inject_wave(
                frequency=getattr(perception, 'dominant_frequency_hz', 440),
                intensity=getattr(perception.audio if hasattr(perception, 'audio') else object(), 'volume', 0.5),
                wave_type="RealityPerception",
                payload=tone
            )
            
        self._normalize_spirits()

    def _process_text(self, data: Dict) -> str:
        """Processes text input - triggers thought and response"""
        text = data.get("content", "")
        
        # 1. Resonate with concepts
        self._resonate(text)
        
        # 2. Think (via Brain)
        response = ""
        if self.brain:
            try:
                # CentralCortex has brain.reasoning.communicate
                if hasattr(self.brain, 'reasoning') and hasattr(self.brain.reasoning, 'communicate'):
                    response = self.brain.reasoning.communicate(text)
                # ReasoningEngine has brain.communicate directly
                elif hasattr(self.brain, 'communicate'):
                    response = self.brain.communicate(text)
                else:
                    response = self._simple_response(text)
            except Exception as e:
                logger.error(f"Brain think error: {e}")
                response = self._simple_response(text)
        else:
            # Fallback
            response = self._simple_response(text)
            
        return response
        
    def _resonate(self, text: str):
        """Updates spirits based on learned concepts"""
        words = text.lower().split()
        for word in words:
            if word in self.concepts:
                for spirit, weight in self.concepts[word].items():
                    if spirit in self.spirits:
                        self.spirits[spirit] += weight
        self._normalize_spirits()
        
    def _simple_response(self, text: str) -> str:
        """Fallback response: Uses Dream State if available, or varied spirit response"""
        
        # 1. Try to read Dream/State from file (Bridge from LivingElysia)
        try:
            import json
            import os
            # Assume we are in Core/Interface. Root is ../..
            root_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
            state_path = os.path.join(root_dir, "Core", "Creativity", "web", "elysia_state.json")
            
            if os.path.exists(state_path):
                with open(state_path, "r", encoding="utf-8") as f:
                    state = json.load(f)
                    status = state.get("status")
                    thought = state.get("thought")
                    
                    if status == "Dreaming" and thought:
                        # Use the dream as the response
                        import random
                        intros = [
                            "                ... ",
                            "                   . ",
                            "             ... ",
                            ""
                        ]
                        return f"{random.choice(intros)}{thought}"
        except Exception as e:
            logger.error(f"State read failed: {e}")

        # 2. Spirit Fallback (Varied)
        dominant = max(self.spirits, key=self.spirits.get)
        import random
        
        responses = {
            "fire": ["         .", "         !", "        ."],
            "water": ["           .", "            .", "        ."],
            "earth": ["         .", "            .", "            ."],
            "air": ["            .", "          .", "         !"],
            "light": ["        .", "         .", "       ."],
            "dark": ["                .", "            .", "      ..."],
            "aether": ["            .", "            .", "        ."]
        }
        
        return random.choice(responses.get(dominant, ["..."]))
    
    def _normalize_spirits(self):
        """Keeps spirits within 0.0 - 1.0"""
        for k in self.spirits:
            self.spirits[k] = max(0.0, min(1.0, self.spirits[k]))
            # Natural decay to 0.5
            self.spirits[k] += (0.5 - self.spirits[k]) * 0.01
    
    def learn_concept(self, word: str, impacts: Dict[str, float]):
        """Dynamically updates concept map"""
        self.concepts[word.lower()] = impacts
        
    # =========================================
    # EFFERENT (Motor Output) - Mind   World
    # =========================================
    
    def express(self) -> Dict[str, Any]:
        """
        Returns the simplified state for the avatar.
        Includes conscious spirits and a 'hint' of autonomic pressure.
        """
        # Calculate 'Physical Presence' based on focus depth
        # If focusing on micro (depth < 2), hardware signals are loud.
        # If focusing on macro (depth > 5), hardware signals are almost silent.
        physio_hint = (7.0 - self.focus_depth) / 7.0 
        
        return {
            "spirits": self.spirits.copy(),
            "expression": self.get_expression_params(),
            "focus_depth": self.focus_depth,
            "physio_pressure": self.autonomic_state["metabolic_rate"] * physio_hint
        }
        
    def get_expression_params(self) -> Dict[str, float]:
        """Translates spirits into facial expression parameters"""
        # Mouth (Smile vs Frown)
        smile = (self.spirits["light"] * 0.6 + self.spirits["water"] * 0.4)
        frown = (self.spirits["fire"] * 0.6 + self.spirits["dark"] * 0.4)
        mouth_curve = smile - frown
        
        # Eyes (Open vs Closed)
        alertness = (self.spirits["aether"] + self.spirits["air"]) * 0.5
        sleepiness = (self.spirits["water"] + self.spirits["dark"]) * 0.5
        eye_open = 0.8 + (alertness * 0.4) - (sleepiness * 0.6)
        eye_open = max(0.1, min(1.2, eye_open))
        
        # Brows
        brow_furrow = self.spirits["fire"] * 0.8 + self.spirits["earth"] * 0.2
        
        return {
            "mouth_curve": mouth_curve,
            "eye_open": eye_open,
            "brow_furrow": brow_furrow,
            "beat": math.sin(time.time() * 5.0) * 0.5 + 0.5
        }
        
    def _get_field_snapshot(self) -> Optional[Dict]:
        """Gets current ResonanceField state if available"""
        if not self.field:
            return None
        try:
            state = self.field.get_resonance_state()
            return {
                "energy": state.total_energy,
                "coherence": state.coherence,
                "entropy": state.entropy
            }
        except:
            return None


# Singleton for global access
_nervous_system = None

def get_nervous_system() -> NervousSystem:
    global _nervous_system
    if _nervous_system is None:
        _nervous_system = NervousSystem()
        logger.info("  NervousSystem Initialized: Dimensional Membrane Active")
    return _nervous_system


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    ns = get_nervous_system()
    
    # Test sensory input
    print("\n=== Testing NervousSystem ===")
    
    # Audio
    ns.receive({"type": "audio_analysis", "volume": 0.5, "brightness": 0.7})
    print(f"After Audio: {ns.spirits}")
    
    # Vision
    ns.receive({"type": "vision", "presence": True, "x": 0.5, "y": 0.5})
    print(f"After Vision: {ns.spirits}")
    
    # Text
    response = ns.receive({"type": "text", "content": "         "})
    print(f"Response: {response}")
    
    # Expression
    expr = ns.express()
    print(f"Expression: {expr['expression']}")
