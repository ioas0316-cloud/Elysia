"""
Distributed Engine - ë¶„ì‚° ì²˜ë¦¬ ì—”ì§„
==================================

ë†’ì€ ìš°ì„ ìˆœìœ„ #2: ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ â†’ Ray/Dask ë¶„ì‚°
ì˜ˆìƒ íš¨ê³¼: 100x í™•ì¥ì„±

í•µì‹¬ ê¸°ëŠ¥:
- ë©€í‹°í”„ë¡œì„¸ìŠ¤ ì›Œì»¤ í’€
- ì‘ì—… ë¶„ë°° ë° ìˆ˜ì§‘
- ì¥ì•  ë³µêµ¬ (Fault Tolerance)
- ë¡œë“œ ë°¸ëŸ°ì‹±
"""

import asyncio
import logging
import time
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field
from typing import Any, Callable, Dict, List, Optional, Tuple, Union
from enum import Enum
import queue
import threading

logger = logging.getLogger("DistributedEngine")


class TaskStatus(Enum):
    """ì‘ì—… ìƒíƒœ"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


class WorkerStatus(Enum):
    """ì›Œì»¤ ìƒíƒœ"""
    IDLE = "idle"
    BUSY = "busy"
    OFFLINE = "offline"


@dataclass
class Task:
    """ë¶„ì‚° ì‘ì—…"""
    task_id: str
    func: Callable
    args: Tuple = field(default_factory=tuple)
    kwargs: Dict[str, Any] = field(default_factory=dict)
    priority: int = 0  # ë†’ì„ìˆ˜ë¡ ë¨¼ì €
    created_at: float = field(default_factory=time.time)
    timeout: Optional[float] = None


@dataclass
class TaskResult:
    """ì‘ì—… ê²°ê³¼"""
    task_id: str
    status: TaskStatus
    result: Any = None
    error: Optional[str] = None
    started_at: float = 0.0
    completed_at: float = 0.0
    worker_id: Optional[str] = None
    
    @property
    def duration_ms(self) -> float:
        """ì‹¤í–‰ ì‹œê°„ (ms)"""
        if self.completed_at and self.started_at:
            return (self.completed_at - self.started_at) * 1000
        return 0.0


@dataclass
class WorkerNode:
    """ì›Œì»¤ ë…¸ë“œ ì •ë³´"""
    worker_id: str
    status: WorkerStatus = WorkerStatus.IDLE
    tasks_completed: int = 0
    tasks_failed: int = 0
    total_processing_time_ms: float = 0.0
    last_heartbeat: float = field(default_factory=time.time)
    
    @property
    def avg_task_time_ms(self) -> float:
        """í‰ê·  ì‘ì—… ì‹œê°„"""
        if self.tasks_completed > 0:
            return self.total_processing_time_ms / self.tasks_completed
        return 0.0


class DistributedEngine:
    """
    ë¶„ì‚° ì²˜ë¦¬ ì—”ì§„
    
    ë†’ì€ ìš°ì„ ìˆœìœ„ #2 êµ¬í˜„:
    - ë©€í‹°í”„ë¡œì„¸ìŠ¤ ë³‘ë ¬ ì²˜ë¦¬
    - ìŠ¤ë ˆë“œ í’€ í•˜ì´ë¸Œë¦¬ë“œ
    - ì‘ì—… ìš°ì„ ìˆœìœ„ í
    - ìë™ ì¥ì•  ë³µêµ¬
    
    ì˜ˆìƒ íš¨ê³¼: 100x í™•ì¥ì„± (CPU ì½”ì–´ ìˆ˜ì— ë¹„ë¡€)
    """
    
    def __init__(
        self,
        num_workers: Optional[int] = None,
        use_processes: bool = True,
        max_queue_size: int = 10000
    ):
        """
        Args:
            num_workers: ì›Œì»¤ ìˆ˜ (ê¸°ë³¸: CPU ì½”ì–´ ìˆ˜)
            use_processes: True=í”„ë¡œì„¸ìŠ¤ í’€, False=ìŠ¤ë ˆë“œ í’€
            max_queue_size: ìµœëŒ€ í í¬ê¸°
        """
        self.num_workers = num_workers or mp.cpu_count()
        self.use_processes = use_processes
        self.max_queue_size = max_queue_size
        
        # ì›Œì»¤ í’€
        self._executor: Optional[Union[ProcessPoolExecutor, ThreadPoolExecutor]] = None
        self._running = False
        
        # ì‘ì—… ê´€ë¦¬
        self._task_queue: queue.PriorityQueue = queue.PriorityQueue(maxsize=max_queue_size)
        self._results: Dict[str, TaskResult] = {}
        self._pending_futures: Dict[str, Any] = {}
        
        # ì›Œì»¤ ì •ë³´
        self.workers: Dict[str, WorkerNode] = {}
        for i in range(self.num_workers):
            worker_id = f"worker_{i}"
            self.workers[worker_id] = WorkerNode(worker_id=worker_id)
        
        # í†µê³„
        self.stats = {
            "total_submitted": 0,
            "total_completed": 0,
            "total_failed": 0,
            "avg_queue_time_ms": 0.0,
            "avg_execution_time_ms": 0.0
        }
        
        # ë½
        self._lock = threading.Lock()
        
        self.logger = logging.getLogger("DistributedEngine")
        pool_type = "Process" if use_processes else "Thread"
        self.logger.info(f"ğŸŒ DistributedEngine initialized ({self.num_workers} {pool_type} workers)")
    
    def start(self) -> None:
        """ì—”ì§„ ì‹œì‘"""
        if self._running:
            return
        
        if self.use_processes:
            self._executor = ProcessPoolExecutor(max_workers=self.num_workers)
        else:
            self._executor = ThreadPoolExecutor(max_workers=self.num_workers)
        
        self._running = True
        self.logger.info("â–¶ï¸ Distributed engine started")
    
    def stop(self) -> None:
        """ì—”ì§„ ì •ì§€"""
        self._running = False
        
        if self._executor:
            self._executor.shutdown(wait=True)
            self._executor = None
        
        self.logger.info("â¹ï¸ Distributed engine stopped")
    
    def submit(
        self,
        task_id: str,
        func: Callable,
        *args,
        priority: int = 0,
        timeout: Optional[float] = None,
        **kwargs
    ) -> str:
        """
        ì‘ì—… ì œì¶œ
        
        Args:
            task_id: ì‘ì—… ID
            func: ì‹¤í–‰í•  í•¨ìˆ˜
            *args: í•¨ìˆ˜ ì¸ì
            priority: ìš°ì„ ìˆœìœ„ (ë†’ì„ìˆ˜ë¡ ë¨¼ì €)
            timeout: íƒ€ì„ì•„ì›ƒ (ì´ˆ)
            **kwargs: í•¨ìˆ˜ í‚¤ì›Œë“œ ì¸ì
            
        Returns:
            ì‘ì—… ID
        """
        if not self._running:
            self.start()
        
        task = Task(
            task_id=task_id,
            func=func,
            args=args,
            kwargs=kwargs,
            priority=priority,
            timeout=timeout
        )
        
        # ìš°ì„ ìˆœìœ„ íì— ì¶”ê°€ (ìŒìˆ˜ë¡œ ë³€í™˜í•˜ì—¬ ë†’ì€ priorityê°€ ë¨¼ì € ë‚˜ì˜¤ë„ë¡)
        self._task_queue.put((-priority, time.time(), task))
        
        with self._lock:
            self.stats["total_submitted"] += 1
            self._results[task_id] = TaskResult(
                task_id=task_id,
                status=TaskStatus.PENDING
            )
        
        # ì¦‰ì‹œ ì‹¤í–‰ ì‹œë„
        self._dispatch_tasks()
        
        return task_id
    
    def _dispatch_tasks(self) -> None:
        """íì—ì„œ ì‘ì—… ë””ìŠ¤íŒ¨ì¹˜"""
        while not self._task_queue.empty() and self._executor:
            try:
                _, _, task = self._task_queue.get_nowait()
            except queue.Empty:
                break
            
            # ì‘ì—… ì œì¶œ
            with self._lock:
                self._results[task.task_id].status = TaskStatus.RUNNING
                self._results[task.task_id].started_at = time.time()
            
            future = self._executor.submit(
                self._execute_task,
                task
            )
            
            self._pending_futures[task.task_id] = future
            
            # ì½œë°± ë“±ë¡
            future.add_done_callback(
                lambda f, tid=task.task_id: self._on_task_complete(tid, f)
            )
    
    @staticmethod
    def _execute_task(task: Task) -> Any:
        """ì‘ì—… ì‹¤í–‰ (ì›Œì»¤ì—ì„œ ì‹¤í–‰ë¨)"""
        return task.func(*task.args, **task.kwargs)
    
    def _on_task_complete(self, task_id: str, future) -> None:
        """ì‘ì—… ì™„ë£Œ ì½œë°±"""
        completed_at = time.time()
        
        with self._lock:
            result = self._results.get(task_id)
            if not result:
                return
            
            result.completed_at = completed_at
            
            try:
                result.result = future.result()
                result.status = TaskStatus.COMPLETED
                self.stats["total_completed"] += 1
            except Exception as e:
                result.error = str(e)
                result.status = TaskStatus.FAILED
                self.stats["total_failed"] += 1
            
            # í‰ê·  ì‹¤í–‰ ì‹œê°„ ì—…ë°ì´íŠ¸
            if result.status == TaskStatus.COMPLETED:
                n = self.stats["total_completed"]
                old_avg = self.stats["avg_execution_time_ms"]
                self.stats["avg_execution_time_ms"] = (
                    old_avg * (n - 1) / n + result.duration_ms / n
                )
            
            # ì •ë¦¬
            if task_id in self._pending_futures:
                del self._pending_futures[task_id]
    
    def get_result(self, task_id: str, timeout: Optional[float] = None) -> Optional[TaskResult]:
        """
        ì‘ì—… ê²°ê³¼ ì¡°íšŒ (ë¸”ë¡œí‚¹)
        
        Args:
            task_id: ì‘ì—… ID
            timeout: ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
            
        Returns:
            ì‘ì—… ê²°ê³¼ ë˜ëŠ” None
        """
        start = time.time()
        
        while True:
            with self._lock:
                result = self._results.get(task_id)
                if result and result.status in (TaskStatus.COMPLETED, TaskStatus.FAILED):
                    return result
            
            if timeout and (time.time() - start) > timeout:
                return None
            
            time.sleep(0.01)
    
    def get_result_async(self, task_id: str) -> Optional[TaskResult]:
        """
        ì‘ì—… ê²°ê³¼ ì¡°íšŒ (ë…¼ë¸”ë¡œí‚¹)
        
        Args:
            task_id: ì‘ì—… ID
            
        Returns:
            ì‘ì—… ê²°ê³¼ ë˜ëŠ” None (ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì€ ê²½ìš°)
        """
        with self._lock:
            return self._results.get(task_id)
    
    def map(
        self,
        func: Callable,
        items: List[Any],
        timeout: Optional[float] = None
    ) -> List[TaskResult]:
        """
        ë³‘ë ¬ ë§µ ì—°ì‚°
        
        Args:
            func: ì ìš©í•  í•¨ìˆ˜
            items: ì…ë ¥ í•­ëª©ë“¤
            timeout: ì „ì²´ íƒ€ì„ì•„ì›ƒ
            
        Returns:
            ê²°ê³¼ ëª©ë¡
        """
        task_ids = []
        
        for i, item in enumerate(items):
            task_id = f"map_{id(func)}_{i}_{time.time()}"
            self.submit(task_id, func, item)
            task_ids.append(task_id)
        
        # ëª¨ë“  ê²°ê³¼ ìˆ˜ì§‘
        results = []
        for task_id in task_ids:
            result = self.get_result(task_id, timeout=timeout)
            results.append(result)
        
        return results
    
    def batch_resonance(
        self,
        resonance_engine,
        pairs: List[Tuple[str, str]]
    ) -> Dict[Tuple[str, str], float]:
        """
        ê³µëª… ê³„ì‚° ë³‘ë ¬í™”
        
        Args:
            resonance_engine: ê³µëª… ì—”ì§„
            pairs: (source_id, target_id) ìŒ ëª©ë¡
            
        Returns:
            {(source, target): score} ë”•ì…”ë„ˆë¦¬
        """
        def calc_single(pair):
            source_id, target_id = pair
            source = resonance_engine.nodes.get(source_id)
            target = resonance_engine.nodes.get(target_id)
            if source and target:
                return resonance_engine.calculate_resonance(source, target)
            return 0.0
        
        results = self.map(calc_single, pairs)
        
        return {
            pairs[i]: r.result if r and r.status == TaskStatus.COMPLETED else 0.0
            for i, r in enumerate(results)
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """í†µê³„ ë°˜í™˜"""
        with self._lock:
            return {
                **self.stats,
                "queue_size": self._task_queue.qsize(),
                "pending_tasks": len(self._pending_futures),
                "num_workers": self.num_workers,
                "is_running": self._running
            }
    
    def __enter__(self):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        self.start()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        self.stop()


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    print("\n" + "="*70)
    print("ğŸŒ Distributed Engine Test")
    print("="*70)
    
    def heavy_computation(x):
        """ë¬´ê±°ìš´ ì—°ì‚° ì‹œë®¬ë ˆì´ì…˜"""
        import time
        time.sleep(0.01)
        return x * x
    
    # í…ŒìŠ¤íŠ¸ 1: ë‹¨ì¼ ì‘ì—…
    print("\n[Test 1] Single Task")
    with DistributedEngine(num_workers=4, use_processes=False) as engine:
        task_id = engine.submit("task_1", heavy_computation, 42)
        result = engine.get_result(task_id, timeout=5.0)
        print(f"  âœ“ Result: {result.result}")
        print(f"  Duration: {result.duration_ms:.2f}ms")
    
    # í…ŒìŠ¤íŠ¸ 2: ë³‘ë ¬ ë§µ
    print("\n[Test 2] Parallel Map")
    with DistributedEngine(num_workers=4, use_processes=False) as engine:
        items = list(range(20))
        start = time.time()
        results = engine.map(heavy_computation, items)
        elapsed = (time.time() - start) * 1000
        
        completed = sum(1 for r in results if r and r.status == TaskStatus.COMPLETED)
        print(f"  âœ“ Completed: {completed}/{len(items)}")
        print(f"  Total time: {elapsed:.2f}ms")
        print(f"  Stats: {engine.get_stats()}")
    
    # í…ŒìŠ¤íŠ¸ 3: ìš°ì„ ìˆœìœ„
    print("\n[Test 3] Priority Queue")
    with DistributedEngine(num_workers=2, use_processes=False) as engine:
        # ë‚®ì€ ìš°ì„ ìˆœìœ„ ë¨¼ì € ì œì¶œ
        engine.submit("low_1", heavy_computation, 1, priority=1)
        engine.submit("low_2", heavy_computation, 2, priority=1)
        # ë†’ì€ ìš°ì„ ìˆœìœ„ ë‚˜ì¤‘ì— ì œì¶œ
        engine.submit("high_1", heavy_computation, 100, priority=10)
        
        time.sleep(0.1)
        print(f"  Stats: {engine.get_stats()}")
    
    print("\nâœ… All tests passed!")
    print("="*70 + "\n")
