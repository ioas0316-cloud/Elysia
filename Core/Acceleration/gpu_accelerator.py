"""
GPU Accelerator - GPU ê°€ì† ì—”ì§„
==============================

ë†’ì€ ìš°ì„ ìˆœìœ„ #3: CPU only â†’ CUDA/PyTorch í†µí•©
ì˜ˆìƒ íš¨ê³¼: 50x ì—°ì‚° ì†ë„

í•µì‹¬ ê¸°ëŠ¥:
- í…ì„œ ì—°ì‚° ê°€ì†
- ë°°ì¹˜ ê³µëª… ê³„ì‚°
- ìë™ GPU/CPU í´ë°±
- ë©”ëª¨ë¦¬ ìµœì í™”
"""

import logging
import time
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple, Union
import numpy as np

logger = logging.getLogger("GPUAccelerator")

# PyTorch ì„ íƒì  ì„í¬íŠ¸
try:
    import torch
    TORCH_AVAILABLE = True
    if torch.cuda.is_available():
        GPU_AVAILABLE = True
        GPU_NAME = torch.cuda.get_device_name(0)
    else:
        GPU_AVAILABLE = False
        GPU_NAME = "N/A"
except ImportError:
    TORCH_AVAILABLE = False
    GPU_AVAILABLE = False
    GPU_NAME = "N/A"
    torch = None


@dataclass
class TensorBatch:
    """í…ì„œ ë°°ì¹˜"""
    data: Any  # numpy array ë˜ëŠ” torch tensor
    shape: Tuple[int, ...]
    dtype: str
    device: str = "cpu"
    created_at: float = field(default_factory=time.time)
    
    @property
    def size(self) -> int:
        """ì›ì†Œ ìˆ˜"""
        result = 1
        for dim in self.shape:
            result *= dim
        return result
    
    def to_numpy(self) -> np.ndarray:
        """NumPyë¡œ ë³€í™˜"""
        if TORCH_AVAILABLE and isinstance(self.data, torch.Tensor):
            return self.data.cpu().numpy()
        return self.data


@dataclass
class AcceleratedResonance:
    """ê°€ì†ëœ ê³µëª… ê²°ê³¼"""
    pairs: List[Tuple[str, str]]
    scores: np.ndarray
    computation_time_ms: float
    device_used: str
    
    def to_dict(self) -> Dict[Tuple[str, str], float]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            self.pairs[i]: float(self.scores[i])
            for i in range(len(self.pairs))
        }


class GPUAccelerator:
    """
    GPU ê°€ì† ì—”ì§„
    
    ë†’ì€ ìš°ì„ ìˆœìœ„ #3 êµ¬í˜„:
    - PyTorch í…ì„œ ì—°ì‚°
    - CUDA ê°€ì† (ê°€ëŠ¥í•œ ê²½ìš°)
    - ìë™ CPU í´ë°±
    - ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
    
    ì˜ˆìƒ íš¨ê³¼: 50x ì—°ì‚° ì†ë„ (GPU ìˆëŠ” ê²½ìš°)
    """
    
    def __init__(
        self,
        prefer_gpu: bool = True,
        batch_size: int = 256,
        dtype: str = "float32"
    ):
        """
        Args:
            prefer_gpu: GPU ì‚¬ìš© ì„ í˜¸
            batch_size: ê¸°ë³¸ ë°°ì¹˜ í¬ê¸°
            dtype: ë°ì´í„° íƒ€ì…
        """
        self.batch_size = batch_size
        self.dtype = dtype
        
        # ë””ë°”ì´ìŠ¤ ê²°ì •
        if prefer_gpu and GPU_AVAILABLE:
            self.device = "cuda"
            self.torch_device = torch.device("cuda")
        elif TORCH_AVAILABLE:
            self.device = "cpu"
            self.torch_device = torch.device("cpu")
        else:
            self.device = "numpy"
            self.torch_device = None
        
        # í†µê³„
        self.stats = {
            "total_operations": 0,
            "total_elements": 0,
            "total_time_ms": 0.0,
            "gpu_operations": 0,
            "cpu_operations": 0
        }
        
        self.logger = logging.getLogger("GPUAccelerator")
        self.logger.info(f"ğŸš€ GPUAccelerator initialized (device={self.device}, GPU={GPU_NAME})")
    
    def _to_tensor(self, data: Union[np.ndarray, List]) -> Any:
        """ë°ì´í„°ë¥¼ í…ì„œë¡œ ë³€í™˜"""
        if not TORCH_AVAILABLE:
            return np.array(data, dtype=np.float32)
        
        if isinstance(data, np.ndarray):
            tensor = torch.from_numpy(data.astype(np.float32))
        else:
            tensor = torch.tensor(data, dtype=torch.float32)
        
        return tensor.to(self.torch_device)
    
    def _to_numpy(self, tensor: Any) -> np.ndarray:
        """í…ì„œë¥¼ NumPyë¡œ ë³€í™˜"""
        if isinstance(tensor, np.ndarray):
            return tensor
        if TORCH_AVAILABLE and isinstance(tensor, torch.Tensor):
            return tensor.cpu().numpy()
        return np.array(tensor)
    
    def batch_dot_product(
        self,
        vectors_a: np.ndarray,
        vectors_b: np.ndarray
    ) -> np.ndarray:
        """
        ë°°ì¹˜ ë‚´ì  ê³„ì‚°
        
        Args:
            vectors_a: (N, D) í–‰ë ¬
            vectors_b: (N, D) í–‰ë ¬
            
        Returns:
            (N,) ë‚´ì  ê²°ê³¼
        """
        start = time.time()
        
        if TORCH_AVAILABLE:
            a = self._to_tensor(vectors_a)
            b = self._to_tensor(vectors_b)
            
            result = torch.sum(a * b, dim=1)
            result = self._to_numpy(result)
            
            if self.device == "cuda":
                self.stats["gpu_operations"] += 1
            else:
                self.stats["cpu_operations"] += 1
        else:
            result = np.sum(vectors_a * vectors_b, axis=1)
            self.stats["cpu_operations"] += 1
        
        elapsed = (time.time() - start) * 1000
        self.stats["total_operations"] += 1
        self.stats["total_elements"] += len(result)
        self.stats["total_time_ms"] += elapsed
        
        return result
    
    def batch_cosine_similarity(
        self,
        vectors_a: np.ndarray,
        vectors_b: np.ndarray,
        eps: float = 1e-8
    ) -> np.ndarray:
        """
        ë°°ì¹˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        
        Args:
            vectors_a: (N, D) í–‰ë ¬
            vectors_b: (N, D) í–‰ë ¬
            eps: 0 ë‚˜ëˆ—ì…ˆ ë°©ì§€
            
        Returns:
            (N,) ìœ ì‚¬ë„ ê²°ê³¼
        """
        start = time.time()
        
        if TORCH_AVAILABLE:
            a = self._to_tensor(vectors_a)
            b = self._to_tensor(vectors_b)
            
            # ì •ê·œí™”
            a_norm = a / (torch.norm(a, dim=1, keepdim=True) + eps)
            b_norm = b / (torch.norm(b, dim=1, keepdim=True) + eps)
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
            result = torch.sum(a_norm * b_norm, dim=1)
            result = self._to_numpy(result)
            
            if self.device == "cuda":
                self.stats["gpu_operations"] += 1
            else:
                self.stats["cpu_operations"] += 1
        else:
            # NumPy í´ë°±
            a_norm = vectors_a / (np.linalg.norm(vectors_a, axis=1, keepdims=True) + eps)
            b_norm = vectors_b / (np.linalg.norm(vectors_b, axis=1, keepdims=True) + eps)
            result = np.sum(a_norm * b_norm, axis=1)
            self.stats["cpu_operations"] += 1
        
        elapsed = (time.time() - start) * 1000
        self.stats["total_operations"] += 1
        self.stats["total_elements"] += len(result)
        self.stats["total_time_ms"] += elapsed
        
        return result
    
    def batch_resonance(
        self,
        resonance_engine,
        pairs: List[Tuple[str, str]]
    ) -> AcceleratedResonance:
        """
        ê³µëª… ê³„ì‚° ê°€ì†í™”
        
        Args:
            resonance_engine: ê³µëª… ì—”ì§„
            pairs: (source_id, target_id) ìŒ ëª©ë¡
            
        Returns:
            AcceleratedResonance ê²°ê³¼
        """
        start = time.time()
        n = len(pairs)
        
        if n == 0:
            return AcceleratedResonance(
                pairs=[],
                scores=np.array([]),
                computation_time_ms=0.0,
                device_used=self.device
            )
        
        # ë²¡í„° ì¶”ì¶œ
        # QubitStateì˜ xyz ì¢Œí‘œì™€ í™•ë¥  ë¶„í¬ ì‚¬ìš©
        vectors_a = []
        vectors_b = []
        
        for source_id, target_id in pairs:
            source = resonance_engine.nodes.get(source_id)
            target = resonance_engine.nodes.get(target_id)
            
            if source and target:
                # ìƒíƒœ ë²¡í„°: [x, y, z, Point, Line, Space, God, w]
                source_probs = source.state.probabilities()
                target_probs = target.state.probabilities()
                
                vec_a = [
                    source.state.x, source.state.y, source.state.z,
                    source_probs["Point"], source_probs["Line"],
                    source_probs["Space"], source_probs["God"],
                    source.state.w
                ]
                vec_b = [
                    target.state.x, target.state.y, target.state.z,
                    target_probs["Point"], target_probs["Line"],
                    target_probs["Space"], target_probs["God"],
                    target.state.w
                ]
            else:
                vec_a = [0.0] * 8
                vec_b = [0.0] * 8
            
            vectors_a.append(vec_a)
            vectors_b.append(vec_b)
        
        vectors_a = np.array(vectors_a, dtype=np.float32)
        vectors_b = np.array(vectors_b, dtype=np.float32)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ ê³µëª… ê·¼ì‚¬
        scores = self.batch_cosine_similarity(vectors_a, vectors_b)
        
        # ìŒìˆ˜ í´ë¨í•‘
        scores = np.clip(scores, 0.0, 1.0)
        
        elapsed = (time.time() - start) * 1000
        
        return AcceleratedResonance(
            pairs=pairs,
            scores=scores,
            computation_time_ms=elapsed,
            device_used=self.device
        )
    
    def matrix_multiply(
        self,
        a: np.ndarray,
        b: np.ndarray
    ) -> np.ndarray:
        """
        í–‰ë ¬ ê³±ì…ˆ
        
        Args:
            a: (M, K) í–‰ë ¬
            b: (K, N) í–‰ë ¬
            
        Returns:
            (M, N) ê²°ê³¼ í–‰ë ¬
        """
        start = time.time()
        
        if TORCH_AVAILABLE:
            ta = self._to_tensor(a)
            tb = self._to_tensor(b)
            
            result = torch.matmul(ta, tb)
            result = self._to_numpy(result)
            
            if self.device == "cuda":
                self.stats["gpu_operations"] += 1
            else:
                self.stats["cpu_operations"] += 1
        else:
            result = np.matmul(a, b)
            self.stats["cpu_operations"] += 1
        
        elapsed = (time.time() - start) * 1000
        self.stats["total_operations"] += 1
        self.stats["total_elements"] += result.size
        self.stats["total_time_ms"] += elapsed
        
        return result
    
    def softmax(self, x: np.ndarray, axis: int = -1) -> np.ndarray:
        """
        Softmax ì—°ì‚°
        
        Args:
            x: ì…ë ¥ ë°°ì—´
            axis: ì ìš©í•  ì¶•
            
        Returns:
            Softmax ê²°ê³¼
        """
        start = time.time()
        
        if TORCH_AVAILABLE:
            t = self._to_tensor(x)
            result = torch.softmax(t, dim=axis)
            result = self._to_numpy(result)
        else:
            # NumPy êµ¬í˜„
            exp_x = np.exp(x - np.max(x, axis=axis, keepdims=True))
            result = exp_x / np.sum(exp_x, axis=axis, keepdims=True)
        
        elapsed = (time.time() - start) * 1000
        self.stats["total_operations"] += 1
        self.stats["total_time_ms"] += elapsed
        
        return result
    
    def get_stats(self) -> Dict[str, Any]:
        """í†µê³„ ë°˜í™˜"""
        total_ops = self.stats["total_operations"]
        return {
            **self.stats,
            "device": self.device,
            "gpu_name": GPU_NAME,
            "torch_available": TORCH_AVAILABLE,
            "gpu_available": GPU_AVAILABLE,
            "avg_time_per_op_ms": (
                self.stats["total_time_ms"] / total_ops if total_ops > 0 else 0.0
            ),
            "gpu_utilization": (
                self.stats["gpu_operations"] / total_ops if total_ops > 0 else 0.0
            )
        }
    
    def benchmark(self, size: int = 1000, iterations: int = 10) -> Dict[str, float]:
        """
        ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
        
        Args:
            size: ë²¡í„° í¬ê¸°
            iterations: ë°˜ë³µ íšŸìˆ˜
            
        Returns:
            ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼
        """
        results = {}
        
        # ëœë¤ ë°ì´í„° ìƒì„±
        a = np.random.randn(size, 128).astype(np.float32)
        b = np.random.randn(size, 128).astype(np.float32)
        
        # Dot product ë²¤ì¹˜ë§ˆí¬
        times = []
        for _ in range(iterations):
            start = time.time()
            self.batch_dot_product(a, b)
            times.append((time.time() - start) * 1000)
        results["dot_product_ms"] = np.mean(times)
        
        # Cosine similarity ë²¤ì¹˜ë§ˆí¬
        times = []
        for _ in range(iterations):
            start = time.time()
            self.batch_cosine_similarity(a, b)
            times.append((time.time() - start) * 1000)
        results["cosine_similarity_ms"] = np.mean(times)
        
        # Matrix multiply ë²¤ì¹˜ë§ˆí¬
        c = np.random.randn(128, 64).astype(np.float32)
        times = []
        for _ in range(iterations):
            start = time.time()
            self.matrix_multiply(a, c)
            times.append((time.time() - start) * 1000)
        results["matmul_ms"] = np.mean(times)
        
        results["device"] = self.device
        results["size"] = size
        results["iterations"] = iterations
        
        return results


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    print("\n" + "="*70)
    print("ğŸš€ GPU Accelerator Test")
    print("="*70)
    
    accelerator = GPUAccelerator()
    
    print(f"\nDevice: {accelerator.device}")
    print(f"PyTorch: {TORCH_AVAILABLE}")
    print(f"GPU: {GPU_AVAILABLE} ({GPU_NAME})")
    
    # í…ŒìŠ¤íŠ¸ 1: ë‚´ì 
    print("\n[Test 1] Batch Dot Product")
    a = np.random.randn(100, 64).astype(np.float32)
    b = np.random.randn(100, 64).astype(np.float32)
    result = accelerator.batch_dot_product(a, b)
    print(f"  âœ“ Shape: {result.shape}")
    print(f"  Range: [{result.min():.3f}, {result.max():.3f}]")
    
    # í…ŒìŠ¤íŠ¸ 2: ì½”ì‚¬ì¸ ìœ ì‚¬ë„
    print("\n[Test 2] Batch Cosine Similarity")
    result = accelerator.batch_cosine_similarity(a, b)
    print(f"  âœ“ Shape: {result.shape}")
    print(f"  Range: [{result.min():.3f}, {result.max():.3f}]")
    
    # í…ŒìŠ¤íŠ¸ 3: í–‰ë ¬ ê³±
    print("\n[Test 3] Matrix Multiply")
    c = np.random.randn(64, 32).astype(np.float32)
    result = accelerator.matrix_multiply(a, c)
    print(f"  âœ“ Shape: {result.shape}")
    
    # í…ŒìŠ¤íŠ¸ 4: Softmax
    print("\n[Test 4] Softmax")
    x = np.random.randn(10, 5).astype(np.float32)
    result = accelerator.softmax(x)
    print(f"  âœ“ Shape: {result.shape}")
    print(f"  Sum per row: {result.sum(axis=1)}")  # Should be ~1.0
    
    # í…ŒìŠ¤íŠ¸ 5: ë²¤ì¹˜ë§ˆí¬
    print("\n[Test 5] Benchmark")
    bench = accelerator.benchmark(size=1000, iterations=5)
    print(f"  Dot product: {bench['dot_product_ms']:.3f}ms")
    print(f"  Cosine sim: {bench['cosine_similarity_ms']:.3f}ms")
    print(f"  Matmul: {bench['matmul_ms']:.3f}ms")
    
    # í†µê³„
    print("\n[Stats]")
    stats = accelerator.get_stats()
    print(f"  Total ops: {stats['total_operations']}")
    print(f"  GPU ops: {stats['gpu_operations']}")
    print(f"  Avg time: {stats['avg_time_per_op_ms']:.3f}ms")
    
    print("\nâœ… All tests passed!")
    print("="*70 + "\n")
