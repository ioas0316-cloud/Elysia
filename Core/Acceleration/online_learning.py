"""
Online Learning Pipeline - ì‹¤ì‹œê°„ í•™ìŠµ ì—”ì§„
==========================================

ë†’ì€ ìš°ì„ ìˆœìœ„ #1: ë°°ì¹˜ í•™ìŠµ â†’ ì˜¨ë¼ì¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸
ì˜ˆìƒ íš¨ê³¼: 10x ì ì‘ ì†ë„

í•µì‹¬ ê¸°ëŠ¥:
- ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ì²˜ë¦¬
- ì ì‘í˜• í•™ìŠµë¥ 
- ì ì§„ì  ëª¨ë¸ ì—…ë°ì´íŠ¸
- ë§ê° ë°©ì§€ ë©”ì»¤ë‹ˆì¦˜
"""

import asyncio
import logging
import time
from dataclasses import dataclass, field
from typing import Any, Callable, Dict, List, Optional, Tuple
from collections import deque
from enum import Enum
import numpy as np

logger = logging.getLogger("OnlineLearning")


class LearningMode(Enum):
    """í•™ìŠµ ëª¨ë“œ"""
    PASSIVE = "passive"      # ê´€ì°°ë§Œ, ì—…ë°ì´íŠ¸ ì—†ìŒ
    INCREMENTAL = "incremental"  # ì ì§„ì  ì—…ë°ì´íŠ¸
    AGGRESSIVE = "aggressive"    # ì¦‰ì‹œ ì ìš©
    REPLAY = "replay"        # ê²½í—˜ ì¬ìƒ ì‚¬ìš©


@dataclass
class LearningEvent:
    """í•™ìŠµ ì´ë²¤íŠ¸"""
    concept: str
    resonances: Dict[str, float]
    timestamp: float = field(default_factory=time.time)
    importance: float = 0.5
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    @property
    def age(self) -> float:
        """ì´ë²¤íŠ¸ ë‚˜ì´ (ì´ˆ)"""
        return time.time() - self.timestamp


@dataclass
class LearningStats:
    """í•™ìŠµ í†µê³„"""
    total_events: int = 0
    events_processed: int = 0
    adaptations_made: int = 0
    avg_adaptation_time_ms: float = 0.0
    learning_rate: float = 0.01
    buffer_utilization: float = 0.0


class AdaptiveBuffer:
    """
    ì ì‘í˜• ê²½í—˜ ë²„í¼
    
    ê¸°ëŠ¥:
    - ì¤‘ìš”ë„ ê¸°ë°˜ ìš°ì„ ìˆœìœ„ í
    - ì‹œê°„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê°ì†Œ
    - ë‹¤ì–‘ì„± ìœ ì§€ ìƒ˜í”Œë§
    """
    
    def __init__(self, max_size: int = 10000, diversity_weight: float = 0.3):
        self.max_size = max_size
        self.diversity_weight = diversity_weight
        self.buffer: deque = deque(maxlen=max_size)
        self.concept_counts: Dict[str, int] = {}
        self.logger = logging.getLogger("AdaptiveBuffer")
    
    def add(self, event: LearningEvent) -> None:
        """ì´ë²¤íŠ¸ ì¶”ê°€"""
        self.buffer.append(event)
        self.concept_counts[event.concept] = self.concept_counts.get(event.concept, 0) + 1
    
    def sample(self, batch_size: int = 32) -> List[LearningEvent]:
        """
        ë‹¤ì–‘ì„±ì„ ê³ ë ¤í•œ ìƒ˜í”Œë§
        
        Args:
            batch_size: ë°°ì¹˜ í¬ê¸°
            
        Returns:
            ìƒ˜í”Œë§ëœ ì´ë²¤íŠ¸ ëª©ë¡
        """
        if len(self.buffer) == 0:
            return []
        
        if len(self.buffer) <= batch_size:
            return list(self.buffer)
        
        # ì¤‘ìš”ë„ + ì‹œê°„ + ë‹¤ì–‘ì„± ì ìˆ˜ ê³„ì‚°
        scores = []
        for event in self.buffer:
            # ì‹œê°„ ê°€ì¤‘ì¹˜ (ìµœì‹ ì¼ìˆ˜ë¡ ë†’ìŒ)
            time_weight = np.exp(-event.age / 3600)  # 1ì‹œê°„ ë°˜ê°ê¸°
            
            # ë‹¤ì–‘ì„± ê°€ì¤‘ì¹˜ (í¬ê·€ ê°œë…ì¼ìˆ˜ë¡ ë†’ìŒ)
            concept_freq = self.concept_counts.get(event.concept, 1)
            diversity = 1.0 / np.sqrt(concept_freq)
            
            # ì¢…í•© ì ìˆ˜
            score = (
                event.importance * 0.5 +
                time_weight * 0.3 +
                diversity * self.diversity_weight
            )
            scores.append(score)
        
        # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìƒ˜í”Œë§
        scores = np.array(scores)
        probs = scores / scores.sum()
        
        indices = np.random.choice(
            len(self.buffer),
            size=min(batch_size, len(self.buffer)),
            replace=False,
            p=probs
        )
        
        return [self.buffer[i] for i in indices]
    
    def get_stats(self) -> Dict[str, Any]:
        """ë²„í¼ í†µê³„"""
        return {
            "size": len(self.buffer),
            "max_size": self.max_size,
            "utilization": len(self.buffer) / self.max_size,
            "unique_concepts": len(self.concept_counts),
            "top_concepts": sorted(
                self.concept_counts.items(),
                key=lambda x: x[1],
                reverse=True
            )[:10]
        }


class OnlineLearningPipeline:
    """
    ì˜¨ë¼ì¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸
    
    ë†’ì€ ìš°ì„ ìˆœìœ„ #1 êµ¬í˜„:
    - ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ ì²˜ë¦¬
    - ì ì‘í˜• í•™ìŠµë¥  ì¡°ì •
    - ì ì§„ì  ëª¨ë¸ ì—…ë°ì´íŠ¸
    - ê²½í—˜ ì¬ìƒ í†µí•©
    
    ì˜ˆìƒ íš¨ê³¼: 10x ì ì‘ ì†ë„
    """
    
    def __init__(
        self,
        resonance_engine=None,
        initial_learning_rate: float = 0.01,
        adaptation_threshold: float = 0.3,
        replay_frequency: int = 100,
        buffer_size: int = 10000
    ):
        """
        Args:
            resonance_engine: ê³µëª… ì—”ì§„ ì°¸ì¡°
            initial_learning_rate: ì´ˆê¸° í•™ìŠµë¥ 
            adaptation_threshold: ì ì‘ ì„ê³„ê°’
            replay_frequency: ê²½í—˜ ì¬ìƒ ë¹ˆë„ (ì´ë²¤íŠ¸ ìˆ˜)
            buffer_size: ë²„í¼ í¬ê¸°
        """
        self.resonance_engine = resonance_engine
        self.learning_rate = initial_learning_rate
        self.adaptation_threshold = adaptation_threshold
        self.replay_frequency = replay_frequency
        
        self.mode = LearningMode.INCREMENTAL
        self.buffer = AdaptiveBuffer(max_size=buffer_size)
        
        self.stats = LearningStats(learning_rate=initial_learning_rate)
        self.logger = logging.getLogger("OnlineLearningPipeline")
        
        # ë¹„ë™ê¸° í
        self._event_queue: asyncio.Queue = None
        self._running = False
        self._task = None
        
        self.logger.info(f"ğŸ“ OnlineLearningPipeline initialized (lr={initial_learning_rate})")
    
    async def start(self) -> None:
        """íŒŒì´í”„ë¼ì¸ ì‹œì‘"""
        if self._running:
            return
        
        self._event_queue = asyncio.Queue()
        self._running = True
        self._task = asyncio.create_task(self._process_loop())
        self.logger.info("â–¶ï¸ Online learning pipeline started")
    
    async def stop(self) -> None:
        """íŒŒì´í”„ë¼ì¸ ì •ì§€"""
        self._running = False
        if self._task:
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:
                pass
        self.logger.info("â¹ï¸ Online learning pipeline stopped")
    
    async def submit(self, event: LearningEvent) -> None:
        """
        í•™ìŠµ ì´ë²¤íŠ¸ ì œì¶œ
        
        Args:
            event: í•™ìŠµ ì´ë²¤íŠ¸
        """
        if self._event_queue:
            await self._event_queue.put(event)
        else:
            # ë™ê¸° ëª¨ë“œì—ì„œë„ ì²˜ë¦¬ ê°€ëŠ¥
            self._process_event_sync(event)
        
        self.stats.total_events += 1
    
    def submit_sync(self, event: LearningEvent) -> None:
        """ë™ê¸° ì´ë²¤íŠ¸ ì œì¶œ"""
        self._process_event_sync(event)
        self.stats.total_events += 1
    
    async def _process_loop(self) -> None:
        """ë¹„ë™ê¸° ì²˜ë¦¬ ë£¨í”„"""
        replay_counter = 0
        
        while self._running:
            try:
                # ì´ë²¤íŠ¸ ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒ ìˆìŒ)
                try:
                    event = await asyncio.wait_for(
                        self._event_queue.get(),
                        timeout=1.0
                    )
                except asyncio.TimeoutError:
                    continue
                
                # ì´ë²¤íŠ¸ ì²˜ë¦¬
                start_time = time.time()
                await self._process_event(event)
                elapsed_ms = (time.time() - start_time) * 1000
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                self.stats.events_processed += 1
                self.stats.avg_adaptation_time_ms = (
                    self.stats.avg_adaptation_time_ms * 0.9 +
                    elapsed_ms * 0.1
                )
                
                # ê²½í—˜ ì¬ìƒ
                replay_counter += 1
                if replay_counter >= self.replay_frequency:
                    await self._experience_replay()
                    replay_counter = 0
                
            except Exception as e:
                self.logger.error(f"Error in processing loop: {e}")
    
    async def _process_event(self, event: LearningEvent) -> None:
        """
        ì´ë²¤íŠ¸ ë¹„ë™ê¸° ì²˜ë¦¬
        
        Args:
            event: í•™ìŠµ ì´ë²¤íŠ¸
        """
        # ë²„í¼ì— ì¶”ê°€
        self.buffer.add(event)
        
        # ëª¨ë“œì— ë”°ë¥¸ ì²˜ë¦¬
        if self.mode == LearningMode.PASSIVE:
            return
        
        if self.mode == LearningMode.AGGRESSIVE or event.importance > self.adaptation_threshold:
            await self._adapt_model(event)
        elif self.mode == LearningMode.INCREMENTAL:
            # ì¤‘ìš”ë„ì— ë”°ë¥¸ í™•ë¥ ì  ì ì‘
            if np.random.random() < event.importance:
                await self._adapt_model(event)
    
    def _process_event_sync(self, event: LearningEvent) -> None:
        """ë™ê¸° ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        self.buffer.add(event)
        
        if self.mode != LearningMode.PASSIVE:
            if event.importance > self.adaptation_threshold:
                self._adapt_model_sync(event)
            self.stats.events_processed += 1
    
    async def _adapt_model(self, event: LearningEvent) -> None:
        """
        ëª¨ë¸ ì ì‘ (ë¹„ë™ê¸°)
        
        í•µì‹¬ ë¡œì§: ê³µëª… ê°€ì¤‘ì¹˜ ì ì§„ì  ì—…ë°ì´íŠ¸
        """
        if not self.resonance_engine:
            return
        
        # ìŠ¤ë ˆë“œ í’€ì—ì„œ ì‹¤í–‰
        await asyncio.to_thread(self._adapt_model_sync, event)
    
    def _adapt_model_sync(self, event: LearningEvent) -> None:
        """
        ëª¨ë¸ ì ì‘ (ë™ê¸°)
        
        í•µì‹¬ ë¡œì§:
        1. ê°œë…ì´ ì—†ìœ¼ë©´ ì¶”ê°€
        2. ê³µëª… ì ìˆ˜ë¡œ psionic link ê°•í™”
        3. í•™ìŠµë¥  ì ì‘
        """
        if not self.resonance_engine:
            return
        
        try:
            # ê°œë… ì¶”ê°€
            if hasattr(self.resonance_engine, 'add_node'):
                if event.concept not in getattr(self.resonance_engine, 'nodes', {}):
                    self.resonance_engine.add_node(event.concept)
            
            # ê³µëª… ê´€ê³„ ê°•í™”
            if hasattr(self.resonance_engine, 'entangle'):
                for related, score in event.resonances.items():
                    if score > 0.5:  # ê°•í•œ ê³µëª…ë§Œ
                        self.resonance_engine.entangle(event.concept, related)
            
            # ì ì‘ í†µê³„ ì—…ë°ì´íŠ¸
            self.stats.adaptations_made += 1
            
            # ì ì‘í˜• í•™ìŠµë¥  ì¡°ì •
            self._adjust_learning_rate(event)
            
        except Exception as e:
            self.logger.error(f"Adaptation error: {e}")
    
    def _adjust_learning_rate(self, event: LearningEvent) -> None:
        """
        ì ì‘í˜• í•™ìŠµë¥  ì¡°ì •
        
        - ì„±ê³µì  ì ì‘ ì‹œ ì•½ê°„ ì¦ê°€
        - ì˜¤ë¥˜ ë°œìƒ ì‹œ ê°ì†Œ
        - ë²”ìœ„ ì œí•œ (0.001 ~ 0.1)
        """
        if event.importance > 0.7:
            # ì¤‘ìš” ì´ë²¤íŠ¸ëŠ” í•™ìŠµë¥  ì‚´ì§ ì¦ê°€
            self.learning_rate = min(0.1, self.learning_rate * 1.01)
        else:
            # ì¼ë°˜ ì´ë²¤íŠ¸ëŠ” ì‚´ì§ ê°ì†Œ
            self.learning_rate = max(0.001, self.learning_rate * 0.999)
        
        self.stats.learning_rate = self.learning_rate
    
    async def _experience_replay(self) -> None:
        """
        ê²½í—˜ ì¬ìƒ
        
        ë²„í¼ì—ì„œ ìƒ˜í”Œë§í•˜ì—¬ ì¬í•™ìŠµ
        ë§ê° ë°©ì§€ ë° ì¼ë°˜í™” í–¥ìƒ
        """
        batch = self.buffer.sample(batch_size=16)
        
        for event in batch:
            await self._adapt_model(event)
        
        self.logger.debug(f"ğŸ”„ Experience replay: {len(batch)} events")
    
    def set_mode(self, mode: LearningMode) -> None:
        """í•™ìŠµ ëª¨ë“œ ì„¤ì •"""
        self.mode = mode
        self.logger.info(f"ğŸ¯ Learning mode set to: {mode.value}")
    
    def get_stats(self) -> LearningStats:
        """í†µê³„ ë°˜í™˜"""
        self.stats.buffer_utilization = len(self.buffer.buffer) / self.buffer.max_size
        return self.stats
    
    def get_buffer_stats(self) -> Dict[str, Any]:
        """ë²„í¼ í†µê³„"""
        return self.buffer.get_stats()


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    import asyncio
    
    async def test_pipeline():
        print("\n" + "="*70)
        print("ğŸ“ Online Learning Pipeline Test")
        print("="*70)
        
        pipeline = OnlineLearningPipeline()
        
        # ë™ê¸° í…ŒìŠ¤íŠ¸
        print("\n[Test 1] Sync Event Processing")
        event1 = LearningEvent(
            concept="consciousness",
            resonances={"awareness": 0.8, "perception": 0.6},
            importance=0.7
        )
        pipeline.submit_sync(event1)
        print(f"  âœ“ Event processed: {event1.concept}")
        print(f"  Stats: {pipeline.get_stats()}")
        
        # ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸
        print("\n[Test 2] Async Event Processing")
        await pipeline.start()
        
        for i in range(10):
            event = LearningEvent(
                concept=f"concept_{i}",
                resonances={f"related_{i}": 0.5 + i * 0.05},
                importance=0.3 + i * 0.07
            )
            await pipeline.submit(event)
        
        await asyncio.sleep(0.5)
        await pipeline.stop()
        
        print(f"  âœ“ Processed {pipeline.stats.events_processed} events")
        print(f"  Avg time: {pipeline.stats.avg_adaptation_time_ms:.2f}ms")
        
        print("\n[Test 3] Buffer Stats")
        buffer_stats = pipeline.get_buffer_stats()
        print(f"  Buffer size: {buffer_stats['size']}")
        print(f"  Unique concepts: {buffer_stats['unique_concepts']}")
        
        print("\nâœ… All tests passed!")
        print("="*70 + "\n")
    
    asyncio.run(test_pipeline())
