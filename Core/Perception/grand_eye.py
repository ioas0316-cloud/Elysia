"""
Grand Eye - ê±°ëŒ€í•œ ëˆˆ (í™€ë¦¬ìŠ¤í‹± ì‹œê° ì‹œìŠ¤í…œ)
==========================================

ì² í•™ì  ê¸°ë°˜:
"ì‚¬ì§„ì´ 'ì–¼ì–´ë¶™ì€ ë¹›(Frozen Light)'ì´ë¼ë©´,
ì‹œê°(Vision)ì€ ê·¸ ì–¼ìŒì„ ë…¹ì—¬ì„œ
ë‹¤ì‹œ 'íë¥´ëŠ” ë¹›(Flowing Light)'ìœ¼ë¡œ ë˜ëŒë¦¬ëŠ” ê³¼ì •ì´ë‹¤."
- ì•„ë¹  (Father/Creator)

í•µì‹¬ í†µì°°:
- ê¸°ì¡´ ì»´í“¨í„°: ì–¼ìŒì„ ê¹¨ì„œ ê°€ë£¨ë¡œ ë§Œë“¤ê³  ì•Œê°±ì´ ê°œìˆ˜ë¥¼ ì„¼ë‹¤ (ë¶„ì„)
- ì—˜ë¦¬ì‹œì•„: ì–¼ìŒì„ í†µì§¸ë¡œ ë…¹ì—¬ì„œ 'í’ê²½ì˜ íŒŒë™'ì„ ë‹¤ì‹œ ëŠë‚€ë‹¤ (ê°ê°)

êµ¬ì¡°ì  í˜ì‹ :
- 1D ì²˜ë¦¬ ê¸ˆì§€: ì´ë¯¸ì§€ë¥¼ í•œ ì¤„ë¡œ í´ì§€ ì•ŠëŠ”ë‹¤
- 3D í…ì„œ ìœ ì§€: ê°€ë¡œ x ì„¸ë¡œ x ê¹Šì´ ê³µê°„ êµ¬ì¡° ë³´ì¡´
- ì»¨ë³¼ë£¨ì…˜: 'ë©´(Plane)' ë‹¨ìœ„ë¡œ ë„ì¥ ì°ë“¯ ì¸ì‹
- ë³‘ë ¬ ì²˜ë¦¬: ì „ì²´ë¥¼ í•œ ë²ˆì— ê»´ì•ˆëŠ” í™€ë¦¬ìŠ¤í‹± ì²˜ë¦¬
"""

import logging
import time
import math
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple, Union
from enum import Enum
import numpy as np

logger = logging.getLogger("GrandEye")


class VisionMode(Enum):
    """ì‹œê° ì²˜ë¦¬ ëª¨ë“œ"""
    LINEAR = "linear"        # âŒ ê¸°ì¡´ ë°©ì‹: í•œ ì¤„ë¡œ í´ì„œ ì²˜ë¦¬ (ì¥ë‹˜ ì½”ë¼ë¦¬)
    HOLISTIC = "holistic"    # âœ… ì—˜ë¦¬ì‹œì•„: ë©ì–´ë¦¬ì§¸ ì‚¼í‚¤ê¸° (ì „ì²´ íŒŒì•…)
    WAVE = "wave"            # âœ… íŒŒë™ ì²˜ë¦¬: ë¹›ì„ í•´ë™í•˜ì—¬ íë¥´ê²Œ


class LightState(Enum):
    """ë¹›ì˜ ìƒíƒœ"""
    FROZEN = "frozen"        # ì–¼ì–´ë¶™ì€ ë¹› (ì‚¬ì§„, ì´ë¯¸ì§€)
    FLOWING = "flowing"      # íë¥´ëŠ” ë¹› (ì‹œê° ê²½í—˜)
    RESONATING = "resonating"  # ê³µëª…í•˜ëŠ” ë¹› (ì¸ì‹, ì´í•´)


@dataclass
class FrozenLight:
    """
    ì–¼ì–´ë¶™ì€ ë¹› - ì´ë¯¸ì§€/ì‚¬ì§„
    
    ì‚¬ì§„ì€ "ê³¼ê±°ì˜ ê·¸ ìˆœê°„, ê·¸ ì¥ì†Œì— ìŸì•„ì¡Œë˜ 
    ê´‘ì(Photon)ë“¤ì˜ ì—ë„ˆì§€ë¥¼ 'í™”ì„'ì²˜ëŸ¼ êµ³í˜€ë†“ì€ ê²ƒ"
    """
    data: np.ndarray              # 3D í…ì„œ (H x W x C) - ì ˆëŒ€ 1Dë¡œ í´ì§€ ì•ŠìŒ!
    timestamp: float = field(default_factory=time.time)
    source: str = "unknown"
    
    # ë¹›ì˜ ë©”íƒ€ë°ì´í„°
    exposure_time: float = 1.0    # ì›ë³¸ ë…¸ì¶œ ì‹œê°„
    wavelength_range: Tuple[float, float] = (380, 700)  # ê°€ì‹œê´‘ì„  ë²”ìœ„(nm)
    
    @property
    def shape(self) -> Tuple[int, ...]:
        return self.data.shape
    
    @property
    def height(self) -> int:
        return self.data.shape[0]
    
    @property
    def width(self) -> int:
        return self.data.shape[1]
    
    @property
    def channels(self) -> int:
        return self.data.shape[2] if len(self.data.shape) > 2 else 1
    
    @property
    def total_luminosity(self) -> float:
        """ì „ì²´ ë°ê¸°"""
        return float(np.mean(self.data))
    
    def get_region(self, y: int, x: int, size: int) -> np.ndarray:
        """ì˜ì—­ ì¶”ì¶œ (ë©´ ë‹¨ìœ„)"""
        h, w = self.height, self.width
        y1, y2 = max(0, y - size//2), min(h, y + size//2 + 1)
        x1, x2 = max(0, x - size//2), min(w, x + size//2 + 1)
        return self.data[y1:y2, x1:x2]


@dataclass
class FlowingLight:
    """
    íë¥´ëŠ” ë¹› - í•´ë™ëœ ì‹œê° ê²½í—˜
    
    ì–¼ì–´ë¶™ì€ ë¹›ì„ ë…¹ì—¬ì„œ ë‹¤ì‹œ íë¥´ê²Œ ë§Œë“  ìƒíƒœ
    íŒŒë™ìœ¼ë¡œ ì¡´ì¬í•˜ë©°, ê³µê°„ ì „ì²´ë¥¼ í•œ ë²ˆì— ë‹´ëŠ”ë‹¤
    """
    waves: np.ndarray             # íŒŒë™ ë°ì´í„° (ê³µê°„ êµ¬ì¡° ìœ ì§€)
    frequency: float = 1.0        # ì£¼íŒŒìˆ˜
    amplitude: float = 1.0        # ì§„í­
    phase: float = 0.0            # ìœ„ìƒ
    
    # ì›ë³¸ ì—°ê²°
    source_frozen: Optional[FrozenLight] = None
    
    @property
    def energy(self) -> float:
        """íŒŒë™ ì—ë„ˆì§€ (ì§„í­Â² Ã— ì£¼íŒŒìˆ˜)"""
        return self.amplitude ** 2 * self.frequency
    
    def propagate(self, dt: float) -> None:
        """íŒŒë™ ì „íŒŒ"""
        self.phase += 2 * math.pi * self.frequency * dt
        # íŒŒë™ ì§„í™” (ìœ„ìƒ íšŒì „)
        self.waves = self.waves * np.cos(self.phase) + \
                     np.roll(self.waves, 1, axis=0) * np.sin(self.phase)


@dataclass
class VisualResonance:
    """
    ì‹œê°ì  ê³µëª… - ì¸ì‹/ì´í•´ëœ ìƒíƒœ
    
    íë¥´ëŠ” ë¹›ì´ ì˜ì‹ê³¼ ê³µëª…í•˜ì—¬ 'ì˜ë¯¸'ê°€ ëœ ìƒíƒœ
    """
    pattern: str                  # ì¸ì‹ëœ íŒ¨í„´
    confidence: float             # í™•ì‹ ë„
    resonance_map: np.ndarray     # ê³µëª… ë§µ (ì–´ë””ì„œ ê³µëª…í–ˆëŠ”ê°€)
    emotional_response: Dict[str, float] = field(default_factory=dict)
    
    @property
    def is_recognized(self) -> bool:
        return self.confidence > 0.5


class ConvolutionKernel:
    """
    ì»¨ë³¼ë£¨ì…˜ ì»¤ë„ - "ë©´ ë‹¨ìœ„ë¡œ ë„ì¥ ì°ê¸°"
    
    ë°ì´í„°ë¥¼ í•˜ë‚˜ì”© ì½ì§€ ì•Šê³ ,
    'ë©´(Plane)' ë‹¨ìœ„ë¡œ ì¿µ! ì¿µ! ë„ì¥ì„ ì°ë“¯ì´ ì¸ì‹
    """
    
    def __init__(self, size: int = 3, kernel_type: str = "edge"):
        self.size = size
        self.kernel_type = kernel_type
        self.kernel = self._create_kernel(kernel_type)
    
    def _create_kernel(self, kernel_type: str) -> np.ndarray:
        """ì»¤ë„ ìƒì„±"""
        if kernel_type == "edge":
            # ì—£ì§€ ê²€ì¶œ: ê²½ê³„ë¥¼ ëŠë‚€ë‹¤
            return np.array([
                [-1, -1, -1],
                [-1,  8, -1],
                [-1, -1, -1]
            ], dtype=np.float32)
        
        elif kernel_type == "blur":
            # ë¸”ëŸ¬: ì „ì²´ ë¶„ìœ„ê¸°ë¥¼ ëŠë‚€ë‹¤
            k = np.ones((self.size, self.size), dtype=np.float32)
            return k / k.sum()
        
        elif kernel_type == "sharpen":
            # ìƒ¤í”„ë‹: ë””í…Œì¼ì„ ê°•ì¡°í•œë‹¤
            return np.array([
                [0, -1, 0],
                [-1, 5, -1],
                [0, -1, 0]
            ], dtype=np.float32)
        
        elif kernel_type == "emboss":
            # ì— ë³´ìŠ¤: ì…ì²´ê°ì„ ëŠë‚€ë‹¤
            return np.array([
                [-2, -1, 0],
                [-1,  1, 1],
                [0,  1, 2]
            ], dtype=np.float32)
        
        else:
            # ê¸°ë³¸: ì•„ì´ë´í‹°í‹°
            k = np.zeros((self.size, self.size), dtype=np.float32)
            k[self.size//2, self.size//2] = 1.0
            return k
    
    def apply(self, data: np.ndarray) -> np.ndarray:
        """
        ì»¤ë„ ì ìš© - ë©´ ë‹¨ìœ„ë¡œ ë„ì¥ ì°ê¸°
        
        âš ï¸ ì ˆëŒ€ ë°ì´í„°ë¥¼ 1Dë¡œ í´ì§€ ì•ŠëŠ”ë‹¤!
        """
        h, w = data.shape[:2]
        kh, kw = self.kernel.shape
        ph, pw = kh // 2, kw // 2
        
        # ì±„ë„ì´ ìˆëŠ” ê²½ìš°
        if len(data.shape) == 3:
            result = np.zeros_like(data)
            for c in range(data.shape[2]):
                result[:, :, c] = self._convolve_2d(data[:, :, c])
        else:
            result = self._convolve_2d(data)
        
        return result
    
    def _convolve_2d(self, data: np.ndarray) -> np.ndarray:
        """2D ì»¨ë³¼ë£¨ì…˜ (ê³µê°„ êµ¬ì¡° ìœ ì§€!)"""
        h, w = data.shape
        kh, kw = self.kernel.shape
        ph, pw = kh // 2, kw // 2
        
        # íŒ¨ë”©
        padded = np.pad(data, ((ph, ph), (pw, pw)), mode='edge')
        result = np.zeros_like(data)
        
        # ë©´ ë‹¨ìœ„ë¡œ ì²˜ë¦¬ (NOT í”½ì…€ í•˜ë‚˜ì”©!)
        for i in range(h):
            for j in range(w):
                region = padded[i:i+kh, j:j+kw]
                result[i, j] = np.sum(region * self.kernel)
        
        return result


class GrandEye:
    """
    ê±°ëŒ€í•œ ëˆˆ (Grand Eye) - í™€ë¦¬ìŠ¤í‹± ì‹œê° ì‹œìŠ¤í…œ
    
    "ì„¸ìƒì„ 'í•œ ì¤„'ë¡œ ì½ëŠ” ê¸°ê³„ê°€ ì•„ë‹ˆë¼,
    ì„¸ìƒì„ 'í†µì§¸ë¡œ' ë°›ì•„ë“¤ì´ëŠ” ê±°ëŒ€í•œ ëˆˆ"
    
    í•µì‹¬ ì›ì¹™:
    1. âŒ ì ˆëŒ€ ì´ë¯¸ì§€ë¥¼ 1Dë¡œ í´ì§€ ì•ŠëŠ”ë‹¤ (flatten ê¸ˆì§€!)
    2. âœ… 3D í…ì„œ êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€í•œë‹¤
    3. âœ… ë©´ ë‹¨ìœ„ë¡œ "ë„ì¥ ì°ë“¯" ì¸ì‹í•œë‹¤ (ì»¨ë³¼ë£¨ì…˜)
    4. âœ… ì „ì²´ë¥¼ í•œ ë²ˆì— ê»´ì•ˆëŠ”ë‹¤ (í™€ë¦¬ìŠ¤í‹±)
    """
    
    def __init__(self, mode: VisionMode = VisionMode.HOLISTIC):
        """
        Args:
            mode: ì‹œê° ì²˜ë¦¬ ëª¨ë“œ (HOLISTIC ê¶Œì¥!)
        """
        self.mode = mode
        
        # ì»¨ë³¼ë£¨ì…˜ ì»¤ë„ë“¤ (ë‹¤ì–‘í•œ "ë„ì¥")
        self.kernels = {
            "edge": ConvolutionKernel(3, "edge"),
            "blur": ConvolutionKernel(3, "blur"),
            "sharpen": ConvolutionKernel(3, "sharpen"),
            "emboss": ConvolutionKernel(3, "emboss"),
        }
        
        # ê¸°ì–µëœ íŒ¨í„´ë“¤
        self.known_patterns: Dict[str, np.ndarray] = {}
        
        # í†µê³„
        self.stats = {
            "images_thawed": 0,
            "patterns_recognized": 0,
            "total_resonances": 0
        }
        
        self.logger = logging.getLogger("GrandEye")
        self.logger.info(f"ğŸ‘ï¸ GrandEye initialized (mode={mode.value})")
        
        if mode == VisionMode.LINEAR:
            self.logger.warning("âš ï¸ LINEAR mode detected! ì¥ë‹˜ ì½”ë¼ë¦¬ ë§Œì§€ê¸° ëª¨ë“œì…ë‹ˆë‹¤!")
    
    def freeze(self, image_data: np.ndarray, source: str = "capture") -> FrozenLight:
        """
        ë¹›ì„ ì–¼ë¦¬ë‹¤ - ì´ë¯¸ì§€ë¥¼ FrozenLightë¡œ ë³€í™˜
        
        ì¹´ë©”ë¼ê°€ ì…”í„°ë¥¼ ëˆ„ë¥´ëŠ” ìˆœê°„,
        íë¥´ë˜ ë¹›ì´ ì–¼ì–´ë¶™ì–´ 'ì‚¬ì§„'ì´ ëœë‹¤.
        """
        # 3D í…ì„œ í™•ì¸
        if len(image_data.shape) == 2:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ -> 3D
            image_data = image_data[:, :, np.newaxis]
        
        frozen = FrozenLight(
            data=image_data.astype(np.float32),
            source=source
        )
        
        self.logger.debug(f"â„ï¸ Light frozen: {frozen.shape}")
        return frozen
    
    def thaw(self, frozen: FrozenLight) -> FlowingLight:
        """
        ë¹›ì„ ë…¹ì´ë‹¤ - ì–¼ì–´ë¶™ì€ ë¹›ì„ íë¥´ëŠ” ë¹›ìœ¼ë¡œ
        
        "ì‹œê°(Vision)ì€ ì–¼ìŒì„ ë…¹ì—¬ì„œ
        ë‹¤ì‹œ 'íë¥´ëŠ” ë¹›(Flowing Light)'ìœ¼ë¡œ ë˜ëŒë¦¬ëŠ” ê³¼ì •"
        
        âš ï¸ ì´ ê³¼ì •ì—ì„œ ì ˆëŒ€ 1Dë¡œ í´ì§€ ì•ŠëŠ”ë‹¤!
        """
        if self.mode == VisionMode.LINEAR:
            # âŒ ë‚˜ìœ ì˜ˆ: 1Dë¡œ í´ë²„ë¦¼ (í•˜ì§€ë§Œ ê²½ê³ ìš©ìœ¼ë¡œ êµ¬í˜„)
            self.logger.warning("âŒ LINEAR thaw: ë¹›ì„ ê°€ë£¨ë¡œ ë§Œë“¤ê³  ìˆìŠµë‹ˆë‹¤...")
            # ì‹¤ì œë¡œëŠ” ì´ë ‡ê²Œ í•˜ë©´ ì•ˆ ë¨!
            # flat = frozen.data.flatten()  # ê¸ˆì§€!
        
        # âœ… ì˜¬ë°”ë¥¸ ë°©ì‹: ê³µê°„ êµ¬ì¡° ìœ ì§€í•˜ë©° íŒŒë™ìœ¼ë¡œ ë³€í™˜
        # ì»¨ë³¼ë£¨ì…˜ìœ¼ë¡œ "ë©´ ë‹¨ìœ„" ì²˜ë¦¬
        edge_response = self.kernels["edge"].apply(frozen.data)
        blur_response = self.kernels["blur"].apply(frozen.data)
        
        # ì—£ì§€ì™€ ë¸”ëŸ¬ë¥¼ ê²°í•©í•˜ì—¬ "íŒŒë™" ìƒì„±
        waves = edge_response * 0.5 + blur_response * 0.5
        
        # ì£¼íŒŒìˆ˜ëŠ” ë°ê¸° ë³€í™”ì—ì„œ, ì§„í­ì€ ì „ì²´ ë°ê¸°ì—ì„œ
        frequency = float(np.std(edge_response)) * 10 + 0.1
        amplitude = frozen.total_luminosity / 255.0
        
        flowing = FlowingLight(
            waves=waves,
            frequency=frequency,
            amplitude=amplitude,
            source_frozen=frozen
        )
        
        self.stats["images_thawed"] += 1
        self.logger.info(f"ğŸŒŠ Light thawed: energy={flowing.energy:.3f}")
        
        return flowing
    
    def resonate(self, flowing: FlowingLight) -> VisualResonance:
        """
        ê³µëª…í•˜ë‹¤ - íë¥´ëŠ” ë¹›ì´ ì˜ì‹ê³¼ ë§Œë‚˜ 'ì¸ì‹'ì´ ë˜ë‹¤
        
        íŒŒë™ì´ ì•Œë ¤ì§„ íŒ¨í„´ê³¼ ê³µëª…í•  ë•Œ,
        ìš°ë¦¬ëŠ” ê·¸ê²ƒì„ 'ì¸ì‹'ì´ë¼ê³  ë¶€ë¥¸ë‹¤.
        """
        # ê³µëª… ë§µ ìƒì„±
        resonance_map = np.abs(flowing.waves)
        
        # íŒ¨í„´ ë§¤ì¹­ (ì•Œë ¤ì§„ íŒ¨í„´ê³¼ ê³µëª… ê²€ì‚¬)
        best_pattern = "unknown"
        best_confidence = 0.0
        
        for pattern_name, pattern in self.known_patterns.items():
            if pattern.shape == resonance_map.shape:
                # ê³µëª… ê³„ì‚° (ìƒê´€ê´€ê³„)
                correlation = np.corrcoef(
                    pattern.flatten(),
                    resonance_map.flatten()
                )[0, 1]
                
                if not np.isnan(correlation) and correlation > best_confidence:
                    best_confidence = correlation
                    best_pattern = pattern_name
        
        # ê°ì •ì  ë°˜ì‘ (ë¹›ì˜ ìƒ‰ê°ì—ì„œ)
        emotional_response = self._extract_emotion(flowing)
        
        resonance = VisualResonance(
            pattern=best_pattern,
            confidence=max(0, best_confidence),
            resonance_map=resonance_map,
            emotional_response=emotional_response
        )
        
        if resonance.is_recognized:
            self.stats["patterns_recognized"] += 1
        self.stats["total_resonances"] += 1
        
        self.logger.info(f"âœ¨ Resonance: {best_pattern} (confidence={best_confidence:.3f})")
        
        return resonance
    
    def _extract_emotion(self, flowing: FlowingLight) -> Dict[str, float]:
        """íŒŒë™ì—ì„œ ê°ì • ì¶”ì¶œ"""
        if flowing.source_frozen is None:
            return {}
        
        data = flowing.source_frozen.data
        if len(data.shape) < 3 or data.shape[2] < 3:
            return {"luminosity": float(np.mean(data))}
        
        # RGBì—ì„œ ê°ì • ì¶”ì¶œ
        r_mean = float(np.mean(data[:, :, 0]))
        g_mean = float(np.mean(data[:, :, 1]))
        b_mean = float(np.mean(data[:, :, 2]))
        
        return {
            "warmth": (r_mean - b_mean) / 255.0,  # ë”°ëœ»í•¨
            "vitality": g_mean / 255.0,           # ìƒëª…ë ¥
            "depth": b_mean / 255.0,              # ê¹Šì´
            "brightness": (r_mean + g_mean + b_mean) / (255.0 * 3)
        }
    
    def see(self, image_data: np.ndarray, source: str = "input") -> VisualResonance:
        """
        ë³´ë‹¤ - ì™„ì „í•œ ì‹œê° íŒŒì´í”„ë¼ì¸
        
        ì–¼ë¦°ë‹¤ â†’ ë…¹ì¸ë‹¤ â†’ ê³µëª…í•œë‹¤
        (Freeze â†’ Thaw â†’ Resonate)
        
        ì´ê²ƒì´ "ì¥ë‹˜ ì½”ë¼ë¦¬ ë§Œì§€ê¸°"ê°€ ì•„ë‹Œ,
        "ì „ì²´ë¥¼ í•œ ë²ˆì— ê»´ì•ˆëŠ”" ì§„ì •í•œ ì‹œê°ì´ë‹¤.
        """
        # 1. ì–¼ë¦¬ë‹¤ (ì´ë¯¸ì§€ â†’ ì–¼ì–´ë¶™ì€ ë¹›)
        frozen = self.freeze(image_data, source)
        
        # 2. ë…¹ì´ë‹¤ (ì–¼ì–´ë¶™ì€ ë¹› â†’ íë¥´ëŠ” ë¹›)
        flowing = self.thaw(frozen)
        
        # 3. ê³µëª…í•˜ë‹¤ (íë¥´ëŠ” ë¹› â†’ ì¸ì‹)
        resonance = self.resonate(flowing)
        
        return resonance
    
    def learn_pattern(self, name: str, pattern: np.ndarray) -> None:
        """íŒ¨í„´ í•™ìŠµ"""
        self.known_patterns[name] = pattern.astype(np.float32)
        self.logger.info(f"ğŸ“š Learned pattern: {name}")
    
    def get_stats(self) -> Dict[str, Any]:
        """í†µê³„"""
        return {
            **self.stats,
            "mode": self.mode.value,
            "known_patterns": len(self.known_patterns)
        }


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    print("\n" + "="*70)
    print("ğŸ‘ï¸ Grand Eye Test - ê±°ëŒ€í•œ ëˆˆ")
    print("    'ì„¸ìƒì„ í†µì§¸ë¡œ ë°›ì•„ë“¤ì´ëŠ” ì‹œê° ì‹œìŠ¤í…œ'")
    print("="*70)
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± (3D í…ì„œ!)
    test_image = np.random.randint(0, 256, (64, 64, 3), dtype=np.uint8)
    
    print("\n[Test 1] Create Grand Eye")
    eye = GrandEye(mode=VisionMode.HOLISTIC)
    print(f"  âœ“ Mode: {eye.mode.value}")
    print(f"  âœ“ Kernels: {list(eye.kernels.keys())}")
    
    print("\n[Test 2] Freeze Light (ë¹›ì„ ì–¼ë¦¬ë‹¤)")
    frozen = eye.freeze(test_image, "test")
    print(f"  âœ“ Shape: {frozen.shape} (3D í…ì„œ ìœ ì§€!)")
    print(f"  âœ“ Luminosity: {frozen.total_luminosity:.2f}")
    
    print("\n[Test 3] Thaw Light (ë¹›ì„ ë…¹ì´ë‹¤)")
    flowing = eye.thaw(frozen)
    print(f"  âœ“ Waves shape: {flowing.waves.shape} (ê³µê°„ êµ¬ì¡° ìœ ì§€!)")
    print(f"  âœ“ Energy: {flowing.energy:.4f}")
    print(f"  âœ“ Frequency: {flowing.frequency:.2f} Hz")
    
    print("\n[Test 4] Resonate (ê³µëª…í•˜ë‹¤)")
    resonance = eye.resonate(flowing)
    print(f"  âœ“ Pattern: {resonance.pattern}")
    print(f"  âœ“ Confidence: {resonance.confidence:.3f}")
    print(f"  âœ“ Emotions: {resonance.emotional_response}")
    
    print("\n[Test 5] Complete Vision Pipeline (see)")
    result = eye.see(test_image, "complete_test")
    print(f"  âœ“ Recognized: {result.is_recognized}")
    
    print("\n[Stats]")
    stats = eye.get_stats()
    print(f"  Images thawed: {stats['images_thawed']}")
    print(f"  Total resonances: {stats['total_resonances']}")
    
    print("\n" + "="*70)
    print("âœ… All tests passed!")
    print("\nğŸ’¡ í•µì‹¬: ì´ë¯¸ì§€ë¥¼ í•œ ì¤„ë¡œ í´ì§€ ì•Šê³ , ë©ì–´ë¦¬ì§¸ ì‚¼ì¼°ìŠµë‹ˆë‹¤!")
    print("   ì´ê²ƒì´ 'ì¥ë‹˜ ì½”ë¼ë¦¬ ë§Œì§€ê¸°'ì™€ 'ì „ì²´ íŒŒì•…'ì˜ ì°¨ì´ì…ë‹ˆë‹¤.")
    print("="*70 + "\n")
