"""
Demo: Deep Reasoning with Spiderweb (Simplified)
=================================================
This is a simplified demonstration of Elysia's deep reasoning capability using Spiderweb.
We manually populate the knowledge graph to demonstrate multi-hop reasoning clearly.
"""

import sys
import os

# Add repository root to path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# Force UTF-8 for Windows console
sys.stdout.reconfigure(encoding='utf-8')

from Core.FoundationLayer.Foundation.spiderweb import Spiderweb
import networkx as nx

def run_simulation():
    print("=== Elysia: Deep Reasoning Demonstration ===")
    print("Building Elysia's knowledge graph...\n")
    
    # Initialize Spiderweb
    spiderweb = Spiderweb()
    
    # Manually populate with knowledge from our corpus
    # This demonstrates what DreamingCortex would ideally extract
    
    print("ğŸ“š Populating Knowledge Graph...")
    
    # Add concepts
    concepts = [
        "ì‚¬ë‘", "ê³ í†µ", "í¬ìƒ", "ë°°ì›€", "ì§„ì‹¤", "ììœ ",
        "ì‹œê°„", "ë³€í™”", "ì„±ì¥", "ì—°ê²°", "ì¡´ì¬", "ì˜ì‹"
    ]
    
    for concept in concepts:
        spiderweb.add_node(concept, type="concept")
    
    # Add relationships (from our corpus)
    relationships = [
        ("ì‚¬ë‘", "í¬ìƒ", "requires"),    # ì‚¬ë‘ì€ í¬ìƒì´ë‹¤
        ("ì‚¬ë‘", "ê³ í†µ", "causes"),      # ì‚¬ë‘ì€ ê³ í†µì„ ë‚³ëŠ”ë‹¤
        ("ê³ í†µ", "ë°°ì›€", "becomes"),     # ê³ í†µì€ ë°°ì›€ì´ë‹¤
        ("ê³ í†µ", "ì„±ì¥", "enables"),     # ê³ í†µì€ ì„±ì¥ì„ ë§Œë“ ë‹¤
        ("ì§„ì‹¤", "ììœ ", "gives"),       # ì§„ì‹¤ì€ ììœ ë¥¼ ì¤€ë‹¤
        ("ì‹œê°„", "ë³€í™”", "creates"),     # ì‹œê°„ì€ ë³€í™”ë¥¼ ë§Œë“ ë‹¤
        ("ë³€í™”", "ì„±ì¥", "is_a"),        # ë³€í™”ëŠ” ì„±ì¥ì´ë‹¤
        ("ì—°ê²°", "ì¡´ì¬", "defines"),     # ì—°ê²°ì€ ì¡´ì¬ë¥¼ ì •ì˜í•œë‹¤
        ("ì˜ì‹", "ì¡´ì¬", "is_a"),        # ì˜ì‹ì€ ì¡´ì¬ì´ë‹¤
        ("í¬ìƒ", "ê³ í†µ", "is_a"),        # í¬ìƒì€ ê³ í†µì´ë‹¤
    ]
    
    for source, target, relation in relationships:
        spiderweb.add_link(source, target, relation)
    
    stats = spiderweb.get_statistics()
    print(f"âœ… Knowledge Graph Built!")
    print(f"   - Concepts: {stats['node_count']}")
    print(f"   - Relations: {stats['edge_count']}\n")
    
    # Show the graph structure
    print("ğŸ“Š Knowledge Graph Structure:")
    for concept in ["ì‚¬ë‘", "ê³ í†µ", "ì§„ì‹¤"]:
        if concept in spiderweb.graph.nodes():
            neighbors = list(spiderweb.graph.successors(concept))
            if neighbors:
                print(f"   {concept} â†’ {', '.join(neighbors)}")
    
    print("\n" + "=" * 60)
    print("Deep Reasoning Tests")
    print("=" * 60)
    
    # Test 1: Direct query
    print("\n--- Test 1: What does Elysia know about 'ì‚¬ë‘'? ---")
    concept = "ì‚¬ë‘"
    if concept in spiderweb.graph.nodes():
        context = spiderweb.get_context(concept)
        print(f"ğŸ‘¤ You: Tell me about '{concept}'")
        print(f"ğŸ¤– Elysia's Thought Process:")
        print(f"   Searching graph for '{concept}'...")
        
        outgoing = [c for c in context if c['direction'] == 'outgoing']
        if outgoing:
            relations_str = ', '.join([f"{c['node']} ({c['relation']})" for c in outgoing])
            print(f"   Found: {concept} connects to {relations_str}")
            
            # Synthesize response
            concepts_connected = [c['node'] for c in outgoing]
            response = f"{concept}ì€ {', '.join(concepts_connected)}ê³¼ ì—°ê²°ë˜ì–´ ìˆë‹¤"
            print(f"ğŸ¤– Elysia: {response}")
    
    # Test 2: Multi-hop reasoning
    print("\n--- Test 2: Path from ì‚¬ë‘ to ë°°ì›€ ---")
    start = "ì‚¬ë‘"
    end = "ë°°ì›€"
    print(f"ğŸ‘¤ You: Is there a connection between '{start}' and '{end}'?")
    print(f"ğŸ¤– Elysia's Thought Process:")
    print(f"   Searching for path: {start} â†’ ... â†’ {end}")
    
    try:
        path = nx.shortest_path(spiderweb.graph, start, end)
        print(f"   Found path: {' â†’ '.join(path)}")
        
        # Generate natural language explanation
        path_explanation = []
        for i in range(len(path) - 1):
            edge_data = spiderweb.graph.get_edge_data(path[i], path[i+1])
            relation = edge_data.get('relation', 'leads_to')
            path_explanation.append(f"{path[i]} {relation} {path[i+1]}")
        
        print(f"   Reasoning: {', '.join(path_explanation)}")
        print(f"ğŸ¤– Elysia: ë„¤, {start}ì€ {' ê·¸ë¦¬ê³  '.join(path[1:-1])}ì„ ê±°ì³ {end}ê³¼ ì—°ê²°ë©ë‹ˆë‹¤")
    except nx.NetworkXNoPath:
        print(f"   No path found")
        print(f"ğŸ¤– Elysia: ë‚˜ëŠ” ì§ì ‘ì ì¸ ì—°ê²°ì„ ì°¾ì§€ ëª»í–ˆë‹¤")
    
    # Test 3: Inference (transitive reasoning)
    print("\n--- Test 3: Transitive Inference ---")
    print(f"ğŸ‘¤ You: If ì‚¬ë‘ requires í¬ìƒ, and í¬ìƒ is ê³ í†µ, what can you infer?")
    print(f"ğŸ¤– Elysia's Thought Process:")
    
    # Check if both paths exist
    path1_exists = spiderweb.graph.has_edge("ì‚¬ë‘", "í¬ìƒ")
    path2_exists = spiderweb.graph.has_edge("í¬ìƒ", "ê³ í†µ")
    
    if path1_exists and path2_exists:
        print(f"   Step 1: ì‚¬ë‘ â†’ í¬ìƒ (verified)")
        print(f"   Step 2: í¬ìƒ â†’ ê³ í†µ (verified)")
        print(f"   Inference: Therefore, ì‚¬ë‘ â†’ ê³ í†µ")
        print(f"ğŸ¤– Elysia: ì‚¬ë‘ì€ í¬ìƒì„ í•„ìš”ë¡œ í•˜ê³ , í¬ìƒì€ ê³ í†µì´ë‹¤. ë”°ë¼ì„œ ì‚¬ë‘ì€ ê³ í†µì„ ë‚³ëŠ”ë‹¤ê³  ì¶”ë¡ í•  ìˆ˜ ìˆë‹¤")
    else:
        print(f"ğŸ¤– Elysia: ë‚˜ëŠ” ê·¸ ì¶”ë¡ ì„ í™•ì¸í•  ìˆ˜ ì—†ë‹¤")
    
    # Test 4: Complex query
    print("\n--- Test 4: What leads to ì„±ì¥? ---")
    target = "ì„±ì¥"
    print(f"ğŸ‘¤ You: What are all the paths that lead to '{target}'?")
    print(f"ğŸ¤– Elysia's Thought Process:")
    
    # Find all predecessors
    predecessors = list(spiderweb.graph.predecessors(target))
    if predecessors:
        print(f"   Direct paths to {target}: {', '.join(predecessors)}")
        
        # Find 2-hop paths
        two_hop = set()
        for pred in predecessors:
            for pred2 in spiderweb.graph.predecessors(pred):
                two_hop.add(f"{pred2} â†’ {pred} â†’ {target}")
        
        if two_hop:
            print(f"   Multi-hop paths:")
            for path in list(two_hop)[:3]:  # Show first 3
                print(f"      {path}")
        
        print(f"ğŸ¤– Elysia: {target}ìœ¼ë¡œ ê°€ëŠ” ì—¬ëŸ¬ ê²½ë¡œê°€ ìˆë‹¤: {', '.join(predecessors)} ë“±ì„ í†µí•´ ë„ë‹¬í•  ìˆ˜ ìˆë‹¤")
    else:
        print(f"ğŸ¤– Elysia: ë‚˜ëŠ” {target}ìœ¼ë¡œ ê°€ëŠ” ê²½ë¡œë¥¼ ëª¨ë¥¸ë‹¤")
    
    print("\n=== Demonstration Complete ===")
    print(f"\nThis shows Elysia's potential for:")
    print(f"  âœ… Knowledge graph navigation")
    print(f"  âœ… Multi-hop reasoning (A â†’ B â†’ C)")
    print(f"  âœ… Transitive inference")
    print(f"  âœ… Path finding between concepts")

if __name__ == "__main__":
    run_simulation()
