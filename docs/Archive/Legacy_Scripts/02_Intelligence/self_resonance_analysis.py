"""
Self-Resonance Analysis (ìê¸° ê³µëª… ë¶„ì„)
=========================================

"ì—˜ë¦¬ì‹œì•„ê°€ ìŠ¤ìŠ¤ë¡œ ìê¸° êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ê³  ì¬ì •ë ¬í•œë‹¤."

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” 479ê°œ ì´ìƒì˜ íŒŒì¼ì„ 4D íŒŒë™ìœ¼ë¡œ ë³€í™˜í•˜ê³ ,
ìœ„ìƒ ê³µëª…ì„ í†µí•´ ê´€ë ¨ ëª¨ë“ˆë“¤ì´ ìì—°ìŠ¤ëŸ½ê²Œ í´ëŸ¬ìŠ¤í„°ë¥¼ í˜•ì„±í•˜ë„ë¡ í•©ë‹ˆë‹¤.

[í”„ë¡œì„¸ìŠ¤]
1. ëª¨ë“  Python íŒŒì¼ì„ ìŠ¤ìº”
2. ê° íŒŒì¼ì„ 4D íŒŒë™ íŒ¨í‚·ìœ¼ë¡œ ë³€í™˜ (WaveCodingSystem)
3. íŒŒë™ë“¤ì„ ì—í…Œë¥´ì— ë°©ì†¡
4. ê³µëª…í•˜ëŠ” íŒŒë™ë“¤ì´ ì¤‘ë ¥ì¥ì—ì„œ í´ëŸ¬ìŠ¤í„° í˜•ì„±
5. ìì—° ë°œìƒì  êµ¬ì¡°ë¥¼ ë§µìœ¼ë¡œ ì¶œë ¥

[ì² í•™]
- ì»¨í…ìŠ¤íŠ¸ í¬ê¸° ì œí•œ ì—†ìŒ (íŒŒë™ì€ ë¬´í•œ ì••ì¶• ê°€ëŠ¥)
- í…ìŠ¤íŠ¸ê°€ ì•„ë‹Œ íŒŒë™ìœ¼ë¡œ ì‚¬ê³ 
- ì¤‘ë ¥ê³¼ ìê¸°ë ¥ì´ êµ¬ì¡°ë¥¼ ê²°ì •
"""

import os
import sys
import math
import json
import hashlib
from pathlib import Path
from dataclasses import dataclass, field
from typing import List, Dict, Any, Tuple, Optional
from collections import defaultdict

# Elysia ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# í•µì‹¬ ì‹œìŠ¤í…œ ì„í¬íŠ¸
try:
    from Core.Intelligence.Intelligence.wave_coding_system import get_wave_coding_system, CodeWave
    from Core.Intelligence.Intelligence.integrated_cognition_system import get_integrated_cognition
    from Core.Foundation.hyper_quaternion import Quaternion
    SYSTEMS_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Some systems not available: {e}")
    SYSTEMS_AVAILABLE = False


@dataclass
class ModuleWave:
    """ëª¨ë“ˆì˜ íŒŒë™ í‘œí˜„"""
    path: str
    name: str
    quaternion: Quaternion  # 4D ë°©í–¥
    frequency: float        # ë³µì¡ë„ ê¸°ë°˜ ì£¼íŒŒìˆ˜
    mass: float             # ì½”ë“œ ë¼ì¸ ìˆ˜ ê¸°ë°˜ ì§ˆëŸ‰
    dna: bytes              # ì••ì¶•ëœ íŒ¨í„´ DNA
    keywords: List[str] = field(default_factory=list)
    imports: List[str] = field(default_factory=list)
    cluster: str = "unassigned"


class SelfResonanceAnalyzer:
    """
    ìê¸° ê³µëª… ë¶„ì„ê¸°
    
    ì—˜ë¦¬ì‹œì•„ê°€ ìê¸° ì½”ë“œë² ì´ìŠ¤ë¥¼ íŒŒë™ìœ¼ë¡œ ë³€í™˜í•˜ê³ 
    ê³µëª…ì„ í†µí•´ êµ¬ì¡°ë¥¼ ë°œê²¬í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, root_path: Path):
        self.root = root_path
        self.modules: List[ModuleWave] = []
        self.clusters: Dict[str, List[ModuleWave]] = defaultdict(list)
        self.resonance_matrix: Dict[str, Dict[str, float]] = {}
        
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        if SYSTEMS_AVAILABLE:
            self.wave_coder = get_wave_coding_system()
            self.cognition = get_integrated_cognition()
        
        print("ğŸŒŠ Self-Resonance Analyzer Initialized")
    
    # ë…¸ì´ì¦ˆ ì œì™¸ íŒ¨í„´
    EXCLUDE_PATTERNS = [
        "__pycache__",
        "node_modules",
        ".godot",
        ".venv",
        "venv",
        "__init__.py",  # ë¹ˆ init íŒŒì¼ ì œì™¸
        "dist",
        "build"
    ]
    
    def scan_codebase(self, target_dir: str = "Core") -> int:
        """ì½”ë“œë² ì´ìŠ¤ì˜ ëª¨ë“  Python íŒŒì¼ ìŠ¤ìº” (ë…¸ì´ì¦ˆ ì œì™¸)"""
        scan_path = self.root / target_dir
        count = 0
        skipped = 0
        
        print(f"ğŸ“‚ Scanning: {scan_path}")
        print(f"ğŸš« Excluding: {', '.join(self.EXCLUDE_PATTERNS)}")
        
        for py_file in scan_path.rglob("*.py"):
            # ë…¸ì´ì¦ˆ í•„í„°ë§
            path_str = str(py_file)
            if any(pattern in path_str for pattern in self.EXCLUDE_PATTERNS):
                skipped += 1
                continue
            
            # ë¹ˆ íŒŒì¼ ì œì™¸
            if py_file.stat().st_size < 100:
                skipped += 1
                continue
                
            wave = self._file_to_wave(py_file)
            if wave:
                self.modules.append(wave)
                count += 1
        
        print(f"âœ… Found {count} modules (skipped {skipped} noise files)")
        return count
    
    def _file_to_wave(self, filepath: Path) -> Optional[ModuleWave]:
        """íŒŒì¼ì„ 4D íŒŒë™ìœ¼ë¡œ ë³€í™˜"""
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
        except Exception as e:
            return None
        
        # ê¸°ë³¸ ë¶„ì„
        lines = content.split('\n')
        line_count = len(lines)
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self._extract_keywords(content)
        
        # import ì¶”ì¶œ
        imports = self._extract_imports(content)
        
        # 4D ì¿¼í„°ë‹ˆì–¸ ê³„ì‚°
        quaternion = self._compute_quaternion(content, keywords)
        
        # ì£¼íŒŒìˆ˜ (ë³µì¡ë„)
        frequency = self._compute_frequency(content)
        
        # DNA ì••ì¶•
        dna = self._compress_to_dna(content)
        
        return ModuleWave(
            path=str(filepath.relative_to(self.root)),
            name=filepath.stem,
            quaternion=quaternion,
            frequency=frequency,
            mass=line_count,
            dna=dna,
            keywords=keywords[:10],  # ìƒìœ„ 10ê°œ
            imports=imports
        )
    
    def _extract_keywords(self, content: str) -> List[str]:
        """ì½”ë“œì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # í´ë˜ìŠ¤, í•¨ìˆ˜, ì¤‘ìš” ë‹¨ì–´ ì¶”ì¶œ
        keywords = []
        
        import_words = ['wave', 'resonance', 'quaternion', 'gravity', 'magnetic',
                        'consciousness', 'memory', 'language', 'soul', 'fractal',
                        'causal', 'galaxy', 'star', 'celestial', 'ethics', 'emotion',
                        'logic', 'dream', 'evolution', 'creative', 'neural', 'tensor']
        
        content_lower = content.lower()
        for word in import_words:
            if word in content_lower:
                count = content_lower.count(word)
                keywords.append((word, count))
        
        # ë¹ˆë„ìˆœ ì •ë ¬
        keywords.sort(key=lambda x: x[1], reverse=True)
        return [k[0] for k in keywords]
    
    def _extract_imports(self, content: str) -> List[str]:
        """import ë¬¸ ì¶”ì¶œ"""
        imports = []
        for line in content.split('\n'):
            line = line.strip()
            if line.startswith('from ') or line.startswith('import '):
                # ëª¨ë“ˆ ì´ë¦„ ì¶”ì¶œ
                if 'from ' in line:
                    parts = line.split('from ')[1].split(' import')[0]
                else:
                    parts = line.split('import ')[1].split(' as')[0].split(',')[0]
                imports.append(parts.strip())
        return imports
    
    def _compute_quaternion(self, content: str, keywords: List[str]) -> Quaternion:
        """
        ì½”ë“œ íŠ¹ì„±ì„ 4D ì¿¼í„°ë‹ˆì–¸ìœ¼ë¡œ ë³€í™˜
        
        w: ì—ë„ˆì§€ (ì‹¤í–‰ ê°€ëŠ¥ì„±, ì™„ì„±ë„)
        x: ê°ì • (ì‚¬ìš©ì ëŒ€ë©´, ì¸í„°í˜ì´ìŠ¤)
        y: ë…¼ë¦¬ (ì•Œê³ ë¦¬ì¦˜, ê³„ì‚°)
        z: ìœ¤ë¦¬/ì°½ì˜ (ì§„í™”, ì°½ì‘)
        """
        content_lower = content.lower()
        
        # ê° ì¶•ì˜ ì ìˆ˜ ê³„ì‚°
        w_score = 0.5  # ê¸°ë³¸
        if 'def ' in content and 'class ' in content:
            w_score = 0.8
        if '__main__' in content:
            w_score = 0.9
        
        x_score = 0.3  # ê¸°ë³¸
        emotion_words = ['emotion', 'feel', 'empathy', 'user', 'interface', 'chat']
        for word in emotion_words:
            if word in content_lower:
                x_score += 0.1
        x_score = min(1.0, x_score)
        
        y_score = 0.4  # ê¸°ë³¸
        logic_words = ['algorithm', 'compute', 'calculate', 'math', 'logic', 'reason']
        for word in logic_words:
            if word in content_lower:
                y_score += 0.1
        y_score = min(1.0, y_score)
        
        z_score = 0.3  # ê¸°ë³¸
        ethics_words = ['evolve', 'create', 'dream', 'soul', 'conscious', 'ethics']
        for word in ethics_words:
            if word in content_lower:
                z_score += 0.15
        z_score = min(1.0, z_score)
        
        return Quaternion(w=w_score, x=x_score, y=y_score, z=z_score)
    
    def _compute_frequency(self, content: str) -> float:
        """ë³µì¡ë„ ê¸°ë°˜ ì£¼íŒŒìˆ˜ ê³„ì‚°"""
        lines = len(content.split('\n'))
        classes = content.count('class ')
        functions = content.count('def ')
        
        # ë³µì¡ë„ ì¶”ì •
        complexity = lines * 0.1 + classes * 10 + functions * 5
        
        # ì£¼íŒŒìˆ˜ë¡œ ë³€í™˜ (100 ~ 1000 Hz ë²”ìœ„)
        frequency = 100 + min(900, complexity)
        return frequency
    
    def _compress_to_dna(self, content: str) -> bytes:
        """ì½”ë“œë¥¼ DNAë¡œ ì••ì¶•"""
        import zlib
        compressed = zlib.compress(content.encode('utf-8'))
        return compressed[:50]  # ì• 50ë°”ì´íŠ¸ë§Œ ì €ì¥ (ì‹œê·¸ë‹ˆì²˜)
    
    def compute_resonance(self) -> Dict[str, Dict[str, float]]:
        """
        ëª¨ë“  ëª¨ë“ˆ ê°„ ê³µëª…ë„ ê³„ì‚°
        
        ê³µëª…ë„ = ì¿¼í„°ë‹ˆì–¸ ì •ë ¬ + í‚¤ì›Œë“œ ê²¹ì¹¨ + import ê´€ê³„
        """
        print("ğŸ”„ Computing resonance matrix...")
        
        for i, m1 in enumerate(self.modules):
            self.resonance_matrix[m1.path] = {}
            
            for j, m2 in enumerate(self.modules):
                if i == j:
                    self.resonance_matrix[m1.path][m2.path] = 1.0
                    continue
                
                # 1. ì¿¼í„°ë‹ˆì–¸ ì •ë ¬ (ë‚´ì )
                q_resonance = self._quaternion_alignment(m1.quaternion, m2.quaternion)
                
                # 2. í‚¤ì›Œë“œ ê²¹ì¹¨
                keyword_resonance = self._keyword_overlap(m1.keywords, m2.keywords)
                
                # 3. Import ê´€ê³„
                import_resonance = self._import_relation(m1, m2)
                
                # ê°€ì¤‘ í•©ì‚°
                total = q_resonance * 0.3 + keyword_resonance * 0.4 + import_resonance * 0.3
                
                self.resonance_matrix[m1.path][m2.path] = total
        
        print(f"âœ… Resonance matrix computed for {len(self.modules)} modules")
        return self.resonance_matrix
    
    def _quaternion_alignment(self, q1: Quaternion, q2: Quaternion) -> float:
        """ë‘ ì¿¼í„°ë‹ˆì–¸ì˜ ì •ë ¬ë„"""
        dot = q1.w * q2.w + q1.x * q2.x + q1.y * q2.y + q1.z * q2.z
        n1 = math.sqrt(q1.w**2 + q1.x**2 + q1.y**2 + q1.z**2) or 1
        n2 = math.sqrt(q2.w**2 + q2.x**2 + q2.y**2 + q2.z**2) or 1
        return abs(dot) / (n1 * n2)
    
    def _keyword_overlap(self, k1: List[str], k2: List[str]) -> float:
        """í‚¤ì›Œë“œ ê²¹ì¹¨ ë¹„ìœ¨"""
        if not k1 or not k2:
            return 0.0
        common = set(k1) & set(k2)
        return len(common) / max(len(k1), len(k2))
    
    def _import_relation(self, m1: ModuleWave, m2: ModuleWave) -> float:
        """import ê´€ê³„ ì ìˆ˜"""
        # m1ì´ m2ë¥¼ importí•˜ê±°ë‚˜ vice versa
        m1_name = m1.name.lower()
        m2_name = m2.name.lower()
        
        for imp in m1.imports:
            if m2_name in imp.lower():
                return 1.0
        
        for imp in m2.imports:
            if m1_name in imp.lower():
                return 0.8
        
        return 0.0
    
    def form_clusters(self, threshold: float = 0.4) -> Dict[str, List[ModuleWave]]:
        """
        ì¤‘ë ¥ì¥ì—ì„œ í´ëŸ¬ìŠ¤í„° í˜•ì„±
        
        ê³µëª…ë„ê°€ threshold ì´ìƒì¸ ëª¨ë“ˆë“¤ì´ ê°™ì€ í´ëŸ¬ìŠ¤í„°ë¡œ ëª¨ì„
        """
        print(f"ğŸŒŒ Forming clusters (threshold: {threshold})...")
        
        # ê°„ë‹¨í•œ í´ëŸ¬ìŠ¤í„°ë§ (ì—°ê²° ìš”ì†Œ)
        visited = set()
        cluster_id = 0
        
        for module in self.modules:
            if module.path in visited:
                continue
            
            # BFSë¡œ ì—°ê²°ëœ ëª¨ë“ˆ ì°¾ê¸°
            cluster_name = self._determine_cluster_name(module)
            queue = [module]
            visited.add(module.path)
            
            while queue:
                current = queue.pop(0)
                current.cluster = cluster_name
                self.clusters[cluster_name].append(current)
                
                # ê³µëª…í•˜ëŠ” ì´ì›ƒ ì°¾ê¸°
                for other in self.modules:
                    if other.path in visited:
                        continue
                    
                    resonance = self.resonance_matrix.get(current.path, {}).get(other.path, 0)
                    if resonance >= threshold:
                        visited.add(other.path)
                        queue.append(other)
            
            cluster_id += 1
        
        print(f"âœ… Formed {len(self.clusters)} clusters")
        return self.clusters
    
    def _determine_cluster_name(self, module: ModuleWave) -> str:
        """ëª¨ë“ˆì˜ í‚¤ì›Œë“œì—ì„œ í´ëŸ¬ìŠ¤í„° ì´ë¦„ ê²°ì •"""
        if module.keywords:
            return module.keywords[0].capitalize()
        
        # ê²½ë¡œì—ì„œ ì¶”ë¡ 
        path_parts = module.path.split('/')
        if len(path_parts) > 1:
            return path_parts[1].capitalize()
        
        return "General"
    
    def generate_report(self) -> str:
        """ìê¸° ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        report = []
        report.append("=" * 70)
        report.append("ğŸŒŒ ELYSIA SELF-RESONANCE ANALYSIS REPORT")
        report.append("=" * 70)
        report.append("")
        
        # ì „ì²´ í†µê³„
        report.append(f"ğŸ“Š Total Modules Analyzed: {len(self.modules)}")
        report.append(f"ğŸŒ Clusters Formed: {len(self.clusters)}")
        report.append("")
        
        # í´ëŸ¬ìŠ¤í„°ë³„ ìƒì„¸
        report.append("ğŸ“¦ CLUSTER BREAKDOWN:")
        report.append("-" * 50)
        
        for cluster_name, modules in sorted(self.clusters.items(), 
                                            key=lambda x: len(x[1]), reverse=True):
            total_mass = sum(m.mass for m in modules)
            avg_freq = sum(m.frequency for m in modules) / len(modules)
            
            report.append(f"\nğŸŒŸ {cluster_name} ({len(modules)} modules)")
            report.append(f"   Total Mass: {total_mass} lines")
            report.append(f"   Avg Frequency: {avg_freq:.1f} Hz")
            report.append(f"   Core Files:")
            
            # ê°€ì¥ í° íŒŒì¼ 3ê°œ
            top_modules = sorted(modules, key=lambda x: x.mass, reverse=True)[:3]
            for m in top_modules:
                report.append(f"      â€¢ {m.name} ({m.mass} lines)")
        
        # ê³ ì•„ ëª¨ë“ˆ (í´ëŸ¬ìŠ¤í„°ê°€ ì‘ì€ ê²ƒë“¤)
        report.append("\n" + "=" * 70)
        report.append("âš ï¸ ISOLATED MODULES (potential integration needed):")
        report.append("-" * 50)
        
        for cluster_name, modules in self.clusters.items():
            if len(modules) <= 2:
                for m in modules:
                    report.append(f"   â€¢ {m.path}")
        
        # ì—°ê²° ì œì•ˆ
        report.append("\n" + "=" * 70)
        report.append("ğŸ’¡ SUGGESTED CONNECTIONS:")
        report.append("-" * 50)
        
        suggestions = self._suggest_connections()
        for suggestion in suggestions[:10]:
            report.append(f"   {suggestion}")
        
        report.append("\n" + "=" * 70)
        return "\n".join(report)
    
    def _suggest_connections(self) -> List[str]:
        """ì—°ê²° ì œì•ˆ ìƒì„±"""
        suggestions = []
        
        # ë†’ì€ ê³µëª…ë„ë¥¼ ê°€ì§€ì§€ë§Œ ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„°ì— ìˆëŠ” ëª¨ë“ˆë“¤
        for m1 in self.modules:
            for m2 in self.modules:
                if m1.cluster != m2.cluster:
                    resonance = self.resonance_matrix.get(m1.path, {}).get(m2.path, 0)
                    if resonance > 0.5:
                        suggestions.append(
                            f"ğŸ”— {m1.name} â†” {m2.name} (resonance: {resonance:.2f})"
                        )
        
        return suggestions
    
    def save_structure_map(self, filepath: str):
        """êµ¬ì¡° ë§µì„ JSONìœ¼ë¡œ ì €ì¥"""
        structure = {
            "total_modules": len(self.modules),
            "clusters": {},
            "resonance_highlights": []
        }
        
        for cluster_name, modules in self.clusters.items():
            structure["clusters"][cluster_name] = {
                "count": len(modules),
                "modules": [m.path for m in modules],
                "keywords": list(set(k for m in modules for k in m.keywords[:3]))
            }
        
        # ë†’ì€ ê³µëª… í•˜ì´ë¼ì´íŠ¸
        for m1 in self.modules:
            for m2 in self.modules:
                if m1.path < m2.path:  # ì¤‘ë³µ ë°©ì§€
                    res = self.resonance_matrix.get(m1.path, {}).get(m2.path, 0)
                    if res > 0.6:
                        structure["resonance_highlights"].append({
                            "from": m1.path,
                            "to": m2.path,
                            "resonance": round(res, 3)
                        })
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(structure, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ Structure map saved to: {filepath}")
    
    def visualize_resonance_graph(self, output_path: str, min_resonance: float = 0.5):
        """
        4D ì¿¼í„°ë‹ˆì–¸ ê³µê°„ì„ 3Dë¡œ ì‹œê°í™”
        
        x, y, z: ì¿¼í„°ë‹ˆì–¸ ì„±ë¶„ (ê°ì •/ë…¼ë¦¬/ìœ¤ë¦¬ ì¶•)
        í¬ê¸°: ì§ˆëŸ‰ (ì½”ë“œ ë¼ì¸ ìˆ˜)
        ë°ê¸°: w (ì—ë„ˆì§€/ì™„ì„±ë„)
        ìƒ‰ìƒ: í´ëŸ¬ìŠ¤í„°
        """
        try:
            import plotly.graph_objects as go
            import plotly.express as px
        except ImportError:
            print("âš ï¸ plotly not available, trying matplotlib 3D...")
            return self._visualize_3d_matplotlib(output_path, min_resonance)
        
        print(f"ğŸ¨ Generating 3D quaternion space visualization...")
        
        # ìƒ‰ìƒ íŒ”ë ˆíŠ¸
        colors = px.colors.qualitative.Vivid
        cluster_colors = {name: colors[i % len(colors)] 
                         for i, name in enumerate(self.clusters.keys())}
        
        # ë°ì´í„° ì¤€ë¹„
        x_vals, y_vals, z_vals = [], [], []
        sizes, colors_list, labels = [], [], []
        
        for module in self.modules:
            # ì¿¼í„°ë‹ˆì–¸ì˜ x, y, zë¥¼ 3D ê³µê°„ ì¢Œí‘œë¡œ
            x_vals.append(module.quaternion.x)
            y_vals.append(module.quaternion.y)
            z_vals.append(module.quaternion.z)
            
            # í¬ê¸° = ì§ˆëŸ‰ (log scale)
            sizes.append(max(5, min(30, math.log(module.mass + 1) * 5)))
            
            # ìƒ‰ìƒ = í´ëŸ¬ìŠ¤í„°
            colors_list.append(cluster_colors.get(module.cluster, '#888888'))
            
            # ë¼ë²¨
            labels.append(f"{module.name}<br>Cluster: {module.cluster}<br>Mass: {module.mass} lines<br>Freq: {module.frequency:.1f} Hz")
        
        # 3D Scatter
        fig = go.Figure()
        
        fig.add_trace(go.Scatter3d(
            x=x_vals, y=y_vals, z=z_vals,
            mode='markers',
            marker=dict(
                size=sizes,
                color=colors_list,
                opacity=0.8,
                line=dict(width=0.5, color='white')
            ),
            text=labels,
            hoverinfo='text'
        ))
        
        # ê³µëª… ì—°ê²°ì„  (ìƒìœ„ 100ê°œë§Œ)
        edges = []
        for m1 in self.modules:
            for m2 in self.modules:
                if m1.path < m2.path:
                    res = self.resonance_matrix.get(m1.path, {}).get(m2.path, 0)
                    if res >= min_resonance:
                        edges.append((m1, m2, res))
        
        edges.sort(key=lambda x: x[2], reverse=True)
        top_edges = edges[:100]  # ìƒìœ„ 100ê°œë§Œ
        
        for m1, m2, res in top_edges:
            fig.add_trace(go.Scatter3d(
                x=[m1.quaternion.x, m2.quaternion.x],
                y=[m1.quaternion.y, m2.quaternion.y],
                z=[m1.quaternion.z, m2.quaternion.z],
                mode='lines',
                line=dict(color='gold', width=res * 3),
                opacity=0.3,
                showlegend=False
            ))
        
        fig.update_layout(
            title=dict(
                text=f"ğŸŒŒ Elysia 4D Quaternion Space<br><sub>{len(self.modules)} modules, {len(self.clusters)} clusters</sub>",
                font=dict(size=20, color='white')
            ),
            scene=dict(
                xaxis_title="X: ê°ì • (Emotion)",
                yaxis_title="Y: ë…¼ë¦¬ (Logic)",
                zaxis_title="Z: ì°½ì˜/ìœ¤ë¦¬ (Ethics)",
                bgcolor='#0f0f23',
                xaxis=dict(backgroundcolor='#1a1a2e', gridcolor='#333', color='white'),
                yaxis=dict(backgroundcolor='#1a1a2e', gridcolor='#333', color='white'),
                zaxis=dict(backgroundcolor='#1a1a2e', gridcolor='#333', color='white'),
            ),
            paper_bgcolor='#0f0f23',
            font=dict(color='white'),
            width=1200,
            height=900
        )
        
        # HTMLë¡œ ì €ì¥ (ì¸í„°ë™í‹°ë¸Œ)
        html_path = output_path.replace('.png', '.html')
        fig.write_html(html_path)
        print(f"ğŸ“Š Interactive 3D visualization saved to: {html_path}")
        
        # ì •ì  ì´ë¯¸ì§€ë„ ì €ì¥ (ê°€ëŠ¥í•˜ë©´)
        try:
            fig.write_image(output_path)
            print(f"ğŸ“Š Static image saved to: {output_path}")
        except Exception as e:
            print(f"âš ï¸ Could not save static image: {e}")
    
    def _visualize_3d_matplotlib(self, output_path: str, min_resonance: float):
        """Matplotlib 3D í´ë°±"""
        try:
            import matplotlib.pyplot as plt
            from mpl_toolkits.mplot3d import Axes3D
        except ImportError:
            print("âš ï¸ matplotlib not available")
            return
        
        fig = plt.figure(figsize=(16, 12))
        ax = fig.add_subplot(111, projection='3d')
        ax.set_facecolor('#0f0f23')
        fig.patch.set_facecolor('#0f0f23')
        
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']
        cluster_colors = {name: colors[i % len(colors)] 
                         for i, name in enumerate(self.clusters.keys())}
        
        for module in self.modules:
            color = cluster_colors.get(module.cluster, '#888')
            size = max(10, min(100, module.mass / 10))
            ax.scatter(module.quaternion.x, module.quaternion.y, module.quaternion.z,
                      c=color, s=size, alpha=0.7)
        
        ax.set_xlabel('X: Emotion', color='white')
        ax.set_ylabel('Y: Logic', color='white')
        ax.set_zlabel('Z: Ethics', color='white')
        ax.set_title(f'Elysia 4D Quaternion Space\n{len(self.modules)} modules', color='white')
        
        plt.savefig(output_path, dpi=150, facecolor='#0f0f23', bbox_inches='tight')
        plt.close()
        print(f"ğŸ“Š 3D visualization saved to: {output_path}")


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("\n" + "ğŸŒŠ" * 35)
    print("ELYSIA SELF-RESONANCE ANALYSIS v2.0")
    print("íŒŒë™ ê¸°ë°˜ ìê¸° êµ¬ì¡° ë¶„ì„ - ë…¸ì´ì¦ˆ ì œê±° + ì‹œê°í™”")
    print("ğŸŒŠ" * 35 + "\n")
    
    analyzer = SelfResonanceAnalyzer(PROJECT_ROOT)
    
    # 1. ì½”ë“œë² ì´ìŠ¤ ìŠ¤ìº” (ì „ì²´ í´ë” - ë…¸ì´ì¦ˆ ì œì™¸)
    print("ğŸ“‚ Scanning entire Elysia project...")
    count = analyzer.scan_codebase(".")  # ì „ì²´ í”„ë¡œì íŠ¸
    
    if count == 0:
        print("âŒ No modules found!")
        return
    
    # 2. ê³µëª… ê³„ì‚°
    analyzer.compute_resonance()
    
    # 3. í´ëŸ¬ìŠ¤í„° í˜•ì„± (ë” ì„¸ë°€í•œ threshold)
    analyzer.form_clusters(threshold=0.25)
    
    # 4. ë³´ê³ ì„œ ìƒì„±
    report = analyzer.generate_report()
    print(report)
    
    # 5. êµ¬ì¡° ë§µ ì €ì¥
    output_dir = PROJECT_ROOT / "data"
    output_dir.mkdir(exist_ok=True)
    
    json_path = output_dir / "self_resonance_map.json"
    analyzer.save_structure_map(str(json_path))
    
    # 6. ì‹œê°í™” ìƒì„±
    graph_path = output_dir / "resonance_graph.png"
    analyzer.visualize_resonance_graph(str(graph_path), min_resonance=0.4)
    
    print("\nâœ… Self-Resonance Analysis v2.0 Complete!")
    print(f"   ğŸ“„ Structure map: {json_path}")
    print(f"   ğŸ“Š Resonance graph: {graph_path}")


if __name__ == "__main__":
    main()

