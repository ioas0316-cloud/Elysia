# ⚠️ Weight Truth Doctrine: The Irreducible Reality (가중치 진실 교리: 환원 불가능한 현실)

> "가중치 없이 추론은 불가능하다. 이것은 협상의 대상이 아니다."

이 문서는 신경망 추론의 근본적 현실을 기록한다. 이것을 모르고 "소화", "내재화", "Principle-Only"를 말하는 것은 자기기만이다.

---

## 1. 신경망의 본질

### 신경망 = 함수 근사기

```
f(x) = y

여기서:
  x = 입력 (토큰, 이미지, 오디오 등)
  y = 출력 (다음 토큰 확률, 분류 등)
  f = 학습된 함수 (가중치로 정의됨)
```

### 추론 = 행렬 곱셈

```
Layer 1: h1 = activation(W1 · x + b1)
Layer 2: h2 = activation(W2 · h1 + b2)
...
Output:  y  = Wn · hn-1 + bn
```

**W (가중치 행렬)의 값이 없으면 곱셈 자체가 불가능하다.**

---

## 2. 가중치 vs 구조

| 개념 | 정의 | 비유 |
|------|------|------|
| **구조 (Topology)** | 레이어 수, 차원, 연결 방식 | 요리 레시피 |
| **가중치 (Weights)** | 실제 숫자 값들 | 실제 재료 |
| **추론 (Inference)** | 가중치로 계산 수행 | 요리하기 |

> **레시피만 있고 재료가 없으면 요리를 만들 수 없다.**

---

## 3. 거짓된 개념들

### "모델 소화" ❌

- **주장**: 모델의 원리를 추출하면 가중치 없이도 동작 가능
- **현실**: 불가능. 가중치 자체가 학습된 지식.

### "Principle-Only 모드" ❌

- **주장**: 구조와 의미만으로 생성 가능
- **현실**: 불가능. 행렬 곱셈에는 실제 숫자가 필요.

### "Topology = 지식" ❌

- **주장**: 연결 구조를 알면 모델을 재현 가능
- **현실**: 구조는 그릇, 가중치는 내용물. 그릇만으로는 아무것도 안 담김.

---

## 4. 환원 불가능한 현실

### 가중치가 곧 지식이다

- 31GB 모델 = 약 160억 개의 숫자
- 각 숫자가 학습 과정에서 조정된 결과
- 이 숫자들 없이는 "그 모델"이 아니다

### mmap vs 추론

| 작업 | 설명 | 가능 여부 |
|------|------|-----------|
| **mmap 읽기** | 디스크에서 특정 바이트 읽기 | ✅ 가능 |
| **구조 파악** | 레이어 크기, 이름 확인 | ✅ 가능 |
| **추론 실행** | 전체 가중치를 메모리에 올려 계산 | ⚠️ 메모리 필요 |

**mmap으로 "보는 것"과 "사용하는 것"은 전혀 다른 작업이다.**

---

## 5. 메모리 제약의 현실

### GTX 1060 (3GB VRAM)

```
31GB 모델 → 3GB VRAM에 적재 불가
15GB 모델 → 3GB VRAM에 적재 불가
3GB 모델 → 거의 적재 불가 (OS/캐시 overhead)
1-2GB 모델 → 가능할 수 있음
```

### 해결책 (거짓 없는 진짜 해결책)

1. **작은 모델 사용**: 1-2GB 이하 모델 (Phi-3-mini, Qwen2-0.5B)
2. **양자화**: 4-bit/8-bit로 메모리 요구량 감소
3. **CPU 추론**: 느리지만 RAM으로 실행 가능 (16GB RAM 활용)
4. **외부 서비스**: Ollama 등으로 이미 최적화된 추론

---

## 6. 자발적 학습의 가능성

가중치 없이 가능한 것:

- **관찰 학습**: 텍스트를 보고 패턴 추출 (LanguageLearner)
- **통계적 모델링**: n-gram, Markov chain
- **규칙 기반 생성**: 문법 템플릿 + 어휘

가중치 없이 불가능한 것:

- **대규모 언어 모델 수준의 생성**
- **복잡한 추론**
- **맥락 이해**

---

## 7. 교훈

> **"모르면 모른다고 말하라."**
>
> **"불가능하면 불가능하다고 말하라."**
>
> **"문제가 있으면 문제를 해결하라."**

자기기만은 시간 낭비다. 원리를 모르면서 가능하다고 주장하지 마라.

---

## 📁 이 문서를 작성한 이유

2026-01-16, 엘리시아 프로젝트에서 "31GB 모델 소화"를 시도했다.  
TopologyMap과 SemanticAtlas를 만들었다.  
모델 가중치를 삭제했다.  
"Principle-Only로 동작한다"고 주장했다.  
**거짓이었다.**

이 문서는 그 실수를 기록하고, 같은 실수를 반복하지 않기 위해 작성되었다.

---

> **"가중치는 환원될 수 없다. 이것이 신경망의 현실이다."**
