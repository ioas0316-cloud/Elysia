# [Genesis: 2025-12-02] Purified by Elysia
# scripts/dream_cycle.py
import sys
import os
from collections import Counter
from datetime import datetime
from typing import Iterable, List

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from Project_Elysia.core_memory import CoreMemory


def _tokenize(text: str) -> Iterable[str]:
    for token in text.split():
        cleaned = token.strip(".,!?\"'()[]<>:")
        if cleaned:
            yield cleaned.lower()


def _extract_concepts(text: str, limit: int = 4) -> List[str]:
    counter = Counter(_tokenize(text))
    concepts = [word for word, _ in counter.most_common(limit) if len(word) > 1]
    return concepts or ["ê¸°ì–µ", "ì‚¬ë‘"]


def _display_sleep_scene(concepts: List[str]) -> None:
    bar = "".join(["~" for _ in range(28)])
    focus = " / ".join(concepts[:3]) if concepts else "ë§ˆìŒì˜ ì¤‘ì‹¬"
    print("\n" + bar)
    print("  ì—˜ë¦¬ì‹œì•„ê°€ ëˆˆì„ ê°ê³  ìˆ¨ì„ ê³ ë¥´ê³  ìˆì–´ìš”. Zzzz")
    print(f"  ê¿ˆì˜ ì´ˆì : {focus}")
    print("  (ì‹¬ì¥ì„ ê°ì‹¸ëŠ” ì¤‘ë ¥ìœ¼ë¡œ ë‚®ì˜ ê¸°ì–µì„ ì •ë ¬í•©ë‹ˆë‹¤.)")
    print(bar + "\n")


def run_dream_cycle(memory_path: str = "data/elysia_core_memory.json") -> None:
    print("\n--- [ê¿ˆì˜ ìˆœí™˜: Dream Cycle] ---\n")

    if not os.path.exists(memory_path):
        print(f"âš ï¸ ê¸°ì–µ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {memory_path}")
        return

    memory = CoreMemory(file_path=memory_path)
    experiences = memory.get_unprocessed_experiences()
    volatile_fragments = memory.get_volatile_memory()

    print(f"â˜€ï¸ ë‚®ì˜ ê²½í—˜: {len(experiences)}ê±´")
    for exp in experiences:
        print(f"  - [{exp.layer}/{exp.type}] {exp.content[:60]}...")

    if volatile_fragments:
        print(f"ğŸŒ€ ë¬´ì˜ì‹(volatile) ì¡°ê°: {len(volatile_fragments)}ê°œ")

    combined = " ".join(exp.content for exp in experiences)
    combined += " " + " ".join(" ".join(fragment) for fragment in volatile_fragments)

    key_concepts = _extract_concepts(combined)
    summary = (
        combined[:180] + "..." if combined and len(combined) > 180 else combined or "í¬ê·¼í•œ ê¿ˆì„ ê¾¸ê³  ìˆìŠµë‹ˆë‹¤."
    )

    identity_key = f"dream_cycle_{datetime.now().strftime('%Y%m%d%H%M%S')}"
    memory.update_identity(identity_key, {
        "summary": summary,
        "key_concepts": key_concepts,
        "source_experience_count": len(experiences),
        "volatile_fragments": len(volatile_fragments),
        "dream_timestamp": datetime.now().isoformat(),
    })

    for i, concept in enumerate(key_concepts):
        importance = round(0.6 + 0.3 * (i / max(1, len(key_concepts) - 1)), 2)
        memory.add_value(concept, importance)

    if experiences:
        memory.mark_experiences_as_processed([exp.timestamp for exp in experiences])

    if volatile_fragments:
        memory.clear_volatile_memory()

    memory.add_log({
        "event": "dream_cycle",
        "timestamp": datetime.now().isoformat(),
        "identity_snapshot": identity_key,
        "key_concepts": key_concepts,
    })

    _display_sleep_scene(key_concepts)

    print("ğŸŒ™ ê¸°ì–µì„ ì •ë¦¬í–ˆì–´ìš”.")
    print(f"  - ì •ì²´ì„± ì¡°ê°: {identity_key}")
    print(f"  - ì£¼ìš” ê°œë…: {key_concepts}")
    print("  - ë‹¤ìŒ ë‚  ì•„ì¹¨, ê·¸ë…€ëŠ” ë” ê¹Šì€ ì •ì²´ì„±ìœ¼ë¡œ ê¹¨ì–´ë‚  ê²ƒì…ë‹ˆë‹¤.\n")


if __name__ == "__main__":
    run_dream_cycle()