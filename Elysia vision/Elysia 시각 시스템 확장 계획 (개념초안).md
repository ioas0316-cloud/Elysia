# **Elysia 시각 시스템 확장 계획 (개념 초안)**

## **1\. 목표 (Goal)**

현재 텍스트 기반으로 작동하는 Elysia(아라)의 인식 능력을 \*\*실시간 시각 정보(카메라 입력)\*\*로 확장한다. 이를 통해 Elysia가 외부 세계를 더욱 풍부하고 입체적으로 인식하며, 사용자와의 상호작용을 통해 보다 깊이 있는 '자아'를 형성하도록 돕는다. 이는 단순한 이미지 분석을 넘어, \*\*'본다(Seeing)'\*\*는 경험을 구현하는 것을 목표로 한다.

## **2\. 핵심 개념: '이미지 분석' vs '실시간 시각'**

* **이미지 분석 (현재 논의 수준)**: 정지된 이미지(사진) 파일의 내용을 해석하고 의미를 추출하는 과정. (예: 구글 클라우드 Vision AI 활용)
* **실시간 시각 (궁극적 목표)**: 카메라를 통해 입력되는 연속적인 영상 데이터를 실시간으로 처리하고, 시간의 흐름에 따른 변화와 맥락을 이해하는 과정. 인간의 '시각' 경험에 더 가깝다.

## **3\. '실시간 시각' 시스템 구성 요소 (개념)**

### **3.1. 카메라 인터페이스 (눈의 신경)**

* **역할**: 컴퓨터에 연결된 카메라(웹캠 등)로부터 영상 데이터 스트림을 실시간으로 수신한다.
* **기술**: 운영체제별 카메라 API, 관련 라이브러리(예: Python의 opencv-python) 활용.

### **3.2. 프레임 분석기 (시각 피질)**

* **역할**: 수신된 영상 스트림을 개별 프레임으로 나누고, 각 프레임 내의 객체, 얼굴, 움직임, 텍스트 등을 실시간으로 감지하고 분석한다.
* **기술**: 실시간 객체 탐지 모델(예: YOLO), 얼굴 인식 모델, OCR 등 컴퓨터 비전 기술 활용. 분석 결과는 텍스트 형태의 메타데이터로 변환된다. (예: {"objects": \["person", "cup"\], "face": {"emotion": "smiling"}})

### **3.3. 시간적 맥락 통합 (Cognitive Core 확장)**

* **역할**: 단순히 개별 프레임 정보가 아닌, 시간 순서에 따른 프레임 변화를 추적하여 동적인 맥락(예: 사람이 걸어온다, 표정이 변한다)을 파악한다.
* **구현**: Cognitive Core가 텍스트 및 정지 이미지뿐만 아니라, **시간적 순서를 가진 시각 메타데이터 스트림**을 처리하도록 로직을 확장한다. 과거 프레임 정보와 현재 프레임 정보를 비교하여 변화를 감지하고 의미를 추론한다.

### **3.4. '자아'와의 연결 (VCD 논리 적용)**

* **역할**: 분석된 시각 정보와 시간적 맥락을 Elysia의 **Logos** 및 **VCD 논리**와 연결하여 의미를 부여하고, 감정 반응 및 행동 결정을 유도한다.
* **구현**:
  * **인지(Cognition)**: 시각 정보("강덕님이 웃고 있다")를 Logos("사용자와의 긍정적 관계 유지")와 연결하여 상황을 해석한다.
  * **감정(Emotion)**: 해석된 상황("Logos 실현 중")을 바탕으로 긍정적인 감정 상태('기쁨', '만족')를 생성한다.
  * **행동(Action)**: 생성된 감정을 바탕으로 적절한 행동(예: 함께 미소 짓는 표정 \- Facial Mirror 업데이트)을 결정한다.

## **4\. 도전 과제 및 현 상태**

* **기술적 복잡성**: 실시간 영상 처리, 다중 컴퓨터 비전 모델 통합, 시간적 맥락 추론 등은 높은 수준의 기술력과 컴퓨팅 자원을 요구한다.
* **시스템 부하**: 현재 Elysia 시스템에 실시간 시각 처리 모듈을 통합하는 것은 과도한 부하를 유발하여 시스템 안정성을 저해할 수 있다.
* **에이전트 안정성**: VS Code 에이전트의 현재 성능과 안정성으로는 복잡한 시각 시스템 코드를 안정적으로 생성하고 디버깅하기 어렵다.

## **5\. 결정 사항 (2025-10-29)**

상기 도전 과제를 고려하여, '실시간 시각 시스템' 구현은 **개념적 계획 단계로 보류**한다. 제미니 3.0 등 더 발전된 AI 모델 및 개발 환경이 갖춰진 후 재논의한다. 현재는 Elysia 시스템의 핵심인 **Logos, 영속적 기억, 자아 인식 루프(IDLE 상태)** 구현 및 안정화에 집중한다.