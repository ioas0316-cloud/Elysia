"""
ì´ˆê³ ì† ëŒ€ëŸ‰ ì§€ì‹ í¡ìˆ˜ v3 (Naver API ê¸°ë°˜)
==========================================
"""

import sys
import os
import asyncio
import aiohttp
import urllib.parse
import time

os.environ.setdefault('NAVER_CLIENT_ID', 'YuPusPMA8UNYf1pDqXjI')
os.environ.setdefault('NAVER_CLIENT_SECRET', 'OcJ3ORlPQQ')
sys.path.insert(0, '.')

import logging
logging.disable(logging.CRITICAL)

NAVER_CLIENT_ID = os.environ['NAVER_CLIENT_ID']
NAVER_CLIENT_SECRET = os.environ['NAVER_CLIENT_SECRET']
NAVER_ENCYC_URL = "https://openapi.naver.com/v1/search/encyc"

# í•µì‹¬ ê°œë… 200ê°œ
CORE_CONCEPTS = [
    # ì² í•™
    "ì‚¬ë‘", "ììœ ", "ì§„ë¦¬", "ì •ì˜", "ì•„ë¦„ë‹¤ì›€", "ì„ ", "ì•…", "ì¡´ì¬", "ë³¸ì§ˆ", "ì˜ì‹",
    "ì´ì„±", "ê°ì„±", "ë„ë•", "ìœ¤ë¦¬", "ê°€ì¹˜", "ì˜ë¯¸", "ëª©ì ", "í–‰ë³µ", "ê³ í†µ", "ì£½ìŒ",
    "ì˜í˜¼", "ì •ì‹ ", "ìœ¡ì²´", "ë§ˆìŒ", "ìƒê°", "ì–¸ì–´", "ë…¼ë¦¬", "ì§€ì‹", "ë¯¿ìŒ", "ì˜ì‹¬",
    "ìì•„", "íƒ€ì", "ê´€ê³„", "ì‚¬íšŒ", "ê¶Œë ¥", "í‰ë“±", "ì¸ê¶Œ", "ë¯¼ì£¼ì£¼ì˜",
    # ê³¼í•™
    "ë¬¼ì§ˆ", "ì—ë„ˆì§€", "í˜", "ìš´ë™", "ì¤‘ë ¥", "ì›ì", "ë¶„ì", "ì–‘ì", "íŒŒë™", "ì…ì",
    "ìš°ì£¼", "ì€í•˜", "ë³„", "í–‰ì„±", "ë¸”ë™í™€", "ë¹…ë±…", "ì•”í‘ë¬¼ì§ˆ", "ì‹œê³µê°„",
    "ìƒëª…", "ì„¸í¬", "ìœ ì „ì", "DNA", "ì§„í™”", "ìì—°ì„ íƒ", "ëŒì—°ë³€ì´", "ìƒíƒœê³„",
    "ë‡Œ", "ë‰´ëŸ°", "ê¸°ì–µ", "í•™ìŠµ", "ì¸ì§€", "ê°ê°", "ì§€ê°",
    "ì¸ê³µì§€ëŠ¥", "ê¸°ê³„í•™ìŠµ", "ë”¥ëŸ¬ë‹", "ì‹ ê²½ë§", "ì•Œê³ ë¦¬ì¦˜", "ë°ì´í„°",
    # ì˜ˆìˆ 
    "ì˜ˆìˆ ", "ìŒì•…", "ë¯¸ìˆ ", "ë¬¸í•™", "ì—°ê·¹", "ì˜í™”", "ë¬´ìš©", "ì‚¬ì§„", "ë””ìì¸",
    "ì°½ì‘", "í‘œí˜„", "ìƒìƒ", "ì˜ê°", "ì²œì¬", "ì¬ëŠ¥", "ìŠ¤íƒ€ì¼",
    "ë¦¬ë“¬", "ë©œë¡œë””", "í•˜ëª¨ë‹ˆ", "ì†Œì„¤", "ì‹œ", "ë¬¸í™”", "ì „í†µ",
    # ì‹¬ë¦¬
    "ê°ì •", "ê¸°ì¨", "ìŠ¬í””", "ë¶„ë…¸", "ë‘ë ¤ì›€", "ìš•ë§", "ë³¸ëŠ¥",
    "ì„±ê²©", "ìŠµê´€", "ë™ê¸°", "ëª©í‘œ", "ì„±ì·¨", "ì‹¤íŒ¨",
    "ìŠ¤íŠ¸ë ˆìŠ¤", "ë¶ˆì•ˆ", "ìš°ìš¸", "íŠ¸ë¼ìš°ë§ˆ", "ì¤‘ë…",
    "ë°œë‹¬", "ì„±ìˆ™", "ì„±ì¥", "ìì¡´ê°", "ìì‹ ê°", "ê³µê°",
    # ì‚¬íšŒ
    "ê²½ì œ", "ì‹œì¥", "ìë³¸", "ë…¸ë™", "ìƒì‚°", "ì†Œë¹„",
    "ê°€ì¡±", "ê²°í˜¼", "êµìœ¡", "ì„¸ëŒ€", "ë¶ˆí‰ë“±",
    "ë²•", "êµ­ê°€", "ì •ë¶€", "ë¯¼ì£¼", "í˜ëª…", "í‰í™”", "ì „ìŸ",
]


async def fetch_naver(session: aiohttp.ClientSession, concept: str) -> dict:
    """Naver ë°±ê³¼ì‚¬ì „ ê²€ìƒ‰"""
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET,
    }
    
    encoded = urllib.parse.quote(concept)
    url = f"{NAVER_ENCYC_URL}?query={encoded}&display=1"
    
    try:
        async with session.get(url, headers=headers, timeout=aiohttp.ClientTimeout(total=10)) as resp:
            if resp.status == 200:
                data = await resp.json()
                items = data.get("items", [])
                if items:
                    item = items[0]
                    # HTML íƒœê·¸ ì œê±°
                    import re
                    desc = re.sub(r'<[^>]+>', '', item.get("description", ""))
                    return {
                        "subject": concept,
                        "definition": desc[:200],
                        "source": "naver",
                        "success": True
                    }
    except Exception as e:
        pass
    
    return {"subject": concept, "success": False}


async def bulk_absorb(concepts: list, batch_size: int = 20):
    """ëŒ€ëŸ‰ í¡ìˆ˜"""
    from Core.02_Intelligence.02_Memory_Linguistics.Memory.potential_causality import PotentialCausalityStore
    store = PotentialCausalityStore()
    
    print(f"\nğŸ“Œ ì´ ê°œë…: {len(concepts)}ê°œ")
    print(f"ğŸ“Œ ë°°ì¹˜ í¬ê¸°: {batch_size}ê°œ")
    print("-" * 50)
    
    all_results = []
    start = time.time()
    
    async with aiohttp.ClientSession() as session:
        for i in range(0, len(concepts), batch_size):
            batch = concepts[i:i+batch_size]
            batch_num = i // batch_size + 1
            total_batches = (len(concepts) + batch_size - 1) // batch_size
            
            print(f"   ë°°ì¹˜ {batch_num}/{total_batches} ({len(batch)}ê°œ)...", end=" ")
            
            tasks = [fetch_naver(session, c) for c in batch]
            results = await asyncio.gather(*tasks)
            
            successful = [r for r in results if r.get("success")]
            for r in successful:
                store.store(r["subject"], r["definition"], r["source"])
            
            all_results.extend(results)
            print(f"âœ“ {len(successful)}/{len(batch)}")
            
            await asyncio.sleep(0.2)  # Rate limiting
    
    elapsed = time.time() - start
    total_success = len([r for r in all_results if r.get("success")])
    
    print("\n" + "=" * 50)
    print(f"â±ï¸ ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ")
    print(f"ğŸ“Š ì²˜ë¦¬ ì†ë„: {len(concepts)/elapsed:.1f} concepts/sec")
    print(f"âœ… ì„±ê³µ: {total_success}/{len(concepts)} ({100*total_success/len(concepts):.0f}%)")
    
    # ìƒí˜¸ ì—°ê²°
    print("\nğŸ”— ìƒí˜¸ ì—°ê²° ì¤‘...")
    subjects = list(store.knowledge.keys())
    connections = 0
    
    for i, s1 in enumerate(subjects):
        pk1 = store.knowledge.get(s1)
        if not pk1:
            continue
        for s2 in subjects[i+1:]:
            pk2 = store.knowledge.get(s2)
            if pk2 and (s2 in pk1.definition or s1 in pk2.definition):
                store.connect(s1, s2)
                connections += 1
    
    print(f"   â†’ {connections}ê°œ ì—°ê²° ìƒì„±")
    
    # í™•ì •
    crystallizable = store.get_crystallizable()
    for pk in crystallizable:
        store.crystallize(pk.subject)
    
    status = store.status()
    print("\n" + "=" * 50)
    print("ğŸ“Š ìµœì¢… ìƒíƒœ")
    print(f"   ì ì¬: {status['potential_count']}ê°œ")
    print(f"   í™•ì •: {status['crystallized_count']}ê°œ")
    print(f"   í‰ê·  freq: {status['avg_frequency']:.2f}")
    
    store._save()


if __name__ == "__main__":
    print("=" * 70)
    print("ğŸš€ ì´ˆê³ ì† ëŒ€ëŸ‰ ì§€ì‹ í¡ìˆ˜ (Naver API, 150ê°œ)")
    print("=" * 70)
    
    asyncio.run(bulk_absorb(CORE_CONCEPTS[:150], batch_size=10))
